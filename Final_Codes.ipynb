{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v34nw5sV25q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "# Calculate entropy\n",
        "def calculate_entropy(probabilities):\n",
        "    epsilon = 1e-10\n",
        "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
        "\n",
        "# Compute specificity\n",
        "def specificity(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "# Find the best threshold using Youden's J statistic\n",
        "def find_best_threshold(y_true, y_pred_probs):\n",
        "    thresholds = np.linspace(0.1, 0.9, 100)\n",
        "    best_metric = 0\n",
        "    best_threshold = 0.5\n",
        "    for threshold in thresholds:\n",
        "        y_pred = (y_pred_probs >= threshold).astype(int)\n",
        "        metric = recall_score(y_true, y_pred) + specificity(y_true, y_pred) - 1  # Youden's J\n",
        "        if metric > best_metric:\n",
        "            best_metric = metric\n",
        "            best_threshold = threshold\n",
        "    return best_threshold\n",
        "\n",
        "# Build a deep model with regularization\n",
        "def create_advanced_model(input_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(512, kernel_regularizer=l2(0.01)), BatchNormalization(), LeakyReLU(), Dropout(0.5),\n",
        "        Dense(256, kernel_regularizer=l2(0.01)), BatchNormalization(), LeakyReLU(), Dropout(0.4),\n",
        "        Dense(128, kernel_regularizer=l2(0.01)), BatchNormalization(), LeakyReLU(), Dropout(0.4),\n",
        "        Dense(64, kernel_regularizer=l2(0.005)), BatchNormalization(), LeakyReLU(), Dropout(0.3),\n",
        "        Dense(32, kernel_regularizer=l2(0.005)), BatchNormalization(), LeakyReLU(), Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Initialize cross-validation\n",
        "kf = StratifiedKFold(n_splits=10)\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Store metrics\n",
        "metrics = {\n",
        "    \"accuracy\": [], \"precision\": [], \"recall\": [], \"f1\": [], \"auc\": [], \"entropy\": [], \"conf_matrices\": []\n",
        "}\n",
        "\n",
        "# Run cross-validation\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y)):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # Use SMOTETomek to handle imbalanced data\n",
        "    smote = SMOTETomek()\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    # Standardize data\n",
        "    scaler = StandardScaler()\n",
        "    X_train_resampled = scaler.fit_transform(X_train_resampled)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    # Build and compile model\n",
        "    model = create_advanced_model(input_dim=X_train_resampled.shape[1])\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(loss=BinaryCrossentropy(label_smoothing=0.1), optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    # Callbacks for optimization\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=7, min_lr=0.0001)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_resampled, y_train_resampled, epochs=7000, batch_size=64, validation_split=0.2,\n",
        "              callbacks=[early_stopping, reduce_lr], verbose=0)\n",
        "\n",
        "    # Get predicted probabilities\n",
        "    y_pred_probs_train = model.predict(X_train_resampled).ravel()\n",
        "    y_pred_probs_test = model.predict(X_test).ravel()\n",
        "\n",
        "    # Find best threshold on training set only\n",
        "    best_threshold = find_best_threshold(y_train_resampled, y_pred_probs_train)\n",
        "    y_pred_opt = (y_pred_probs_test >= best_threshold).astype(int)\n",
        "\n",
        "    # Compute metrics on test set\n",
        "    acc = accuracy_score(y_test, y_pred_opt)\n",
        "    precision = precision_score(y_test, y_pred_opt)\n",
        "    recall = recall_score(y_test, y_pred_opt)\n",
        "    f1 = f1_score(y_test, y_pred_opt)\n",
        "    auc = roc_auc_score(y_test, y_pred_probs_test)\n",
        "    entropy = calculate_entropy(np.vstack((1 - y_pred_probs_test, y_pred_probs_test)).T)\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_opt)\n",
        "\n",
        "    # Store metrics\n",
        "    metrics[\"accuracy\"].append(acc)\n",
        "    metrics[\"precision\"].append(precision)\n",
        "    metrics[\"recall\"].append(recall)\n",
        "    metrics[\"f1\"].append(f1)\n",
        "    metrics[\"auc\"].append(auc)\n",
        "    metrics[\"entropy\"].append(entropy)\n",
        "    metrics[\"conf_matrices\"].append(conf_matrix)\n",
        "\n",
        "    # Print results for each fold\n",
        "    print(f'Fold {fold + 1}')\n",
        "    print(f'Best Threshold (Train): {best_threshold:.2f}')\n",
        "    print(f'Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, AUC: {auc:.4f}')\n",
        "    print(f'Entropy: {entropy:.4f}')\n",
        "    print(f'Confusion Matrix:\\n{conf_matrix}\\n')\n",
        "\n",
        "# Compute average and std metrics\n",
        "print(f'Avg Accuracy: {np.mean(metrics[\"accuracy\"]):.4f} ± {np.std(metrics[\"accuracy\"]):.4f}')\n",
        "print(f'Avg Precision: {np.mean(metrics[\"precision\"]):.4f} ± {np.std(metrics[\"precision\"]):.4f}')\n",
        "print(f'Avg Recall: {np.mean(metrics[\"recall\"]):.4f} ± {np.std(metrics[\"recall\"]):.4f}')\n",
        "print(f'Avg F1-score: {np.mean(metrics[\"f1\"]):.4f} ± {np.std(metrics[\"f1\"]):.4f}')\n",
        "print(f'Avg AUC: {np.mean(metrics[\"auc\"]):.4f} ± {np.std(metrics[\"auc\"]):.4f}')\n",
        "print(f'Avg Entropy: {np.mean(metrics[\"entropy\"]):.4f} ± {np.std(metrics[\"entropy\"]):.4f}')\n",
        "\n",
        "# Mean confusion matrix\n",
        "mean_conf_matrix = np.mean(metrics[\"conf_matrices\"], axis=0).astype(int)\n",
        "print('Mean Confusion Matrix:\\n', mean_conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "# Define entropy function\n",
        "def calculate_entropy(probabilities):\n",
        "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
        "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
        "\n",
        "# Function to find the best threshold for F1-score\n",
        "def find_best_threshold(y_true, y_prob, thresholds):\n",
        "    best_f1 = 0\n",
        "    best_threshold = 0.5\n",
        "    for threshold in thresholds:\n",
        "        y_pred = (y_prob[:, 1] >= threshold).astype(int)\n",
        "        f1 = f1_score(y_true, y_pred)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "    return best_threshold, best_f1\n",
        "\n",
        "# Number of folds\n",
        "n_splits = 10\n",
        "\n",
        "# Initialize StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics\n",
        "best_thresholds = []\n",
        "f1_list = []\n",
        "accuracy_list = []\n",
        "precision_list = []\n",
        "recall_list = []\n",
        "roc_auc_list = []\n",
        "entropy_list = []\n",
        "confusion_matrices = []\n",
        "\n",
        "# Loop through the StratifiedKFold splits\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Initialize and train the SVM model with probability estimation\n",
        "    svm_model = SVC(probability=True, random_state=42)\n",
        "    svm_model.fit(X_train, y_train)\n",
        "\n",
        "    # Calibrate the model\n",
        "    calibrated_model = CalibratedClassifierCV(svm_model, method='isotonic', cv=5)\n",
        "    calibrated_model.fit(X_train, y_train)\n",
        "\n",
        "    # Get predicted probabilities on training set\n",
        "    y_prob_train = calibrated_model.predict_proba(X_train)\n",
        "\n",
        "    # Define a range of thresholds to test\n",
        "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
        "\n",
        "    # Find the best threshold based on training set\n",
        "    best_threshold, _ = find_best_threshold(y_train, y_prob_train, thresholds)\n",
        "    best_thresholds.append(best_threshold)\n",
        "\n",
        "    # Get predicted probabilities on test set\n",
        "    y_prob_test = calibrated_model.predict_proba(X_test)\n",
        "\n",
        "    # Calculate entropy\n",
        "    entropy = calculate_entropy(y_prob_test)\n",
        "    entropy_list.append(entropy)\n",
        "\n",
        "    # Make predictions using the best threshold\n",
        "    y_pred = (y_prob_test[:, 1] >= best_threshold).astype(int)\n",
        "\n",
        "    # Calculate and store ROC AUC\n",
        "    roc_auc = roc_auc_score(y_test, y_prob_test[:, 1])\n",
        "    roc_auc_list.append(roc_auc)\n",
        "\n",
        "    # Store the metrics\n",
        "    f1_list.append(f1_score(y_test, y_pred))\n",
        "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
        "    precision_list.append(precision_score(y_test, y_pred))\n",
        "    recall_list.append(recall_score(y_test, y_pred))\n",
        "    confusion_matrices.append(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    print(f'Best Threshold for Fold {len(best_thresholds)}: {best_threshold}')\n",
        "    print(f'Confusion Matrix for Fold {len(best_thresholds)}:\\n', confusion_matrices[-1])\n",
        "\n",
        "# Calculate mean and standard deviation of each metric\n",
        "mean_accuracy = np.mean(accuracy_list)\n",
        "std_accuracy = np.std(accuracy_list)\n",
        "mean_precision = np.mean(precision_list)\n",
        "std_precision = np.std(precision_list)\n",
        "mean_recall = np.mean(recall_list)\n",
        "std_recall = np.std(recall_list)\n",
        "mean_f1 = np.mean(f1_list)\n",
        "std_f1 = np.std(f1_list)\n",
        "mean_roc_auc = np.mean(roc_auc_list)\n",
        "std_roc_auc = np.std(roc_auc_list)\n",
        "mean_entropy = np.mean(entropy_list)\n",
        "std_entropy = np.std(entropy_list)\n",
        "\n",
        "# Calculate mean confusion matrix\n",
        "mean_conf_matrix = np.mean(confusion_matrices, axis=0).astype(int)\n",
        "\n",
        "# Print the results\n",
        "print('--- Overall Results ---')\n",
        "print('Mean Accuracy:', mean_accuracy)\n",
        "print('Accuracy Std Dev:', std_accuracy)\n",
        "print('Mean Precision:', mean_precision)\n",
        "print('Precision Std Dev:', std_precision)\n",
        "print('Mean Recall:', mean_recall)\n",
        "print('Recall Std Dev:', std_recall)\n",
        "print('Mean F1-score:', mean_f1)\n",
        "print('F1-score Std Dev:', std_f1)\n",
        "print('Mean ROC AUC:', mean_roc_auc)\n",
        "print('ROC AUC Std Dev:', std_roc_auc)\n",
        "print('Mean Entropy:', mean_entropy)\n",
        "print('Entropy Std Dev:', std_entropy)\n",
        "print('Mean Confusion Matrix:\\n', mean_conf_matrix)"
      ],
      "metadata": {
        "id": "uD_8hPlqWRPe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}