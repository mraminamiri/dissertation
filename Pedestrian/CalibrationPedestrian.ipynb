{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-08T14:49:47.859200Z",
     "start_time": "2024-09-08T14:49:47.636640Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:49:51.133369Z",
     "start_time": "2024-09-08T14:49:50.967260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('final_with_covid_AS.csv')\n",
    "data.head()"
   ],
   "id": "f22ed627134f6712",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CountCases  BedDys  BeddystoCC  Severity  DiedCases  DiedBdDys  Hsptlsns  \\\n",
       "0          17     133    7.823529        75          4          9        13   \n",
       "1          13     372   28.615385        63          4         34         9   \n",
       "2           8     106   13.250000        48          4         13         4   \n",
       "3          45     218    4.844444       153          3         24        42   \n",
       "4          24     238    9.916667        90          3          8        21   \n",
       "\n",
       "   April  August  December  ...  Y2013  Y2014  Y2015  Y2016  Y2017  Y2018  \\\n",
       "0      0       0         0  ...      1      0      0      0      0      0   \n",
       "1      0       0         0  ...      0      0      0      0      0      0   \n",
       "2      0       0         0  ...      0      0      0      0      0      1   \n",
       "3      0       0         0  ...      0      0      0      1      0      0   \n",
       "4      0       1         0  ...      1      0      0      0      0      0   \n",
       "\n",
       "   Y2019  Y2020  Y2021  CovidPrd  \n",
       "0      0      0      0         0  \n",
       "1      0      0      0         0  \n",
       "2      0      0      0         0  \n",
       "3      0      0      0         0  \n",
       "4      0      0      0         0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountCases</th>\n",
       "      <th>BedDys</th>\n",
       "      <th>BeddystoCC</th>\n",
       "      <th>Severity</th>\n",
       "      <th>DiedCases</th>\n",
       "      <th>DiedBdDys</th>\n",
       "      <th>Hsptlsns</th>\n",
       "      <th>April</th>\n",
       "      <th>August</th>\n",
       "      <th>December</th>\n",
       "      <th>...</th>\n",
       "      <th>Y2013</th>\n",
       "      <th>Y2014</th>\n",
       "      <th>Y2015</th>\n",
       "      <th>Y2016</th>\n",
       "      <th>Y2017</th>\n",
       "      <th>Y2018</th>\n",
       "      <th>Y2019</th>\n",
       "      <th>Y2020</th>\n",
       "      <th>Y2021</th>\n",
       "      <th>CovidPrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>133</td>\n",
       "      <td>7.823529</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>372</td>\n",
       "      <td>28.615385</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>218</td>\n",
       "      <td>4.844444</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>238</td>\n",
       "      <td>9.916667</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:49:55.927408Z",
     "start_time": "2024-09-08T14:49:55.913436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filtered_data5 = data[data['Pedestrian'] == 1]\n",
    "filtered_data5.info()"
   ],
   "id": "94f0a753b54ff83e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6086 entries, 0 to 54037\n",
      "Data columns (total 58 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CountCases       6086 non-null   int64  \n",
      " 1   BedDys           6086 non-null   int64  \n",
      " 2   BeddystoCC       6086 non-null   float64\n",
      " 3   Severity         6086 non-null   int64  \n",
      " 4   DiedCases        6086 non-null   int64  \n",
      " 5   DiedBdDys        6086 non-null   int64  \n",
      " 6   Hsptlsns         6086 non-null   int64  \n",
      " 7   April            6086 non-null   int64  \n",
      " 8   August           6086 non-null   int64  \n",
      " 9   December         6086 non-null   int64  \n",
      " 10  February         6086 non-null   int64  \n",
      " 11  January          6086 non-null   int64  \n",
      " 12  July             6086 non-null   int64  \n",
      " 13  June             6086 non-null   int64  \n",
      " 14  March            6086 non-null   int64  \n",
      " 15  May              6086 non-null   int64  \n",
      " 16  November         6086 non-null   int64  \n",
      " 17  October          6086 non-null   int64  \n",
      " 18  September        6086 non-null   int64  \n",
      " 19  MajorCities      6086 non-null   int64  \n",
      " 20  Regional         6086 non-null   int64  \n",
      " 21  Female           6086 non-null   int64  \n",
      " 22  Male             6086 non-null   int64  \n",
      " 23  Age07            6086 non-null   int64  \n",
      " 24  Age816           6086 non-null   int64  \n",
      " 25  Age1725          6086 non-null   int64  \n",
      " 26  Age2639          6086 non-null   int64  \n",
      " 27  Age4064          6086 non-null   int64  \n",
      " 28  Age6574          6086 non-null   int64  \n",
      " 29  Age75plus        6086 non-null   int64  \n",
      " 30  CarDriver        6086 non-null   int64  \n",
      " 31  CarPngr          6086 non-null   int64  \n",
      " 32  Mtrcyclist       6086 non-null   int64  \n",
      " 33  PdlCyclist       6086 non-null   int64  \n",
      " 34  Pedestrian       6086 non-null   int64  \n",
      " 35  Cntrprt23WldMV   6086 non-null   int64  \n",
      " 36  CntrprtCrTrkVn   6086 non-null   int64  \n",
      " 37  CntrprtFxdStnry  6086 non-null   int64  \n",
      " 38  CntrprtHvyVhcl   6086 non-null   int64  \n",
      " 39  CntrprtNClsn     6086 non-null   int64  \n",
      " 40  CntrprtNA        6086 non-null   int64  \n",
      " 41  CntrprtOther     6086 non-null   int64  \n",
      " 42  CntrprtNMV       6086 non-null   int64  \n",
      " 43  CntrprtPdlC      6086 non-null   int64  \n",
      " 44  CntrprtPdstAnml  6086 non-null   int64  \n",
      " 45  CntrprtTrn       6086 non-null   int64  \n",
      " 46  Y2011            6086 non-null   int64  \n",
      " 47  Y2012            6086 non-null   int64  \n",
      " 48  Y2013            6086 non-null   int64  \n",
      " 49  Y2014            6086 non-null   int64  \n",
      " 50  Y2015            6086 non-null   int64  \n",
      " 51  Y2016            6086 non-null   int64  \n",
      " 52  Y2017            6086 non-null   int64  \n",
      " 53  Y2018            6086 non-null   int64  \n",
      " 54  Y2019            6086 non-null   int64  \n",
      " 55  Y2020            6086 non-null   int64  \n",
      " 56  Y2021            6086 non-null   int64  \n",
      " 57  CovidPrd         6086 non-null   int64  \n",
      "dtypes: float64(1), int64(57)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:50:02.255357Z",
     "start_time": "2024-09-08T14:50:02.245490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_bins = 2\n",
    "\n",
    "bed_days_min = filtered_data5['Severity'].min()\n",
    "bed_days_max = filtered_data5['Severity'].max()\n",
    "\n",
    "bin_width = (bed_days_max - bed_days_min) / num_bins\n",
    "bins = [bed_days_min + i * bin_width for i in range(num_bins + 1)]\n",
    "\n",
    "def bin_function(x):\n",
    "    for i in range(1, len(bins)):\n",
    "        if x <= bins[i]:\n",
    "            return i - 1\n",
    "    return i\n",
    "\n",
    "filtered_data5['Bed_days_category'] = filtered_data5['Severity'].apply(bin_function)"
   ],
   "id": "47845136ef0f7da7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3l/xh28kn0j7_7d5hh7fgz188940000gn/T/ipykernel_1789/2563099148.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data5['Bed_days_category'] = filtered_data5['Severity'].apply(bin_function)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:50:06.828662Z",
     "start_time": "2024-09-08T14:50:06.798155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X = filtered_data5[['Age1725','Age2639','Age4064','Age6574','Age75plus',\n",
    "                   \n",
    "                   'Male','Female',\n",
    "                   \n",
    "                   'Regional','MajorCities',\n",
    "\n",
    "                   'April','December','February','January','July',\n",
    "                   'June','March','May','November','October','September',\n",
    "\n",
    "                   'Cntrprt23WldMV','CntrprtFxdStnry','CntrprtHvyVhcl',\n",
    "                   'CntrprtNClsn','CntrprtOther','CntrprtNMV','CntrprtCrTrkVn',\n",
    "                   'CntrprtPdlC','CntrprtPdstAnml','CntrprtTrn',\n",
    "\n",
    "                   'Y2014','Y2015','Y2016','Y2017','Y2018','Y2019','Y2020','Y2021',\n",
    "                   'Y2013','Y2012',\n",
    "                   'CovidPrd']]\n",
    "\n",
    "\n",
    "\n",
    "y = filtered_data5['Bed_days_category']"
   ],
   "id": "db8ca3f154e8ea0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "XGBOOST ",
   "id": "80e56b9430f5a6d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:50:35.566850Z",
     "start_time": "2024-09-08T14:50:29.868287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_after = []\n",
    "precision_list_after = []\n",
    "recall_list_after = []\n",
    "f1_list_after = []\n",
    "entropy_list_after = []\n",
    "confusion_matrices_after = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    xgb_model = XGBClassifier(random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before calibration\n",
    "    y_pred_before = xgb_model.predict(X_test)\n",
    "    y_prob_before = xgb_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before calibration\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before calibration\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Calibrate the model\n",
    "    calibrated_model = CalibratedClassifierCV(xgb_model, method='isotonic', cv=5)\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities after calibration\n",
    "    y_pred_after = calibrated_model.predict(X_test)\n",
    "    y_prob_after = calibrated_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after calibration\n",
    "    entropy_after = calculate_entropy(y_prob_after)\n",
    "    entropy_list_after.append(entropy_after)\n",
    "    \n",
    "    # Store metrics after calibration\n",
    "    accuracy_list_after.append(accuracy_score(y_test, y_pred_after))\n",
    "    precision_list_after.append(precision_score(y_test, y_pred_after))\n",
    "    recall_list_after.append(recall_score(y_test, y_pred_after))\n",
    "    f1_list_after.append(f1_score(y_test, y_pred_after))\n",
    "    confusion_matrices_after.append(confusion_matrix(y_test, y_pred_after))\n",
    "    \n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Calibration:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_after)} After Calibration:\\n', confusion_matrices_after[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before calibration\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after calibration\n",
    "mean_accuracy_after = np.mean(accuracy_list_after)\n",
    "std_accuracy_after = np.std(accuracy_list_after)\n",
    "mean_precision_after = np.mean(precision_list_after)\n",
    "std_precision_after = np.std(precision_list_after)\n",
    "mean_recall_after = np.mean(recall_list_after)\n",
    "std_recall_after = np.std(recall_list_after)\n",
    "mean_f1_after = np.mean(f1_list_after)\n",
    "std_f1_after = np.std(f1_list_after)\n",
    "mean_entropy_after = np.mean(entropy_list_after)\n",
    "std_entropy_after = np.std(entropy_list_after)\n",
    "\n",
    "# Calculate mean confusion matrix before and after calibration\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0).astype(int)\n",
    "mean_conf_matrix_after = np.mean(confusion_matrices_after, axis=0).astype(int)\n",
    "\n",
    "# Print results before calibration\n",
    "print('--- Before Calibration ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after calibration\n",
    "print('--- After Calibration ---')\n",
    "print('Mean Accuracy:', mean_accuracy_after)\n",
    "print('Accuracy Std Dev:', std_accuracy_after)\n",
    "print('Mean Precision:', mean_precision_after)\n",
    "print('Precision Std Dev:', std_precision_after)\n",
    "print('Mean Recall:', mean_recall_after)\n",
    "print('Recall Std Dev:', std_recall_after)\n",
    "print('Mean F1-score:', mean_f1_after)\n",
    "print('F1-score Std Dev:', std_f1_after)\n",
    "print('Mean Entropy:', mean_entropy_after)\n",
    "print('Entropy Std Dev:', std_entropy_after)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_after)\n"
   ],
   "id": "e50f4097164bb739",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Calibration:\n",
      " [[588   6]\n",
      " [  9   6]]\n",
      "Confusion Matrix for Fold 1 After Calibration:\n",
      " [[559  35]\n",
      " [  1  14]]\n",
      "Confusion Matrix for Fold 2 Before Calibration:\n",
      " [[589   5]\n",
      " [ 10   5]]\n",
      "Confusion Matrix for Fold 2 After Calibration:\n",
      " [[562  32]\n",
      " [  4  11]]\n",
      "Confusion Matrix for Fold 3 Before Calibration:\n",
      " [[589   6]\n",
      " [  9   5]]\n",
      "Confusion Matrix for Fold 3 After Calibration:\n",
      " [[548  47]\n",
      " [  2  12]]\n",
      "Confusion Matrix for Fold 4 Before Calibration:\n",
      " [[589   6]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 4 After Calibration:\n",
      " [[563  32]\n",
      " [  4  10]]\n",
      "Confusion Matrix for Fold 5 Before Calibration:\n",
      " [[591   4]\n",
      " [  7   7]]\n",
      "Confusion Matrix for Fold 5 After Calibration:\n",
      " [[556  39]\n",
      " [  1  13]]\n",
      "Confusion Matrix for Fold 6 Before Calibration:\n",
      " [[590   5]\n",
      " [ 10   4]]\n",
      "Confusion Matrix for Fold 6 After Calibration:\n",
      " [[560  35]\n",
      " [  3  11]]\n",
      "Confusion Matrix for Fold 7 Before Calibration:\n",
      " [[593   1]\n",
      " [ 10   4]]\n",
      "Confusion Matrix for Fold 7 After Calibration:\n",
      " [[577  17]\n",
      " [  3  11]]\n",
      "Confusion Matrix for Fold 8 Before Calibration:\n",
      " [[590   4]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 8 After Calibration:\n",
      " [[567  27]\n",
      " [  1  13]]\n",
      "Confusion Matrix for Fold 9 Before Calibration:\n",
      " [[590   4]\n",
      " [  8   6]]\n",
      "Confusion Matrix for Fold 9 After Calibration:\n",
      " [[557  37]\n",
      " [  3  11]]\n",
      "Confusion Matrix for Fold 10 Before Calibration:\n",
      " [[589   5]\n",
      " [ 12   2]]\n",
      "Confusion Matrix for Fold 10 After Calibration:\n",
      " [[554  40]\n",
      " [  0  14]]\n",
      "--- Before Calibration ---\n",
      "Mean Accuracy: 0.9765040294702272\n",
      "Accuracy Std Dev: 0.003447361594167791\n",
      "Mean Precision: 0.49829725829725824\n",
      "Precision Std Dev: 0.14230838676123778\n",
      "Mean Recall: 0.31619047619047613\n",
      "Recall Std Dev: 0.10396231656377287\n",
      "Mean F1-score: 0.3810383204387781\n",
      "F1-score Std Dev: 0.10651944205297986\n",
      "Mean Entropy: 0.041516528\n",
      "Entropy Std Dev: 0.006146592\n",
      "Mean Confusion Matrix:\n",
      " [[589   4]\n",
      " [  9   4]]\n",
      "--- After Calibration ---\n",
      "Mean Accuracy: 0.940359519488376\n",
      "Accuracy Std Dev: 0.012058005472099013\n",
      "Mean Precision: 0.2678426811372048\n",
      "Precision Std Dev: 0.05206822753539239\n",
      "Mean Recall: 0.8452380952380952\n",
      "Recall Std Dev: 0.09275941132856912\n",
      "Mean F1-score: 0.40352208067149525\n",
      "F1-score Std Dev: 0.05823653599122225\n",
      "Mean Entropy: 0.07694854285263059\n",
      "Entropy Std Dev: 0.009761868446005028\n",
      "Mean Confusion Matrix:\n",
      " [[560  34]\n",
      " [  2  12]]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LOGESTIC REGRESSION",
   "id": "a35daf43ca3401ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:51:05.551273Z",
     "start_time": "2024-09-08T14:51:02.509646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    # Add a small constant to avoid log(0)\n",
    "    epsilon = 1e-10\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_after = []\n",
    "precision_list_after = []\n",
    "recall_list_after = []\n",
    "f1_list_after = []\n",
    "entropy_list_after = []\n",
    "confusion_matrices_after = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    lr_model = LogisticRegression( random_state=42)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities and classes before calibration\n",
    "    y_pred_lr_before = lr_model.predict(X_test)\n",
    "    y_prob_lr_before = lr_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate metrics and entropy before calibration\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_lr_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_lr_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_lr_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_lr_before))\n",
    "    entropy_list_before.append(calculate_entropy(y_prob_lr_before))\n",
    "    conf_matrix_before = confusion_matrix(y_test, y_pred_lr_before)\n",
    "    confusion_matrices_before.append(conf_matrix_before)\n",
    "\n",
    "    # Calibrate the model\n",
    "    calibrated_model = CalibratedClassifierCV(lr_model, method='isotonic', cv=5)\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities and classes after calibration\n",
    "    y_pred_lr_after = calibrated_model.predict(X_test)\n",
    "    y_prob_lr_after = calibrated_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate metrics and entropy after calibration\n",
    "    accuracy_list_after.append(accuracy_score(y_test, y_pred_lr_after))\n",
    "    precision_list_after.append(precision_score(y_test, y_pred_lr_after))\n",
    "    recall_list_after.append(recall_score(y_test, y_pred_lr_after))\n",
    "    f1_list_after.append(f1_score(y_test, y_pred_lr_after))\n",
    "    entropy_list_after.append(calculate_entropy(y_prob_lr_after))\n",
    "    conf_matrix_after = confusion_matrix(y_test, y_pred_lr_after)\n",
    "    confusion_matrices_after.append(conf_matrix_after)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before calibration\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after calibration\n",
    "mean_accuracy_after = np.mean(accuracy_list_after)\n",
    "std_accuracy_after = np.std(accuracy_list_after)\n",
    "mean_precision_after = np.mean(precision_list_after)\n",
    "std_precision_after = np.std(precision_list_after)\n",
    "mean_recall_after = np.mean(recall_list_after)\n",
    "std_recall_after = np.std(recall_list_after)\n",
    "mean_f1_after = np.mean(f1_list_after)\n",
    "std_f1_after = np.std(f1_list_after)\n",
    "mean_entropy_after = np.mean(entropy_list_after)\n",
    "std_entropy_after = np.std(entropy_list_after)\n",
    "\n",
    "# Calculate mean confusion matrix\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_after = np.mean(confusion_matrices_after, axis=0)\n",
    "\n",
    "# Print results before calibration\n",
    "print('--- Before Calibration ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after calibration\n",
    "print('--- After Calibration ---')\n",
    "print('Mean Accuracy:', mean_accuracy_after)\n",
    "print('Accuracy Std Dev:', std_accuracy_after)\n",
    "print('Mean Precision:', mean_precision_after)\n",
    "print('Precision Std Dev:', std_precision_after)\n",
    "print('Mean Recall:', mean_recall_after)\n",
    "print('Recall Std Dev:', std_recall_after)\n",
    "print('Mean F1-score:', mean_f1_after)\n",
    "print('F1-score Std Dev:', std_f1_after)\n",
    "print('Mean Entropy:', mean_entropy_after)\n",
    "print('Entropy Std Dev:', std_entropy_after)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_after)\n"
   ],
   "id": "785247638f4547a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Before Calibration ---\n",
      "Mean Accuracy: 0.9779834824129289\n",
      "Accuracy Std Dev: 0.0030389206233644626\n",
      "Mean Precision: 0.635\n",
      "Precision Std Dev: 0.24601829200285086\n",
      "Mean Recall: 0.16904761904761903\n",
      "Recall Std Dev: 0.05675463360267732\n",
      "Mean F1-score: 0.2639654282765738\n",
      "F1-score Std Dev: 0.08924722989889335\n",
      "Mean Entropy: 0.06300401274992593\n",
      "Entropy Std Dev: 0.006996756113089446\n",
      "Mean Confusion Matrix:\n",
      " [[592.8   1.6]\n",
      " [ 11.8   2.4]]\n",
      "--- After Calibration ---\n",
      "Mean Accuracy: 0.9489035087719297\n",
      "Accuracy Std Dev: 0.010611826236157222\n",
      "Mean Precision: 0.29387000125253354\n",
      "Precision Std Dev: 0.040667327418147735\n",
      "Mean Recall: 0.8114285714285714\n",
      "Recall Std Dev: 0.1401036221634211\n",
      "Mean F1-score: 0.42744053369845664\n",
      "F1-score Std Dev: 0.049453266793939125\n",
      "Mean Entropy: 0.07376303097782226\n",
      "Entropy Std Dev: 0.0112579349823056\n",
      "Mean Confusion Matrix:\n",
      " [[566.   28.4]\n",
      " [  2.7  11.5]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Decesion tree",
   "id": "ab357d9f904c675c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:51:48.614444Z",
     "start_time": "2024-09-08T14:51:47.957875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    # Add a small constant to avoid log(0)\n",
    "    epsilon = 1e-10\n",
    "    probabilities = np.clip(probabilities, epsilon, 1 - epsilon)\n",
    "    entropy = -np.sum(probabilities * np.log(probabilities), axis=1)\n",
    "    return np.mean(entropy)\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_after = []\n",
    "precision_list_after = []\n",
    "recall_list_after = []\n",
    "f1_list_after = []\n",
    "entropy_list_after = []\n",
    "confusion_matrices_after = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    dt_model = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities and classes before calibration\n",
    "    y_pred_dt_before = dt_model.predict(X_test)\n",
    "    y_prob_dt_before = dt_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate metrics and entropy before calibration\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_dt_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_dt_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_dt_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_dt_before))\n",
    "    entropy_list_before.append(calculate_entropy(y_prob_dt_before))\n",
    "    conf_matrix_before = confusion_matrix(y_test, y_pred_dt_before)\n",
    "    confusion_matrices_before.append(conf_matrix_before)\n",
    "\n",
    "    # Calibrate the model\n",
    "    calibrated_model = CalibratedClassifierCV(dt_model, method='sigmoid', cv=5)\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities and classes after calibration\n",
    "    y_pred_dt_after = calibrated_model.predict(X_test)\n",
    "    y_prob_dt_after = calibrated_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate metrics and entropy after calibration\n",
    "    accuracy_list_after.append(accuracy_score(y_test, y_pred_dt_after))\n",
    "    precision_list_after.append(precision_score(y_test, y_pred_dt_after))\n",
    "    recall_list_after.append(recall_score(y_test, y_pred_dt_after))\n",
    "    f1_list_after.append(f1_score(y_test, y_pred_dt_after))\n",
    "    entropy_list_after.append(calculate_entropy(y_prob_dt_after))\n",
    "    conf_matrix_after = confusion_matrix(y_test, y_pred_dt_after)\n",
    "    confusion_matrices_after.append(conf_matrix_after)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before calibration\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after calibration\n",
    "mean_accuracy_after = np.mean(accuracy_list_after)\n",
    "std_accuracy_after = np.std(accuracy_list_after)\n",
    "mean_precision_after = np.mean(precision_list_after)\n",
    "std_precision_after = np.std(precision_list_after)\n",
    "mean_recall_after = np.mean(recall_list_after)\n",
    "std_recall_after = np.std(recall_list_after)\n",
    "mean_f1_after = np.mean(f1_list_after)\n",
    "std_f1_after = np.std(f1_list_after)\n",
    "mean_entropy_after = np.mean(entropy_list_after)\n",
    "std_entropy_after = np.std(entropy_list_after)\n",
    "\n",
    "# Calculate mean confusion matrix\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_after = np.mean(confusion_matrices_after, axis=0)\n",
    "\n",
    "# Print results before calibration\n",
    "print('--- Before Calibration ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after calibration\n",
    "print('--- After Calibration ---')\n",
    "print('Mean Accuracy:', mean_accuracy_after)\n",
    "print('Accuracy Std Dev:', std_accuracy_after)\n",
    "print('Mean Precision:', mean_precision_after)\n",
    "print('Precision Std Dev:', std_precision_after)\n",
    "print('Mean Recall:', mean_recall_after)\n",
    "print('Recall Std Dev:', std_recall_after)\n",
    "print('Mean F1-score:', mean_f1_after)\n",
    "print('F1-score Std Dev:', std_f1_after)\n",
    "print('Mean Entropy:', mean_entropy_after)\n",
    "print('Entropy Std Dev:', std_entropy_after)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_after)\n"
   ],
   "id": "6e0bbaaf209a3f4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Before Calibration ---\n",
      "Mean Accuracy: 0.9585944926972603\n",
      "Accuracy Std Dev: 0.0063466078813425595\n",
      "Mean Precision: 0.24191049213695784\n",
      "Precision Std Dev: 0.08780561767811022\n",
      "Mean Recall: 0.3823809523809524\n",
      "Recall Std Dev: 0.1568113386154437\n",
      "Mean F1-score: 0.2944889825318099\n",
      "F1-score Std Dev: 0.11203786307282336\n",
      "Mean Entropy: 0.00011381967321849379\n",
      "Entropy Std Dev: 0.0003414518119001775\n",
      "Mean Confusion Matrix:\n",
      " [[578.   16.4]\n",
      " [  8.8   5.4]]\n",
      "--- After Calibration ---\n",
      "Mean Accuracy: 0.967305116238873\n",
      "Accuracy Std Dev: 0.006614767399376076\n",
      "Mean Precision: 0.25885836385836386\n",
      "Precision Std Dev: 0.09030461986789384\n",
      "Mean Recall: 0.19047619047619047\n",
      "Recall Std Dev: 0.07893853632419848\n",
      "Mean F1-score: 0.21168939586559726\n",
      "F1-score Std Dev: 0.07399199186998086\n",
      "Mean Entropy: 0.10529170942451253\n",
      "Entropy Std Dev: 0.0055936844393046055\n",
      "Mean Confusion Matrix:\n",
      " [[586.    8.4]\n",
      " [ 11.5   2.7]]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SVM",
   "id": "1ae36b0f1891422f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:52:59.480998Z",
     "start_time": "2024-09-08T14:52:09.893685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10\n",
    "    probabilities = np.clip(probabilities, epsilon, 1 - epsilon)\n",
    "    entropy = -np.sum(probabilities * np.log(probabilities), axis=1)\n",
    "    return np.mean(entropy)\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_after = []\n",
    "precision_list_after = []\n",
    "recall_list_after = []\n",
    "f1_list_after = []\n",
    "entropy_list_after = []\n",
    "confusion_matrices_after = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # 1. Fit the base SVM model\n",
    "    svm_model = SVC(probability=True, random_state=42)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 2. Predict before calibration\n",
    "    y_pred_before = svm_model.predict(X_test)\n",
    "    y_prob_before = svm_model.predict_proba(X_test)\n",
    "    \n",
    "    # 3. Calculate entropy before calibration\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # 4. Store metrics before calibration\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    conf_matrix_before = confusion_matrix(y_test, y_pred_before)\n",
    "    confusion_matrices_before.append(conf_matrix_before)\n",
    "    \n",
    "    # 5. Calibrate the model\n",
    "    calibrated_model = CalibratedClassifierCV(svm_model, method='isotonic', cv=5)\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 6. Predict with the calibrated model\n",
    "    y_pred_after = calibrated_model.predict(X_test)\n",
    "    y_prob_after = calibrated_model.predict_proba(X_test)\n",
    "    \n",
    "    # 7. Calculate entropy after calibration\n",
    "    entropy_after = calculate_entropy(y_prob_after)\n",
    "    entropy_list_after.append(entropy_after)\n",
    "    \n",
    "    # 8. Store metrics after calibration\n",
    "    accuracy_list_after.append(accuracy_score(y_test, y_pred_after))\n",
    "    precision_list_after.append(precision_score(y_test, y_pred_after))\n",
    "    recall_list_after.append(recall_score(y_test, y_pred_after))\n",
    "    f1_list_after.append(f1_score(y_test, y_pred_after))\n",
    "    conf_matrix_after = confusion_matrix(y_test, y_pred_after)\n",
    "    confusion_matrices_after.append(conf_matrix_after)\n",
    "\n",
    "# Calculate mean and standard deviation for each metric before calibration\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "\n",
    "# Calculate mean and standard deviation for each metric after calibration\n",
    "mean_accuracy_after = np.mean(accuracy_list_after)\n",
    "std_accuracy_after = np.std(accuracy_list_after)\n",
    "mean_precision_after = np.mean(precision_list_after)\n",
    "std_precision_after = np.std(precision_list_after)\n",
    "mean_recall_after = np.mean(recall_list_after)\n",
    "std_recall_after = np.std(recall_list_after)\n",
    "mean_f1_after = np.mean(f1_list_after)\n",
    "std_f1_after = np.std(f1_list_after)\n",
    "mean_entropy_after = np.mean(entropy_list_after)\n",
    "std_entropy_after = np.std(entropy_list_after)\n",
    "mean_conf_matrix_after = np.mean(confusion_matrices_after, axis=0)\n",
    "\n",
    "# Print results\n",
    "print('Before Calibration:')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "print('\\nAfter Calibration:')\n",
    "print('Mean Accuracy:', mean_accuracy_after)\n",
    "print('Accuracy Std Dev:', std_accuracy_after)\n",
    "print('Mean Precision:', mean_precision_after)\n",
    "print('Precision Std Dev:', std_precision_after)\n",
    "print('Mean Recall:', mean_recall_after)\n",
    "print('Recall Std Dev:', std_recall_after)\n",
    "print('Mean F1-score:', mean_f1_after)\n",
    "print('F1-score Std Dev:', std_f1_after)\n",
    "print('Mean Entropy:', mean_entropy_after)\n",
    "print('Entropy Std Dev:', std_entropy_after)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_after)\n"
   ],
   "id": "6059ac44c245b7da",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Calibration:\n",
      "Mean Accuracy: 0.9766679630109756\n",
      "Accuracy Std Dev: 0.0006494725957168835\n",
      "Mean Precision: 0.1\n",
      "Precision Std Dev: 0.30000000000000004\n",
      "Mean Recall: 0.006666666666666666\n",
      "Recall Std Dev: 0.019999999999999997\n",
      "Mean F1-score: 0.0125\n",
      "F1-score Std Dev: 0.037500000000000006\n",
      "Mean Entropy: 0.06044797924420733\n",
      "Entropy Std Dev: 0.005635930448642147\n",
      "Mean Confusion Matrix:\n",
      " [[5.943e+02 1.000e-01]\n",
      " [1.410e+01 1.000e-01]]\n",
      "\n",
      "After Calibration:\n",
      "Mean Accuracy: 0.9748614532019703\n",
      "Accuracy Std Dev: 0.00440460704861612\n",
      "Mean Precision: 0.46669483294483294\n",
      "Precision Std Dev: 0.08997496075277017\n",
      "Mean Recall: 0.4519047619047619\n",
      "Recall Std Dev: 0.11813843296067385\n",
      "Mean F1-score: 0.4531230177293649\n",
      "F1-score Std Dev: 0.0888240714113978\n",
      "Mean Entropy: 0.08065474265273423\n",
      "Entropy Std Dev: 0.008542996495389935\n",
      "Mean Confusion Matrix:\n",
      " [[586.9   7.5]\n",
      " [  7.8   6.4]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Random Forest",
   "id": "d0f718598bc4bc8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:54:28.725369Z",
     "start_time": "2024-09-08T14:54:17.978316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10\n",
    "    probabilities = np.clip(probabilities, epsilon, 1 - epsilon)\n",
    "    entropy = -np.sum(probabilities * np.log(probabilities), axis=1)\n",
    "    return np.mean(entropy)\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_after = []\n",
    "precision_list_after = []\n",
    "recall_list_after = []\n",
    "f1_list_after = []\n",
    "entropy_list_after = []\n",
    "confusion_matrices_after = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # 1. Fit the base Random Forest model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 2. Predict before calibration\n",
    "    y_pred_before = rf_model.predict(X_test)\n",
    "    y_prob_before = rf_model.predict_proba(X_test)\n",
    "    \n",
    "    # 3. Calculate entropy before calibration\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # 4. Store metrics before calibration\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    conf_matrix_before = confusion_matrix(y_test, y_pred_before)\n",
    "    confusion_matrices_before.append(conf_matrix_before)\n",
    "    \n",
    "    # 5. Calibrate the model\n",
    "    calibrated_model = CalibratedClassifierCV(rf_model, method='isotonic', cv=5)\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 6. Predict with the calibrated model\n",
    "    y_pred_after = calibrated_model.predict(X_test)\n",
    "    y_prob_after = calibrated_model.predict_proba(X_test)\n",
    "    \n",
    "    # 7. Calculate entropy after calibration\n",
    "    entropy_after = calculate_entropy(y_prob_after)\n",
    "    entropy_list_after.append(entropy_after)\n",
    "    \n",
    "    # 8. Store metrics after calibration\n",
    "    accuracy_list_after.append(accuracy_score(y_test, y_pred_after))\n",
    "    precision_list_after.append(precision_score(y_test, y_pred_after))\n",
    "    recall_list_after.append(recall_score(y_test, y_pred_after))\n",
    "    f1_list_after.append(f1_score(y_test, y_pred_after))\n",
    "    conf_matrix_after = confusion_matrix(y_test, y_pred_after)\n",
    "    confusion_matrices_after.append(conf_matrix_after)\n",
    "\n",
    "# Calculate mean and standard deviation for each metric before calibration\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "\n",
    "# Calculate mean and standard deviation for each metric after calibration\n",
    "mean_accuracy_after = np.mean(accuracy_list_after)\n",
    "std_accuracy_after = np.std(accuracy_list_after)\n",
    "mean_precision_after = np.mean(precision_list_after)\n",
    "std_precision_after = np.std(precision_list_after)\n",
    "mean_recall_after = np.mean(recall_list_after)\n",
    "std_recall_after = np.std(recall_list_after)\n",
    "mean_f1_after = np.mean(f1_list_after)\n",
    "std_f1_after = np.std(f1_list_after)\n",
    "mean_entropy_after = np.mean(entropy_list_after)\n",
    "std_entropy_after = np.std(entropy_list_after)\n",
    "mean_conf_matrix_after = np.mean(confusion_matrices_after, axis=0)\n",
    "\n",
    "# Print results\n",
    "print('Before Calibration:')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "print('\\nAfter Calibration:')\n",
    "print('Mean Accuracy:', mean_accuracy_after)\n",
    "print('Accuracy Std Dev:', std_accuracy_after)\n",
    "print('Mean Precision:', mean_precision_after)\n",
    "print('Precision Std Dev:', std_precision_after)\n",
    "print('Mean Recall:', mean_recall_after)\n",
    "print('Recall Std Dev:', std_recall_after)\n",
    "print('Mean F1-score:', mean_f1_after)\n",
    "print('F1-score Std Dev:', std_f1_after)\n",
    "print('Mean Entropy:', mean_entropy_after)\n",
    "print('Entropy Std Dev:', std_entropy_after)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_after)\n"
   ],
   "id": "5366f84aa8ec923f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Calibration:\n",
      "Mean Accuracy: 0.972725725952813\n",
      "Accuracy Std Dev: 0.00320817877381943\n",
      "Mean Precision: 0.36076479076479073\n",
      "Precision Std Dev: 0.13015847739326522\n",
      "Mean Recall: 0.18285714285714286\n",
      "Recall Std Dev: 0.05598833697790121\n",
      "Mean F1-score: 0.23650870935498744\n",
      "F1-score Std Dev: 0.06422719166946961\n",
      "Mean Entropy: 0.05396587023902031\n",
      "Entropy Std Dev: 0.006488147830608763\n",
      "Mean Confusion Matrix:\n",
      " [[589.4   5. ]\n",
      " [ 11.6   2.6]]\n",
      "\n",
      "After Calibration:\n",
      "Mean Accuracy: 0.9571196309739867\n",
      "Accuracy Std Dev: 0.008869473017465086\n",
      "Mean Precision: 0.2816481625570831\n",
      "Precision Std Dev: 0.06809253332524973\n",
      "Mean Recall: 0.5004761904761905\n",
      "Recall Std Dev: 0.09891589225951815\n",
      "Mean F1-score: 0.35618036247654616\n",
      "F1-score Std Dev: 0.07008095706775783\n",
      "Mean Entropy: 0.07455121382496005\n",
      "Entropy Std Dev: 0.008201203273709034\n",
      "Mean Confusion Matrix:\n",
      " [[575.4  19. ]\n",
      " [  7.1   7.1]]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f4ce96f957e6aa27"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
