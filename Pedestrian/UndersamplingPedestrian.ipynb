{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-08T14:34:38.089752Z",
     "start_time": "2024-09-08T14:34:37.869228Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,cohen_kappa_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:34:43.507400Z",
     "start_time": "2024-09-08T14:34:43.342745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('final_with_covid_AS.csv')\n",
    "data.head()"
   ],
   "id": "aab073c252d6df98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CountCases  BedDys  BeddystoCC  Severity  DiedCases  DiedBdDys  Hsptlsns  \\\n",
       "0          17     133    7.823529        75          4          9        13   \n",
       "1          13     372   28.615385        63          4         34         9   \n",
       "2           8     106   13.250000        48          4         13         4   \n",
       "3          45     218    4.844444       153          3         24        42   \n",
       "4          24     238    9.916667        90          3          8        21   \n",
       "\n",
       "   April  August  December  ...  Y2013  Y2014  Y2015  Y2016  Y2017  Y2018  \\\n",
       "0      0       0         0  ...      1      0      0      0      0      0   \n",
       "1      0       0         0  ...      0      0      0      0      0      0   \n",
       "2      0       0         0  ...      0      0      0      0      0      1   \n",
       "3      0       0         0  ...      0      0      0      1      0      0   \n",
       "4      0       1         0  ...      1      0      0      0      0      0   \n",
       "\n",
       "   Y2019  Y2020  Y2021  CovidPrd  \n",
       "0      0      0      0         0  \n",
       "1      0      0      0         0  \n",
       "2      0      0      0         0  \n",
       "3      0      0      0         0  \n",
       "4      0      0      0         0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountCases</th>\n",
       "      <th>BedDys</th>\n",
       "      <th>BeddystoCC</th>\n",
       "      <th>Severity</th>\n",
       "      <th>DiedCases</th>\n",
       "      <th>DiedBdDys</th>\n",
       "      <th>Hsptlsns</th>\n",
       "      <th>April</th>\n",
       "      <th>August</th>\n",
       "      <th>December</th>\n",
       "      <th>...</th>\n",
       "      <th>Y2013</th>\n",
       "      <th>Y2014</th>\n",
       "      <th>Y2015</th>\n",
       "      <th>Y2016</th>\n",
       "      <th>Y2017</th>\n",
       "      <th>Y2018</th>\n",
       "      <th>Y2019</th>\n",
       "      <th>Y2020</th>\n",
       "      <th>Y2021</th>\n",
       "      <th>CovidPrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>133</td>\n",
       "      <td>7.823529</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>372</td>\n",
       "      <td>28.615385</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>218</td>\n",
       "      <td>4.844444</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>238</td>\n",
       "      <td>9.916667</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:35:02.631851Z",
     "start_time": "2024-09-08T14:35:02.618258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filtered_data5 = data[data['Pedestrian'] == 1]\n",
    "filtered_data5.info()"
   ],
   "id": "2fb528df7a0a6b07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6086 entries, 0 to 54037\n",
      "Data columns (total 58 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CountCases       6086 non-null   int64  \n",
      " 1   BedDys           6086 non-null   int64  \n",
      " 2   BeddystoCC       6086 non-null   float64\n",
      " 3   Severity         6086 non-null   int64  \n",
      " 4   DiedCases        6086 non-null   int64  \n",
      " 5   DiedBdDys        6086 non-null   int64  \n",
      " 6   Hsptlsns         6086 non-null   int64  \n",
      " 7   April            6086 non-null   int64  \n",
      " 8   August           6086 non-null   int64  \n",
      " 9   December         6086 non-null   int64  \n",
      " 10  February         6086 non-null   int64  \n",
      " 11  January          6086 non-null   int64  \n",
      " 12  July             6086 non-null   int64  \n",
      " 13  June             6086 non-null   int64  \n",
      " 14  March            6086 non-null   int64  \n",
      " 15  May              6086 non-null   int64  \n",
      " 16  November         6086 non-null   int64  \n",
      " 17  October          6086 non-null   int64  \n",
      " 18  September        6086 non-null   int64  \n",
      " 19  MajorCities      6086 non-null   int64  \n",
      " 20  Regional         6086 non-null   int64  \n",
      " 21  Female           6086 non-null   int64  \n",
      " 22  Male             6086 non-null   int64  \n",
      " 23  Age07            6086 non-null   int64  \n",
      " 24  Age816           6086 non-null   int64  \n",
      " 25  Age1725          6086 non-null   int64  \n",
      " 26  Age2639          6086 non-null   int64  \n",
      " 27  Age4064          6086 non-null   int64  \n",
      " 28  Age6574          6086 non-null   int64  \n",
      " 29  Age75plus        6086 non-null   int64  \n",
      " 30  CarDriver        6086 non-null   int64  \n",
      " 31  CarPngr          6086 non-null   int64  \n",
      " 32  Mtrcyclist       6086 non-null   int64  \n",
      " 33  PdlCyclist       6086 non-null   int64  \n",
      " 34  Pedestrian       6086 non-null   int64  \n",
      " 35  Cntrprt23WldMV   6086 non-null   int64  \n",
      " 36  CntrprtCrTrkVn   6086 non-null   int64  \n",
      " 37  CntrprtFxdStnry  6086 non-null   int64  \n",
      " 38  CntrprtHvyVhcl   6086 non-null   int64  \n",
      " 39  CntrprtNClsn     6086 non-null   int64  \n",
      " 40  CntrprtNA        6086 non-null   int64  \n",
      " 41  CntrprtOther     6086 non-null   int64  \n",
      " 42  CntrprtNMV       6086 non-null   int64  \n",
      " 43  CntrprtPdlC      6086 non-null   int64  \n",
      " 44  CntrprtPdstAnml  6086 non-null   int64  \n",
      " 45  CntrprtTrn       6086 non-null   int64  \n",
      " 46  Y2011            6086 non-null   int64  \n",
      " 47  Y2012            6086 non-null   int64  \n",
      " 48  Y2013            6086 non-null   int64  \n",
      " 49  Y2014            6086 non-null   int64  \n",
      " 50  Y2015            6086 non-null   int64  \n",
      " 51  Y2016            6086 non-null   int64  \n",
      " 52  Y2017            6086 non-null   int64  \n",
      " 53  Y2018            6086 non-null   int64  \n",
      " 54  Y2019            6086 non-null   int64  \n",
      " 55  Y2020            6086 non-null   int64  \n",
      " 56  Y2021            6086 non-null   int64  \n",
      " 57  CovidPrd         6086 non-null   int64  \n",
      "dtypes: float64(1), int64(57)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:35:03.612667Z",
     "start_time": "2024-09-08T14:35:03.600603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_bins = 2\n",
    "\n",
    "bed_days_min = filtered_data5['Severity'].min()\n",
    "bed_days_max = filtered_data5['Severity'].max()\n",
    "\n",
    "bin_width = (bed_days_max - bed_days_min) / num_bins\n",
    "bins = [bed_days_min + i * bin_width for i in range(num_bins + 1)]\n",
    "\n",
    "def bin_function(x):\n",
    "    for i in range(1, len(bins)):\n",
    "        if x <= bins[i]:\n",
    "            return i - 1\n",
    "    return i\n",
    "\n",
    "filtered_data5['Bed_days_category'] = filtered_data5['Severity'].apply(bin_function)"
   ],
   "id": "8ffcf06e964777dd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3l/xh28kn0j7_7d5hh7fgz188940000gn/T/ipykernel_1675/2563099148.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data5['Bed_days_category'] = filtered_data5['Severity'].apply(bin_function)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:35:10.627835Z",
     "start_time": "2024-09-08T14:35:10.622877Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_data5['Bed_days_category'].value_counts()",
   "id": "64164e468d305c40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bed_days_category\n",
       "0    5944\n",
       "1     142\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:35:22.367869Z",
     "start_time": "2024-09-08T14:35:22.321207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X = filtered_data5[['Age1725','Age2639','Age4064','Age6574','Age75plus',\n",
    "                   \n",
    "                   'Male','Female',\n",
    "                   \n",
    "                   'Regional','MajorCities',\n",
    "\n",
    "                   'April','December','February','January','July',\n",
    "                   'June','March','May','November','October','September',\n",
    "\n",
    "                   'Cntrprt23WldMV','CntrprtFxdStnry','CntrprtHvyVhcl',\n",
    "                   'CntrprtNClsn','CntrprtOther','CntrprtNMV','CntrprtCrTrkVn',\n",
    "                   'CntrprtPdlC','CntrprtPdstAnml','CntrprtTrn',\n",
    "\n",
    "                   'Y2014','Y2015','Y2016','Y2017','Y2018','Y2019','Y2020','Y2021',\n",
    "                   'Y2013','Y2012',\n",
    "                   'CovidPrd']]\n",
    "\n",
    "\n",
    "\n",
    "y = filtered_data5['Bed_days_category']"
   ],
   "id": "c78fc2ad858287b2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LogesticRegresiion",
   "id": "d72c35a004034e45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:38:24.429182Z",
     "start_time": "2024-09-08T14:38:11.590767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Logistic Regression model without undersampling\n",
    "    logreg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = logreg_model.predict(X_test)\n",
    "    y_prob_before = logreg_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Logistic Regression model with NearMiss\n",
    "    logreg_model_nearmiss = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    logreg_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = logreg_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = logreg_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Logistic Regression model with ClusterCentroids\n",
    "    logreg_model_clustercentroids = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    logreg_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = logreg_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = logreg_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Logistic Regression model with TomekLinks\n",
    "    logreg_model_tomeklinks = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    logreg_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = logreg_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = logreg_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n"
   ],
   "id": "e6d246bb94b8b570",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[593   1]\n",
      " [ 12   3]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[335 259]\n",
      " [  7   8]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[386 208]\n",
      " [  0  15]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[593   1]\n",
      " [ 12   3]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[592   2]\n",
      " [ 13   2]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[390 204]\n",
      " [  9   6]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[370 224]\n",
      " [  0  15]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[591   3]\n",
      " [ 13   2]]\n",
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[594   1]\n",
      " [ 13   1]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[324 271]\n",
      " [  1  13]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[344 251]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[594   1]\n",
      " [ 12   2]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[591   4]\n",
      " [ 13   1]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[371 224]\n",
      " [  2  12]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[405 190]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[591   4]\n",
      " [ 13   1]]\n",
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[594   1]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[331 264]\n",
      " [  3  11]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[348 247]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[594   1]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[592   3]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[342 253]\n",
      " [  5   9]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[335 260]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[592   3]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[594   0]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[335 259]\n",
      " [  5   9]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[361 233]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[594   0]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[591   3]\n",
      " [ 12   2]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[381 213]\n",
      " [  2  12]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[375 219]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[590   4]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[593   1]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[350 244]\n",
      " [  1  13]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[400 194]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[593   1]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[594   0]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[326 268]\n",
      " [  5   9]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[364 230]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[594   0]\n",
      " [ 11   3]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9779834824129289\n",
      "Accuracy Std Dev: 0.0030389206233644626\n",
      "Mean Precision: 0.635\n",
      "Precision Std Dev: 0.24601829200285086\n",
      "Mean Recall: 0.16904761904761903\n",
      "Recall Std Dev: 0.05675463360267732\n",
      "Mean F1-score: 0.2639654282765738\n",
      "F1-score Std Dev: 0.08924722989889335\n",
      "Mean Entropy: 0.06300401274992593\n",
      "Entropy Std Dev: 0.006996756113089446\n",
      "Mean Confusion Matrix:\n",
      " [[592.8   1.6]\n",
      " [ 11.8   2.4]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.5893859108979345\n",
      "Accuracy Std Dev: 0.036781852000771074\n",
      "Mean Precision: 0.03994972811428811\n",
      "Precision Std Dev: 0.008953365384030415\n",
      "Mean Recall: 0.721904761904762\n",
      "Recall Std Dev: 0.16852299546352717\n",
      "Mean F1-score: 0.07567060297004334\n",
      "F1-score Std Dev: 0.016936985922204616\n",
      "Mean Entropy: 0.5811592133377271\n",
      "Entropy Std Dev: 0.01162962414207834\n",
      "Mean Confusion Matrix:\n",
      " [[348.5 245.9]\n",
      " [  4.   10.2]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.629320067409904\n",
      "Accuracy Std Dev: 0.03659491895561419\n",
      "Mean Precision: 0.059766919752227456\n",
      "Precision Std Dev: 0.006138071749209429\n",
      "Mean Recall: 1.0\n",
      "Recall Std Dev: 0.0\n",
      "Mean F1-score: 0.11272931256227905\n",
      "F1-score Std Dev: 0.010922611744760917\n",
      "Mean Entropy: 0.451346474312725\n",
      "Entropy Std Dev: 0.014851468887555749\n",
      "Mean Confusion Matrix:\n",
      " [[368.8 225.6]\n",
      " [  0.   14.2]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9779834824129289\n",
      "Accuracy Std Dev: 0.0032114718758167924\n",
      "Mean Precision: 0.6445238095238095\n",
      "Precision Std Dev: 0.24728697972221678\n",
      "Mean Recall: 0.1833333333333333\n",
      "Recall Std Dev: 0.04763095089322905\n",
      "Mean F1-score: 0.2814610054548135\n",
      "F1-score Std Dev: 0.07546753829496355\n",
      "Mean Entropy: 0.06384847735387442\n",
      "Entropy Std Dev: 0.007181555695603723\n",
      "Mean Confusion Matrix:\n",
      " [[592.6   1.8]\n",
      " [ 11.6   2.6]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "XGBOOST",
   "id": "46288a79de16dbf9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:39:49.239058Z",
     "start_time": "2024-09-08T14:39:29.820550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the XGBoost model without undersampling\n",
    "    xgb_model = XGBClassifier(random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = xgb_model.predict(X_test)\n",
    "    y_prob_before = xgb_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the XGBoost model with NearMiss\n",
    "    xgb_model_nearmiss = XGBClassifier(random_state=42)\n",
    "    xgb_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = xgb_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = xgb_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the XGBoost model with ClusterCentroids\n",
    "    xgb_model_clustercentroids = XGBClassifier(random_state=42)\n",
    "    xgb_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = xgb_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = xgb_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the XGBoost model with TomekLinks\n",
    "    xgb_model_tomeklinks = XGBClassifier(random_state=42)\n",
    "    xgb_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = xgb_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = xgb_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n"
   ],
   "id": "30f8d9cdd01de8bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[588   6]\n",
      " [  9   6]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[337 257]\n",
      " [  5  10]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[499  95]\n",
      " [  0  15]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[586   8]\n",
      " [  9   6]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[589   5]\n",
      " [ 10   5]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[393 201]\n",
      " [  5  10]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[464 130]\n",
      " [  0  15]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[588   6]\n",
      " [ 10   5]]\n",
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[589   6]\n",
      " [  9   5]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[284 311]\n",
      " [  2  12]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[398 197]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[588   7]\n",
      " [  8   6]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[589   6]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[309 286]\n",
      " [  3  11]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[497  98]\n",
      " [  1  13]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[589   6]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[591   4]\n",
      " [  7   7]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[297 298]\n",
      " [  1  13]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[356 239]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[591   4]\n",
      " [  7   7]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[590   5]\n",
      " [ 10   4]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[327 268]\n",
      " [  5   9]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[338 257]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[590   5]\n",
      " [  9   5]]\n",
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[593   1]\n",
      " [ 10   4]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[334 260]\n",
      " [  4  10]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[352 242]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[593   1]\n",
      " [ 10   4]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[590   4]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[342 252]\n",
      " [  4  10]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[389 205]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[589   5]\n",
      " [  9   5]]\n",
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[590   4]\n",
      " [  8   6]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[337 257]\n",
      " [  4  10]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[471 123]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[589   5]\n",
      " [  7   7]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[589   5]\n",
      " [ 12   2]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[329 265]\n",
      " [  2  12]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[333 261]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[587   7]\n",
      " [ 12   2]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9765040294702272\n",
      "Accuracy Std Dev: 0.003447361594167791\n",
      "Mean Precision: 0.49829725829725824\n",
      "Precision Std Dev: 0.14230838676123778\n",
      "Mean Recall: 0.31619047619047613\n",
      "Recall Std Dev: 0.10396231656377287\n",
      "Mean F1-score: 0.3810383204387781\n",
      "F1-score Std Dev: 0.10651944205297986\n",
      "Mean Entropy: 0.041516528\n",
      "Entropy Std Dev: 0.006146592\n",
      "Mean Confusion Matrix:\n",
      " [[589.8   4.6]\n",
      " [  9.7   4.5]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.5580092472560713\n",
      "Accuracy Std Dev: 0.04499458049890669\n",
      "Mean Precision: 0.03893063652169057\n",
      "Precision Std Dev: 0.003948232034663209\n",
      "Mean Recall: 0.7547619047619047\n",
      "Recall Std Dev: 0.09224462203719293\n",
      "Mean F1-score: 0.0739764305545378\n",
      "F1-score Std Dev: 0.0071861515951800025\n",
      "Mean Entropy: 0.3944993\n",
      "Entropy Std Dev: 0.019973658\n",
      "Mean Confusion Matrix:\n",
      " [[328.9 265.5]\n",
      " [  3.5  10.7]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.696327294529427\n",
      "Accuracy Std Dev: 0.10402461955497355\n",
      "Mean Precision: 0.08019895377981671\n",
      "Precision Std Dev: 0.029898901044760357\n",
      "Mean Recall: 0.9928571428571429\n",
      "Recall Std Dev: 0.02142857142857142\n",
      "Mean F1-score: 0.1469250626585604\n",
      "F1-score Std Dev: 0.050252986094125075\n",
      "Mean Entropy: 0.2427835\n",
      "Entropy Std Dev: 0.01629409\n",
      "Mean Confusion Matrix:\n",
      " [[4.097e+02 1.847e+02]\n",
      " [1.000e-01 1.410e+01]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9760111485610578\n",
      "Accuracy Std Dev: 0.0042317360541701465\n",
      "Mean Precision: 0.491990786990787\n",
      "Precision Std Dev: 0.15115678248132355\n",
      "Mean Recall: 0.3519047619047619\n",
      "Recall Std Dev: 0.10930516478016512\n",
      "Mean F1-score: 0.4030483044577576\n",
      "F1-score Std Dev: 0.1088817153665949\n",
      "Mean Entropy: 0.042135756\n",
      "Entropy Std Dev: 0.0062793717\n",
      "Mean Confusion Matrix:\n",
      " [[589.    5.4]\n",
      " [  9.2   5. ]]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "svm",
   "id": "ba8943e770127a3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:40:44.741059Z",
     "start_time": "2024-09-08T14:40:13.386918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the SVM model without undersampling\n",
    "    svm_model = SVC(probability=True, random_state=42)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = svm_model.predict(X_test)\n",
    "    y_prob_before = svm_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with NearMiss\n",
    "    svm_model_nearmiss = SVC(probability=True, random_state=42)\n",
    "    svm_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = svm_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = svm_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with ClusterCentroids\n",
    "    svm_model_clustercentroids = SVC(probability=True, random_state=42)\n",
    "    svm_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = svm_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = svm_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with TomekLinks\n",
    "    svm_model_tomeklinks = SVC(probability=True, random_state=42)\n",
    "    svm_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = svm_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = svm_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n"
   ],
   "id": "65c60ab8a13ad031",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[594   0]\n",
      " [ 15   0]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[249 345]\n",
      " [  6   9]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[169 425]\n",
      " [  0  15]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[594   0]\n",
      " [ 15   0]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[594   0]\n",
      " [ 14   1]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[354 240]\n",
      " [ 10   5]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[244 350]\n",
      " [  0  15]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[593   1]\n",
      " [ 13   2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[595   0]\n",
      " [ 14   0]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[199 396]\n",
      " [  2  12]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[204 391]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[595   0]\n",
      " [ 14   0]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[594   1]\n",
      " [ 14   0]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[277 318]\n",
      " [  5   9]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[179 416]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[592   3]\n",
      " [ 14   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[595   0]\n",
      " [ 14   0]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[156 439]\n",
      " [  3  11]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[142 453]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[595   0]\n",
      " [ 14   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[595   0]\n",
      " [ 14   0]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[201 394]\n",
      " [  4  10]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[277 318]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[595   0]\n",
      " [ 14   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[594   0]\n",
      " [ 14   0]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[182 412]\n",
      " [  3  11]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[259 335]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[594   0]\n",
      " [ 14   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[594   0]\n",
      " [ 14   0]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[242 352]\n",
      " [  6   8]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[235 359]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[594   0]\n",
      " [ 14   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[594   0]\n",
      " [ 14   0]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[250 344]\n",
      " [  3  11]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[278 316]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[594   0]\n",
      " [ 14   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[594   0]\n",
      " [ 14   0]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[182 412]\n",
      " [  5   9]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[246 348]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[594   0]\n",
      " [ 14   0]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9766679630109756\n",
      "Accuracy Std Dev: 0.0006494725957168835\n",
      "Mean Precision: 0.1\n",
      "Precision Std Dev: 0.30000000000000004\n",
      "Mean Recall: 0.006666666666666666\n",
      "Recall Std Dev: 0.019999999999999997\n",
      "Mean F1-score: 0.0125\n",
      "F1-score Std Dev: 0.037500000000000006\n",
      "Mean Entropy: 0.060447979044207324\n",
      "Entropy Std Dev: 0.005635930448642148\n",
      "Mean Confusion Matrix:\n",
      " [[5.943e+02 1.000e-01]\n",
      " [1.410e+01 1.000e-01]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.3921957371877971\n",
      "Accuracy Std Dev: 0.0879921360997864\n",
      "Mean Precision: 0.025255405031312732\n",
      "Precision Std Dev: 0.003232475020316332\n",
      "Mean Recall: 0.671904761904762\n",
      "Recall Std Dev: 0.14371882980603592\n",
      "Mean F1-score: 0.048628457563218444\n",
      "F1-score Std Dev: 0.006334273556500676\n",
      "Mean Entropy: 0.6669029745210954\n",
      "Entropy Std Dev: 0.006450618956639943\n",
      "Mean Confusion Matrix:\n",
      " [[229.2 365.2]\n",
      " [  4.7   9.5]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.39027363667790166\n",
      "Accuracy Std Dev: 0.07374892674370154\n",
      "Mean Precision: 0.037320650251215615\n",
      "Precision Std Dev: 0.004099778980901207\n",
      "Mean Recall: 1.0\n",
      "Recall Std Dev: 0.0\n",
      "Mean F1-score: 0.0719257028136012\n",
      "F1-score Std Dev: 0.007630620625286256\n",
      "Mean Entropy: 0.4716894222658947\n",
      "Entropy Std Dev: 0.009892333357484026\n",
      "Mean Confusion Matrix:\n",
      " [[223.3 371.1]\n",
      " [  0.   14.2]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9763395557860166\n",
      "Accuracy Std Dev: 0.0014984502566351638\n",
      "Mean Precision: 0.06666666666666667\n",
      "Precision Std Dev: 0.19999999999999998\n",
      "Mean Recall: 0.013333333333333332\n",
      "Recall Std Dev: 0.039999999999999994\n",
      "Mean F1-score: 0.02222222222222222\n",
      "F1-score Std Dev: 0.06666666666666667\n",
      "Mean Entropy: 0.05965792048875536\n",
      "Entropy Std Dev: 0.006001710561004897\n",
      "Mean Confusion Matrix:\n",
      " [[5.94e+02 4.00e-01]\n",
      " [1.40e+01 2.00e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Random Forest",
   "id": "b3ba9f1add05cd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:41:50.679880Z",
     "start_time": "2024-09-08T14:41:27.306666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Random Forest model without undersampling\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = rf_model.predict(X_test)\n",
    "    y_prob_before = rf_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with NearMiss\n",
    "    rf_model_nearmiss = RandomForestClassifier(random_state=42)\n",
    "    rf_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = rf_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = rf_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with ClusterCentroids\n",
    "    rf_model_clustercentroids = RandomForestClassifier(random_state=42)\n",
    "    rf_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = rf_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = rf_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with TomekLinks\n",
    "    rf_model_tomeklinks = RandomForestClassifier(random_state=42)\n",
    "    rf_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = rf_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = rf_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n"
   ],
   "id": "60bd25d630fe644e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[586   8]\n",
      " [ 12   3]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[374 220]\n",
      " [  8   7]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[462 132]\n",
      " [  0  15]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[587   7]\n",
      " [ 11   4]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[588   6]\n",
      " [ 12   3]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[417 177]\n",
      " [  9   6]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[478 116]\n",
      " [  0  15]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[587   7]\n",
      " [ 13   2]]\n",
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[591   4]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[366 229]\n",
      " [  5   9]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[463 132]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[591   4]\n",
      " [ 10   4]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[591   4]\n",
      " [ 13   1]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[277 318]\n",
      " [  5   9]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[505  90]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[590   5]\n",
      " [ 12   2]]\n",
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[589   6]\n",
      " [ 12   2]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[388 207]\n",
      " [  6   8]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[465 130]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[591   4]\n",
      " [  9   5]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[589   6]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[421 174]\n",
      " [  6   8]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[434 161]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[587   8]\n",
      " [  9   5]]\n",
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[593   1]\n",
      " [ 12   2]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[407 187]\n",
      " [  5   9]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[490 104]\n",
      " [  2  12]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[593   1]\n",
      " [ 12   2]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[588   6]\n",
      " [ 12   2]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[374 220]\n",
      " [  8   6]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[472 122]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[588   6]\n",
      " [ 12   2]]\n",
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[589   5]\n",
      " [ 10   4]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[386 208]\n",
      " [  6   8]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[496  98]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[590   4]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[590   4]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[343 251]\n",
      " [  5   9]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[464 130]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[589   5]\n",
      " [ 12   2]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.972725725952813\n",
      "Accuracy Std Dev: 0.00320817877381943\n",
      "Mean Precision: 0.36076479076479073\n",
      "Precision Std Dev: 0.13015847739326522\n",
      "Mean Recall: 0.18285714285714286\n",
      "Recall Std Dev: 0.05598833697790121\n",
      "Mean F1-score: 0.23650870935498744\n",
      "F1-score Std Dev: 0.06422719166946961\n",
      "Mean Entropy: 0.0539658682033089\n",
      "Entropy Std Dev: 0.006488147851062035\n",
      "Mean Confusion Matrix:\n",
      " [[589.4   5. ]\n",
      " [ 11.6   2.6]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.6296446936306281\n",
      "Accuracy Std Dev: 0.06477478898265054\n",
      "Mean Precision: 0.035424675932878215\n",
      "Precision Std Dev: 0.0060355712794656615\n",
      "Mean Recall: 0.5580952380952382\n",
      "Recall Std Dev: 0.08910744107212244\n",
      "Mean F1-score: 0.06651463779146559\n",
      "F1-score Std Dev: 0.011016970297326706\n",
      "Mean Entropy: 0.5650691092327138\n",
      "Entropy Std Dev: 0.00953893101156773\n",
      "Mean Confusion Matrix:\n",
      " [[375.3 219.1]\n",
      " [  6.3   7.9]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.8000410509031198\n",
      "Accuracy Std Dev: 0.03171613654063052\n",
      "Mean Precision: 0.10528843254718141\n",
      "Precision Std Dev: 0.014869220703129588\n",
      "Mean Recall: 0.9857142857142858\n",
      "Recall Std Dev: 0.04285714285714287\n",
      "Mean F1-score: 0.18990355742324572\n",
      "F1-score Std Dev: 0.024250211702289984\n",
      "Mean Entropy: 0.4492684890333368\n",
      "Entropy Std Dev: 0.01827134445890082\n",
      "Mean Confusion Matrix:\n",
      " [[4.729e+02 1.215e+02]\n",
      " [2.000e-01 1.400e+01]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9733820002592688\n",
      "Accuracy Std Dev: 0.0036553993697610748\n",
      "Mean Precision: 0.39426961926961923\n",
      "Precision Std Dev: 0.13696093733765324\n",
      "Mean Recall: 0.21857142857142856\n",
      "Recall Std Dev: 0.08685615078798517\n",
      "Mean F1-score: 0.2726927283193268\n",
      "F1-score Std Dev: 0.0893850158675487\n",
      "Mean Entropy: 0.05692813301285621\n",
      "Entropy Std Dev: 0.007406719983412067\n",
      "Mean Confusion Matrix:\n",
      " [[589.3   5.1]\n",
      " [ 11.1   3.1]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "decesion tree",
   "id": "78d6ab1ebc7f914a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T14:42:08.874658Z",
     "start_time": "2024-09-08T14:41:57.295955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Decision Tree model without undersampling\n",
    "    dt_model = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = dt_model.predict(X_test)\n",
    "    y_prob_before = dt_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with NearMiss\n",
    "    dt_model_nearmiss = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = dt_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = dt_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with ClusterCentroids\n",
    "    dt_model_clustercentroids = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = dt_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = dt_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with TomekLinks\n",
    "    dt_model_tomeklinks = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = dt_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = dt_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n"
   ],
   "id": "a4d515f22304765d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[574  20]\n",
      " [ 12   3]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[378 216]\n",
      " [ 10   5]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[509  85]\n",
      " [  1  14]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[578  16]\n",
      " [ 11   4]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[579  15]\n",
      " [ 11   4]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[405 189]\n",
      " [  5  10]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[514  80]\n",
      " [  0  15]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[579  15]\n",
      " [ 10   5]]\n",
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[579  16]\n",
      " [  6   8]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[394 201]\n",
      " [  2  12]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[483 112]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[574  21]\n",
      " [  4  10]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[580  15]\n",
      " [  9   5]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[346 249]\n",
      " [  7   7]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[529  66]\n",
      " [  2  12]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[577  18]\n",
      " [  8   6]]\n",
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[581  14]\n",
      " [  6   8]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[367 228]\n",
      " [  4  10]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[437 158]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[581  14]\n",
      " [  5   9]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[572  23]\n",
      " [  8   6]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[407 188]\n",
      " [  6   8]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[506  89]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[572  23]\n",
      " [  8   6]]\n",
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[582  12]\n",
      " [ 13   1]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[430 164]\n",
      " [ 10   4]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[507  87]\n",
      " [  4  10]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[583  11]\n",
      " [ 11   3]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[581  13]\n",
      " [  7   7]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[411 183]\n",
      " [  4  10]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[484 110]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[580  14]\n",
      " [  7   7]]\n",
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[578  16]\n",
      " [  9   5]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[386 208]\n",
      " [  7   7]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[533  61]\n",
      " [  0  14]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[579  15]\n",
      " [  9   5]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[574  20]\n",
      " [  7   7]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[368 226]\n",
      " [  5   9]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[473 121]\n",
      " [  1  13]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[574  20]\n",
      " [  9   5]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9585944926972603\n",
      "Accuracy Std Dev: 0.0063466078813425595\n",
      "Mean Precision: 0.24191049213695784\n",
      "Precision Std Dev: 0.08780561767811022\n",
      "Mean Recall: 0.3823809523809524\n",
      "Recall Std Dev: 0.1568113386154437\n",
      "Mean F1-score: 0.2944889825318099\n",
      "F1-score Std Dev: 0.11203786307282336\n",
      "Mean Entropy: 0.00011381717101147698\n",
      "Entropy Std Dev: 0.00034145181303445583\n",
      "Mean Confusion Matrix:\n",
      " [[578.   16.4]\n",
      " [  8.8   5.4]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.652984022556391\n",
      "Accuracy Std Dev: 0.03911847141387816\n",
      "Mean Precision: 0.038586960928028644\n",
      "Precision Std Dev: 0.011308605671342122\n",
      "Mean Recall: 0.5785714285714285\n",
      "Recall Std Dev: 0.1687119403624464\n",
      "Mean F1-score: 0.07229640341847812\n",
      "F1-score Std Dev: 0.02112637215391046\n",
      "Mean Entropy: 0.02471669325646454\n",
      "Entropy Std Dev: 0.010845640692829636\n",
      "Mean Confusion Matrix:\n",
      " [[389.2 205.2]\n",
      " [  6.    8.2]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.8394693630628295\n",
      "Accuracy Std Dev: 0.044628954387683814\n",
      "Mean Precision: 0.12812614234992153\n",
      "Precision Std Dev: 0.030840922610239928\n",
      "Mean Recall: 0.9433333333333334\n",
      "Recall Std Dev: 0.08914941978285135\n",
      "Mean F1-score: 0.2242425894910752\n",
      "F1-score Std Dev: 0.04828857630790382\n",
      "Mean Entropy: -1.000000082690371e-10\n",
      "Entropy Std Dev: 1.0011427302261019e-26\n",
      "Mean Confusion Matrix:\n",
      " [[497.5  96.9]\n",
      " [  0.8  13.4]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9590873736064299\n",
      "Accuracy Std Dev: 0.0056583486014759885\n",
      "Mean Precision: 0.26184005923305625\n",
      "Precision Std Dev: 0.062378570552681055\n",
      "Mean Recall: 0.42428571428571427\n",
      "Recall Std Dev: 0.14962462479375246\n",
      "Mean F1-score: 0.320488950409751\n",
      "F1-score Std Dev: 0.08758912457891246\n",
      "Mean Entropy: 0.00011381717101147698\n",
      "Entropy Std Dev: 0.00034145181303445583\n",
      "Mean Confusion Matrix:\n",
      " [[577.7  16.7]\n",
      " [  8.2   6. ]]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "feb8cf2d932f8fee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
