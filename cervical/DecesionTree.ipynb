{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T20:47:45.474938Z",
     "start_time": "2024-11-07T20:47:45.472989Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:47:46.871742Z",
     "start_time": "2024-11-07T20:47:46.850049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('cleaned_data.csv')\n",
    "data.head()"
   ],
   "id": "9f597a7c8d2e478f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Age  Number of sexual partners  First sexual intercourse  \\\n",
       "0   18                          6                         5   \n",
       "1   15                          0                         4   \n",
       "2   34                          0                         5   \n",
       "3   52                          7                         6   \n",
       "4   46                          5                        11   \n",
       "\n",
       "   Num of pregnancies  Smokes  Smokes (years)  Smokes (packs/year)  \\\n",
       "0                   1       0               0                    0   \n",
       "1                   1       0               0                    0   \n",
       "2                   1       0               0                    0   \n",
       "3                   6       1              23                   49   \n",
       "4                   6       0               0                    0   \n",
       "\n",
       "   Hormonal Contraceptives  Hormonal Contraceptives (years)  IUD  ...  \\\n",
       "0                        0                                0    0  ...   \n",
       "1                        0                                0    0  ...   \n",
       "2                        0                                0    0  ...   \n",
       "3                        1                               29    0  ...   \n",
       "4                        1                               20    0  ...   \n",
       "\n",
       "   STDs: Time since first diagnosis  STDs: Time since last diagnosis  \\\n",
       "0                                 0                                0   \n",
       "1                                 0                                0   \n",
       "2                                 0                                0   \n",
       "3                                 0                                0   \n",
       "4                                 0                                0   \n",
       "\n",
       "   Dx:Cancer  Dx:CIN  Dx:HPV  Dx  Hinselmann  Schiller  Citology  Biopsy  \n",
       "0          0       0       0   0           0         0         0       0  \n",
       "1          0       0       0   0           0         0         0       0  \n",
       "2          0       0       0   0           0         0         0       0  \n",
       "3          1       0       1   0           0         0         0       0  \n",
       "4          0       0       0   0           0         0         0       0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of sexual partners</th>\n",
       "      <th>First sexual intercourse</th>\n",
       "      <th>Num of pregnancies</th>\n",
       "      <th>Smokes</th>\n",
       "      <th>Smokes (years)</th>\n",
       "      <th>Smokes (packs/year)</th>\n",
       "      <th>Hormonal Contraceptives</th>\n",
       "      <th>Hormonal Contraceptives (years)</th>\n",
       "      <th>IUD</th>\n",
       "      <th>...</th>\n",
       "      <th>STDs: Time since first diagnosis</th>\n",
       "      <th>STDs: Time since last diagnosis</th>\n",
       "      <th>Dx:Cancer</th>\n",
       "      <th>Dx:CIN</th>\n",
       "      <th>Dx:HPV</th>\n",
       "      <th>Dx</th>\n",
       "      <th>Hinselmann</th>\n",
       "      <th>Schiller</th>\n",
       "      <th>Citology</th>\n",
       "      <th>Biopsy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:47:51.968790Z",
     "start_time": "2024-11-07T20:47:51.963770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X=data.drop(['Biopsy'], axis=1)\n",
    "y=data['Biopsy']"
   ],
   "id": "8178c3264f76ef54",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Over Sampling\n",
    "\n"
   ],
   "id": "d5806523d7517c10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:49:40.904010Z",
     "start_time": "2024-11-07T20:49:40.510699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_smote = []\n",
    "precision_list_smote = []\n",
    "recall_list_smote = []\n",
    "f1_list_smote = []\n",
    "entropy_list_smote = []\n",
    "confusion_matrices_smote = []\n",
    "\n",
    "accuracy_list_adasyn = []\n",
    "precision_list_adasyn = []\n",
    "recall_list_adasyn = []\n",
    "f1_list_adasyn = []\n",
    "entropy_list_adasyn = []\n",
    "confusion_matrices_adasyn = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Decision Tree model without SMOTE/ADASYN\n",
    "    dt_model = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before SMOTE/ADASYN\n",
    "    y_pred_before = dt_model.predict(X_test)\n",
    "    y_prob_before = dt_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before SMOTE/ADASYN\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before SMOTE/ADASYN\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with SMOTE\n",
    "    dt_model_smote = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_smote.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Predictions and probabilities after SMOTE\n",
    "    y_pred_smote = dt_model_smote.predict(X_test)\n",
    "    y_prob_smote = dt_model_smote.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after SMOTE\n",
    "    entropy_smote = calculate_entropy(y_prob_smote)\n",
    "    entropy_list_smote.append(entropy_smote)\n",
    "    \n",
    "    # Store metrics after SMOTE\n",
    "    accuracy_list_smote.append(accuracy_score(y_test, y_pred_smote))\n",
    "    precision_list_smote.append(precision_score(y_test, y_pred_smote))\n",
    "    recall_list_smote.append(recall_score(y_test, y_pred_smote))\n",
    "    f1_list_smote.append(f1_score(y_test, y_pred_smote))\n",
    "    confusion_matrices_smote.append(confusion_matrix(y_test, y_pred_smote))\n",
    "    \n",
    "    # Apply ADASYN to the training data\n",
    "    adasyn = ADASYN(random_state=42)\n",
    "    X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with ADASYN\n",
    "    dt_model_adasyn = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_adasyn.fit(X_train_adasyn, y_train_adasyn)\n",
    "    \n",
    "    # Predictions and probabilities after ADASYN\n",
    "    y_pred_adasyn = dt_model_adasyn.predict(X_test)\n",
    "    y_prob_adasyn = dt_model_adasyn.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ADASYN\n",
    "    entropy_adasyn = calculate_entropy(y_prob_adasyn)\n",
    "    entropy_list_adasyn.append(entropy_adasyn)\n",
    "    \n",
    "    # Store metrics after ADASYN\n",
    "    accuracy_list_adasyn.append(accuracy_score(y_test, y_pred_adasyn))\n",
    "    precision_list_adasyn.append(precision_score(y_test, y_pred_adasyn))\n",
    "    recall_list_adasyn.append(recall_score(y_test, y_pred_adasyn))\n",
    "    f1_list_adasyn.append(f1_score(y_test, y_pred_adasyn))\n",
    "    confusion_matrices_adasyn.append(confusion_matrix(y_test, y_pred_adasyn))\n",
    "    \n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Oversampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_smote)} After SMOTE:\\n', confusion_matrices_smote[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_adasyn)} After ADASYN:\\n', confusion_matrices_adasyn[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before oversampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after SMOTE\n",
    "mean_accuracy_smote = np.mean(accuracy_list_smote)\n",
    "std_accuracy_smote = np.std(accuracy_list_smote)\n",
    "mean_precision_smote = np.mean(precision_list_smote)\n",
    "std_precision_smote = np.std(precision_list_smote)\n",
    "mean_recall_smote = np.mean(recall_list_smote)\n",
    "std_recall_smote = np.std(recall_list_smote)\n",
    "mean_f1_smote = np.mean(f1_list_smote)\n",
    "std_f1_smote = np.std(f1_list_smote)\n",
    "mean_entropy_smote = np.mean(entropy_list_smote)\n",
    "std_entropy_smote = np.std(entropy_list_smote)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ADASYN\n",
    "mean_accuracy_adasyn = np.mean(accuracy_list_adasyn)\n",
    "std_accuracy_adasyn = np.std(accuracy_list_adasyn)\n",
    "mean_precision_adasyn = np.mean(precision_list_adasyn)\n",
    "std_precision_adasyn = np.std(precision_list_adasyn)\n",
    "mean_recall_adasyn = np.mean(recall_list_adasyn)\n",
    "std_recall_adasyn = np.std(recall_list_adasyn)\n",
    "mean_f1_adasyn = np.mean(f1_list_adasyn)\n",
    "std_f1_adasyn = np.std(f1_list_adasyn)\n",
    "mean_entropy_adasyn = np.mean(entropy_list_adasyn)\n",
    "std_entropy_adasyn = np.std(entropy_list_adasyn)\n",
    "\n",
    "# Calculate mean confusion matrix before and after SMOTE/ADASYN\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_smote = np.mean(confusion_matrices_smote, axis=0)\n",
    "mean_conf_matrix_adasyn = np.mean(confusion_matrices_adasyn, axis=0)\n",
    "\n",
    "# Print results before oversampling\n",
    "print('--- Before Oversampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after SMOTE\n",
    "print('--- After SMOTE ---')\n",
    "print('Mean Accuracy:', mean_accuracy_smote)\n",
    "print('Accuracy Std Dev:', std_accuracy_smote)\n",
    "print('Mean Precision:', mean_precision_smote)\n",
    "print('Precision Std Dev:', std_precision_smote)\n",
    "print('Mean Recall:', mean_recall_smote)\n",
    "print('Recall Std Dev:', std_recall_smote)\n",
    "print('Mean F1-score:', mean_f1_smote)\n",
    "print('F1-score Std Dev:', std_f1_smote)\n",
    "print('Mean Entropy:', mean_entropy_smote)\n",
    "print('Entropy Std Dev:', std_entropy_smote)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_smote)\n",
    "\n",
    "# Print results after ADASYN\n",
    "print('--- After ADASYN ---')\n",
    "print('Mean Accuracy:', mean_accuracy_adasyn)\n",
    "print('Accuracy Std Dev:', std_accuracy_adasyn)\n",
    "print('Mean Precision:', mean_precision_adasyn)\n",
    "print('Precision Std Dev:', std_precision_adasyn)\n",
    "print('Mean Recall:', mean_recall_adasyn)\n",
    "print('Recall Std Dev:', std_recall_adasyn)\n",
    "print('Mean F1-score:', mean_f1_adasyn)\n",
    "print('F1-score Std Dev:', std_f1_adasyn)\n",
    "print('Mean Entropy:', mean_entropy_adasyn)\n",
    "print('Entropy Std Dev:', std_entropy_adasyn)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_adasyn)\n"
   ],
   "id": "54ae81a50dfed588",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Oversampling:\n",
      " [[79  2]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 1 After SMOTE:\n",
      " [[74  7]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 1 After ADASYN:\n",
      " [[73  8]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 2 Before Oversampling:\n",
      " [[81  0]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 2 After SMOTE:\n",
      " [[77  4]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 2 After ADASYN:\n",
      " [[77  4]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 3 Before Oversampling:\n",
      " [[80  1]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 3 After SMOTE:\n",
      " [[78  3]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 3 After ADASYN:\n",
      " [[77  4]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 4 Before Oversampling:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 4 After SMOTE:\n",
      " [[73  7]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 4 After ADASYN:\n",
      " [[75  5]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 5 Before Oversampling:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5 After SMOTE:\n",
      " [[74  6]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5 After ADASYN:\n",
      " [[74  6]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6 Before Oversampling:\n",
      " [[78  2]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 6 After SMOTE:\n",
      " [[76  4]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 6 After ADASYN:\n",
      " [[76  4]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 7 Before Oversampling:\n",
      " [[78  2]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 7 After SMOTE:\n",
      " [[70 10]\n",
      " [ 5  1]]\n",
      "Confusion Matrix for Fold 7 After ADASYN:\n",
      " [[74  6]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 8 Before Oversampling:\n",
      " [[78  2]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After SMOTE:\n",
      " [[76  4]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After ADASYN:\n",
      " [[76  4]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 9 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 9 After SMOTE:\n",
      " [[75  5]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 9 After ADASYN:\n",
      " [[76  4]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 10 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10 After SMOTE:\n",
      " [[71  9]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 10 After ADASYN:\n",
      " [[76  4]\n",
      " [ 0  5]]\n",
      "--- Before Oversampling ---\n",
      "Mean Accuracy: 0.9522435020519836\n",
      "Accuracy Std Dev: 0.01755545744264441\n",
      "Mean Precision: 0.6357142857142858\n",
      "Precision Std Dev: 0.16955657789238368\n",
      "Mean Recall: 0.5566666666666668\n",
      "Recall Std Dev: 0.2246231411844193\n",
      "Mean F1-score: 0.5815512265512266\n",
      "F1-score Std Dev: 0.19656845300519107\n",
      "Mean Entropy: -1.0000000826903714e-10\n",
      "Entropy Std Dev: 5.780100247932768e-27\n",
      "Mean Confusion Matrix:\n",
      " [[78.6  1.7]\n",
      " [ 2.4  3.1]]\n",
      "--- After SMOTE ---\n",
      "Mean Accuracy: 0.9079343365253079\n",
      "Accuracy Std Dev: 0.03139056498159627\n",
      "Mean Precision: 0.3743290043290043\n",
      "Precision Std Dev: 0.1267086691602758\n",
      "Mean Recall: 0.6366666666666666\n",
      "Recall Std Dev: 0.25536466300393074\n",
      "Mean F1-score: 0.46312644355988003\n",
      "F1-score Std Dev: 0.16171532819963963\n",
      "Mean Entropy: 0.005516445574748412\n",
      "Entropy Std Dev: 0.006286634940328367\n",
      "Mean Confusion Matrix:\n",
      " [[74.4  5.9]\n",
      " [ 2.   3.5]]\n",
      "--- After ADASYN ---\n",
      "Mean Accuracy: 0.9231053351573187\n",
      "Accuracy Std Dev: 0.019536440369144415\n",
      "Mean Precision: 0.43520923520923527\n",
      "Precision Std Dev: 0.09091355723241454\n",
      "Mean Recall: 0.6866666666666668\n",
      "Recall Std Dev: 0.1892675942210452\n",
      "Mean F1-score: 0.5289896867838044\n",
      "F1-score Std Dev: 0.11921052020870385\n",
      "Mean Entropy: 0.0008059849935580677\n",
      "Entropy Std Dev: 0.002417955280674228\n",
      "Mean Confusion Matrix:\n",
      " [[75.4  4.9]\n",
      " [ 1.7  3.8]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:50:40.022790Z",
     "start_time": "2024-11-07T20:50:39.892853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "import numpy as np\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "uncertainty_list = []  # List to store entropy for each fold\n",
    "confusion_matrices = []\n",
    "\n",
    "# Choose an oversampling method\n",
    "# oversampler = SMOTE(random_state=42)\n",
    "# oversampler = ADASYN(random_state=42)\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Function to calculate entropy\n",
    "def calculate_entropy(probabilities):\n",
    "    entropy = -np.sum(probabilities * np.log(probabilities + 1e-9), axis=1)  # Add small value to avoid log(0)\n",
    "    return np.mean(entropy)\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply oversampling\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model\n",
    "    decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "    decision_tree_model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict probabilities and classes\n",
    "    y_pred_tree = decision_tree_model.predict(X_test)\n",
    "    y_prob_tree = decision_tree_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate and store entropy\n",
    "    entropy = calculate_entropy(y_prob_tree)\n",
    "    uncertainty_list.append(entropy)\n",
    "    \n",
    "    # Store metrics\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred_tree))\n",
    "    precision_list.append(precision_score(y_test, y_pred_tree))\n",
    "    recall_list.append(recall_score(y_test, y_pred_tree))\n",
    "    f1_list.append(f1_score(y_test, y_pred_tree))\n",
    "    \n",
    "    # Store confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_tree)\n",
    "    confusion_matrices.append(conf_matrix)\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices)}:\\n', conf_matrix)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "std_precision = np.std(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "std_recall = np.std(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "\n",
    "# Calculate mean and standard deviation of entropy\n",
    "mean_entropy = np.mean(uncertainty_list)\n",
    "std_entropy = np.std(uncertainty_list)\n",
    "\n",
    "# Calculate mean confusion matrix\n",
    "mean_conf_matrix = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "# Print results\n",
    "print('Mean Accuracy:', mean_accuracy)\n",
    "print('Accuracy Std Dev:', std_accuracy)\n",
    "print('Mean Precision:', mean_precision)\n",
    "print('Precision Std Dev:', std_precision)\n",
    "print('Mean Recall:', mean_recall)\n",
    "print('Recall Std Dev:', std_recall)\n",
    "print('Mean F1-score:', mean_f1)\n",
    "print('F1-score Std Dev:', std_f1)\n",
    "print('Mean Entropy:', mean_entropy)\n",
    "print('Entropy Std Dev:', std_entropy)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix)\n"
   ],
   "id": "dece33e9ea2d9d30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1:\n",
      " [[79  2]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 2:\n",
      " [[78  3]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 3:\n",
      " [[80  1]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 4:\n",
      " [[79  1]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5:\n",
      " [[76  4]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6:\n",
      " [[78  2]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 7:\n",
      " [[77  3]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 8:\n",
      " [[80  0]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 9:\n",
      " [[79  1]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 10:\n",
      " [[80  0]\n",
      " [ 1  4]]\n",
      "Mean Accuracy: 0.9522708618331054\n",
      "Accuracy Std Dev: 0.024042107012615443\n",
      "Mean Precision: 0.6372222222222222\n",
      "Precision Std Dev: 0.27478442729070635\n",
      "Mean Recall: 0.5633333333333332\n",
      "Recall Std Dev: 0.2478574859336174\n",
      "Mean F1-score: 0.5847330447330448\n",
      "F1-score Std Dev: 0.24746886433421234\n",
      "Mean Entropy: -1.0000000822403705e-09\n",
      "Entropy Std Dev: 2.0679515313825692e-25\n",
      "Mean Confusion Matrix:\n",
      " [[78.6  1.7]\n",
      " [ 2.4  3.1]]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3082711e69788153"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:48:29.829735Z",
     "start_time": "2024-11-07T20:48:28.657317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Decision Tree model without undersampling\n",
    "    dt_model = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = dt_model.predict(X_test)\n",
    "    y_prob_before = dt_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with NearMiss\n",
    "    dt_model_nearmiss = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = dt_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = dt_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with ClusterCentroids\n",
    "    dt_model_clustercentroids = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = dt_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = dt_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with TomekLinks\n",
    "    dt_model_tomeklinks = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = dt_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = dt_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n"
   ],
   "id": "bc992c96c3267de2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[79  2]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[35 46]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[68 13]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[78  3]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[81  0]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[39 42]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[65 16]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[81  0]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[80  1]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[39 42]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[50 31]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[80  1]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[42 38]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[52 28]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[77  3]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[44 36]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[67 13]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[78  2]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[39 41]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[71  9]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[77  3]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[78  2]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[36 44]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[66 14]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[78  2]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[78  2]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[39 41]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[56 24]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[79  1]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[79  1]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[38 42]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[54 26]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[78  2]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[79  1]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[35 45]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[64 16]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[79  1]\n",
      " [ 2  3]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9522435020519836\n",
      "Accuracy Std Dev: 0.01755545744264441\n",
      "Mean Precision: 0.6357142857142858\n",
      "Precision Std Dev: 0.16955657789238368\n",
      "Mean Recall: 0.5566666666666668\n",
      "Recall Std Dev: 0.2246231411844193\n",
      "Mean F1-score: 0.5815512265512266\n",
      "F1-score Std Dev: 0.19656845300519107\n",
      "Mean Entropy: -1.0000000826903714e-10\n",
      "Entropy Std Dev: 5.780100247932768e-27\n",
      "Mean Confusion Matrix:\n",
      " [[78.6  1.7]\n",
      " [ 2.4  3.1]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.5104377564979481\n",
      "Accuracy Std Dev: 0.034019555507881355\n",
      "Mean Precision: 0.11143737784408188\n",
      "Precision Std Dev: 0.016302156889425174\n",
      "Mean Recall: 0.9466666666666667\n",
      "Recall Std Dev: 0.08192137151629669\n",
      "Mean F1-score: 0.1990768839004133\n",
      "F1-score Std Dev: 0.026800805092749107\n",
      "Mean Entropy: -1.0000000826903714e-10\n",
      "Entropy Std Dev: 5.780100247932768e-27\n",
      "Mean Confusion Matrix:\n",
      " [[38.6 41.7]\n",
      " [ 0.3  5.2]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.7738440492476061\n",
      "Accuracy Std Dev: 0.08803963077494673\n",
      "Mean Precision: 0.23300724875942608\n",
      "Precision Std Dev: 0.08678563707595524\n",
      "Mean Recall: 0.9233333333333335\n",
      "Recall Std Dev: 0.13\n",
      "Mean F1-score: 0.3669703243616287\n",
      "F1-score Std Dev: 0.11623376056554062\n",
      "Mean Entropy: -1.0000000826903714e-10\n",
      "Entropy Std Dev: 5.780100247932768e-27\n",
      "Mean Confusion Matrix:\n",
      " [[61.3 19. ]\n",
      " [ 0.4  5.1]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9475649794801642\n",
      "Accuracy Std Dev: 0.01579717014901952\n",
      "Mean Precision: 0.6321428571428571\n",
      "Precision Std Dev: 0.17374509569091148\n",
      "Mean Recall: 0.52\n",
      "Recall Std Dev: 0.13597385369580758\n",
      "Mean F1-score: 0.5576712176712177\n",
      "F1-score Std Dev: 0.1179819397837767\n",
      "Mean Entropy: -1.0000000826903714e-10\n",
      "Entropy Std Dev: 5.780100247932768e-27\n",
      "Mean Confusion Matrix:\n",
      " [[78.4  1.9]\n",
      " [ 2.6  2.9]]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:51:43.528711Z",
     "start_time": "2024-11-07T20:51:42.854992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks, RandomUnderSampler\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "accuracy_list_random = []\n",
    "precision_list_random = []\n",
    "recall_list_random = []\n",
    "f1_list_random = []\n",
    "entropy_list_random = []\n",
    "confusion_matrices_random = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Decision Tree model without undersampling\n",
    "    dt_model = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = dt_model.predict(X_test)\n",
    "    y_prob_before = dt_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with NearMiss\n",
    "    dt_model_nearmiss = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = dt_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = dt_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with ClusterCentroids\n",
    "    dt_model_clustercentroids = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = dt_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = dt_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with TomekLinks\n",
    "    dt_model_tomeklinks = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = dt_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = dt_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Apply RandomUnderSampler to the training data\n",
    "    random_undersampler = RandomUnderSampler(random_state=42)\n",
    "    X_train_random, y_train_random = random_undersampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with RandomUnderSampler\n",
    "    dt_model_random = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_random.fit(X_train_random, y_train_random)\n",
    "    \n",
    "    # Predictions and probabilities after RandomUnderSampler\n",
    "    y_pred_random = dt_model_random.predict(X_test)\n",
    "    y_prob_random = dt_model_random.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after RandomUnderSampler\n",
    "    entropy_random = calculate_entropy(y_prob_random)\n",
    "    entropy_list_random.append(entropy_random)\n",
    "    \n",
    "    # Store metrics after RandomUnderSampler\n",
    "    accuracy_list_random.append(accuracy_score(y_test, y_pred_random))\n",
    "    precision_list_random.append(precision_score(y_test, y_pred_random))\n",
    "    recall_list_random.append(recall_score(y_test, y_pred_random))\n",
    "    f1_list_random.append(f1_score(y_test, y_pred_random))\n",
    "    confusion_matrices_random.append(confusion_matrix(y_test, y_pred_random))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_random)} After RandomUnderSampler:\\n', confusion_matrices_random[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after RandomUnderSampler\n",
    "mean_accuracy_random = np.mean(accuracy_list_random)\n",
    "std_accuracy_random = np.std(accuracy_list_random)\n",
    "mean_precision_random = np.mean(precision_list_random)\n",
    "std_precision_random = np.std(precision_list_random)\n",
    "mean_recall_random = np.mean(recall_list_random)\n",
    "std_recall_random = np.std(recall_list_random)\n",
    "mean_f1_random = np.mean(f1_list_random)\n",
    "std_f1_random = np.std(f1_list_random)\n",
    "mean_entropy_random = np.mean(entropy_list_random)\n",
    "std_entropy_random = np.std(entropy_list_random)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "mean_conf_matrix_random = np.mean(confusion_matrices_random, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n",
    "\n",
    "# Print results after RandomUnderSampler\n",
    "print('--- After RandomUnderSampler ---')\n",
    "print('Mean Accuracy:', mean_accuracy_random)\n",
    "print('Accuracy Std Dev:', std_accuracy_random)\n",
    "print('Mean Precision:', mean_precision_random)\n",
    "print('Precision Std Dev:', std_precision_random)\n",
    "print('Mean Recall:', mean_recall_random)\n",
    "print('Recall Std Dev:', std_recall_random)\n",
    "print('Mean F1-score:', mean_f1_random)\n",
    "print('F1-score Std Dev:', std_f1_random)\n",
    "print('Mean Entropy:', mean_entropy_random)\n",
    "print('Entropy Std Dev:', std_entropy_random)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_random)\n"
   ],
   "id": "a001cbaa681d62b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[79  2]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[35 46]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[68 13]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[78  3]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 1 After RandomUnderSampler:\n",
      " [[68 13]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[81  0]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[39 42]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[65 16]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[81  0]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 2 After RandomUnderSampler:\n",
      " [[69 12]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[80  1]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[39 42]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[50 31]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[80  1]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 3 After RandomUnderSampler:\n",
      " [[72  9]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[42 38]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[52 28]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[77  3]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 4 After RandomUnderSampler:\n",
      " [[69 11]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[44 36]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[67 13]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5 After RandomUnderSampler:\n",
      " [[69 11]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[78  2]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[39 41]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[71  9]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[77  3]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 6 After RandomUnderSampler:\n",
      " [[64 16]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[78  2]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[36 44]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[66 14]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[78  2]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 7 After RandomUnderSampler:\n",
      " [[64 16]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[78  2]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[39 41]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[56 24]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[79  1]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After RandomUnderSampler:\n",
      " [[77  3]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[79  1]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[38 42]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[54 26]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[78  2]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 9 After RandomUnderSampler:\n",
      " [[77  3]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[79  1]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[35 45]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[64 16]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[79  1]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 10 After RandomUnderSampler:\n",
      " [[66 14]\n",
      " [ 0  5]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9522435020519836\n",
      "Accuracy Std Dev: 0.01755545744264441\n",
      "Mean Precision: 0.6357142857142858\n",
      "Precision Std Dev: 0.16955657789238368\n",
      "Mean Recall: 0.5566666666666668\n",
      "Recall Std Dev: 0.2246231411844193\n",
      "Mean F1-score: 0.5815512265512266\n",
      "F1-score Std Dev: 0.19656845300519107\n",
      "Mean Entropy: -1.0000000826903714e-10\n",
      "Entropy Std Dev: 5.780100247932768e-27\n",
      "Mean Confusion Matrix:\n",
      " [[78.6  1.7]\n",
      " [ 2.4  3.1]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.5104377564979481\n",
      "Accuracy Std Dev: 0.034019555507881355\n",
      "Mean Precision: 0.11143737784408188\n",
      "Precision Std Dev: 0.016302156889425174\n",
      "Mean Recall: 0.9466666666666667\n",
      "Recall Std Dev: 0.08192137151629669\n",
      "Mean F1-score: 0.1990768839004133\n",
      "F1-score Std Dev: 0.026800805092749107\n",
      "Mean Entropy: -1.0000000826903714e-10\n",
      "Entropy Std Dev: 5.780100247932768e-27\n",
      "Mean Confusion Matrix:\n",
      " [[38.6 41.7]\n",
      " [ 0.3  5.2]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.7738440492476061\n",
      "Accuracy Std Dev: 0.08803963077494673\n",
      "Mean Precision: 0.23300724875942608\n",
      "Precision Std Dev: 0.08678563707595524\n",
      "Mean Recall: 0.9233333333333335\n",
      "Recall Std Dev: 0.13\n",
      "Mean F1-score: 0.3669703243616287\n",
      "F1-score Std Dev: 0.11623376056554062\n",
      "Mean Entropy: -1.0000000826903714e-10\n",
      "Entropy Std Dev: 5.780100247932768e-27\n",
      "Mean Confusion Matrix:\n",
      " [[61.3 19. ]\n",
      " [ 0.4  5.1]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9475649794801642\n",
      "Accuracy Std Dev: 0.01579717014901952\n",
      "Mean Precision: 0.6321428571428571\n",
      "Precision Std Dev: 0.17374509569091148\n",
      "Mean Recall: 0.52\n",
      "Recall Std Dev: 0.13597385369580758\n",
      "Mean F1-score: 0.5576712176712177\n",
      "F1-score Std Dev: 0.1179819397837767\n",
      "Mean Entropy: -1.0000000826903714e-10\n",
      "Entropy Std Dev: 5.780100247932768e-27\n",
      "Mean Confusion Matrix:\n",
      " [[78.4  1.9]\n",
      " [ 2.6  2.9]]\n",
      "--- After RandomUnderSampler ---\n",
      "Mean Accuracy: 0.8637072503419972\n",
      "Accuracy Std Dev: 0.04907993382340453\n",
      "Mean Precision: 0.3295446113054472\n",
      "Precision Std Dev: 0.14280152597601997\n",
      "Mean Recall: 0.8300000000000001\n",
      "Recall Std Dev: 0.18823743871327334\n",
      "Mean F1-score: 0.4557628040236736\n",
      "F1-score Std Dev: 0.13866116608770013\n",
      "Mean Entropy: -1.0000000826903714e-10\n",
      "Entropy Std Dev: 5.780100247932768e-27\n",
      "Mean Confusion Matrix:\n",
      " [[69.5 10.8]\n",
      " [ 0.9  4.6]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "threshold Moving",
   "id": "f04f283f1e313568"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:52:55.508842Z",
     "start_time": "2024-11-07T20:52:54.152139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Function to find the best threshold for F1-score\n",
    "def find_best_threshold(y_true, y_prob, thresholds):\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0.5\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob[:, 1] >= threshold).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "best_thresholds = []\n",
    "f1_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "roc_auc_list = []\n",
    "entropy_list = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Decision Tree model\n",
    "    dt_model = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calibrate the model\n",
    "    calibrated_model = CalibratedClassifierCV(dt_model, method='isotonic', cv=5)\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predicted probabilities on training set\n",
    "    y_prob_train = calibrated_model.predict_proba(X_train)\n",
    "    \n",
    "    # Define a range of thresholds to test\n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "    \n",
    "    # Find the best threshold based on training set\n",
    "    best_threshold, _ = find_best_threshold(y_train, y_prob_train, thresholds)\n",
    "    best_thresholds.append(best_threshold)\n",
    "    \n",
    "    # Get predicted probabilities on test set\n",
    "    y_prob_test = calibrated_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy\n",
    "    entropy = calculate_entropy(y_prob_test)\n",
    "    entropy_list.append(entropy)\n",
    "    \n",
    "    # Make predictions using the best threshold\n",
    "    y_pred = (y_prob_test[:, 1] >= best_threshold).astype(int)\n",
    "    \n",
    "    # Calculate and store ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_prob_test[:, 1])\n",
    "    roc_auc_list.append(roc_auc)\n",
    "    \n",
    "    # Store the metrics\n",
    "    f1_list.append(f1_score(y_test, y_pred))\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    precision_list.append(precision_score(y_test, y_pred))\n",
    "    recall_list.append(recall_score(y_test, y_pred))\n",
    "    confusion_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(f'Best Threshold for Fold {len(best_thresholds)}: {best_threshold}')\n",
    "    print(f'Confusion Matrix for Fold {len(best_thresholds)}:\\n', confusion_matrices[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "std_precision = np.std(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "std_recall = np.std(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "mean_roc_auc = np.mean(roc_auc_list)\n",
    "std_roc_auc = np.std(roc_auc_list)\n",
    "mean_entropy = np.mean(entropy_list)\n",
    "std_entropy = np.std(entropy_list)\n",
    "\n",
    "# Calculate mean confusion matrix\n",
    "mean_conf_matrix = np.mean(confusion_matrices, axis=0).astype(int)\n",
    "\n",
    "# Print the results\n",
    "print('--- Overall Results ---')\n",
    "print('Mean Accuracy:', mean_accuracy)\n",
    "print('Accuracy Std Dev:', std_accuracy)\n",
    "print('Mean Precision:', mean_precision)\n",
    "print('Precision Std Dev:', std_precision)\n",
    "print('Mean Recall:', mean_recall)\n",
    "print('Recall Std Dev:', std_recall)\n",
    "print('Mean F1-score:', mean_f1)\n",
    "print('F1-score Std Dev:', std_f1)\n",
    "print('Mean ROC AUC:', mean_roc_auc)\n",
    "print('ROC AUC Std Dev:', std_roc_auc)\n",
    "print('Mean Entropy:', mean_entropy)\n",
    "print('Entropy Std Dev:', std_entropy)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix)"
   ],
   "id": "53f829315e32fd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold for Fold 1: 0.17999999999999997\n",
      "Confusion Matrix for Fold 1:\n",
      " [[79  2]\n",
      " [ 2  3]]\n",
      "Best Threshold for Fold 2: 0.17999999999999997\n",
      "Confusion Matrix for Fold 2:\n",
      " [[80  1]\n",
      " [ 3  2]]\n",
      "Best Threshold for Fold 3: 0.19999999999999996\n",
      "Confusion Matrix for Fold 3:\n",
      " [[79  2]\n",
      " [ 1  4]]\n",
      "Best Threshold for Fold 4: 0.17999999999999997\n",
      "Confusion Matrix for Fold 4:\n",
      " [[77  3]\n",
      " [ 1  5]]\n",
      "Best Threshold for Fold 5: 0.16999999999999998\n",
      "Confusion Matrix for Fold 5:\n",
      " [[75  5]\n",
      " [ 1  5]]\n",
      "Best Threshold for Fold 6: 0.19999999999999996\n",
      "Confusion Matrix for Fold 6:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Best Threshold for Fold 7: 0.17999999999999997\n",
      "Confusion Matrix for Fold 7:\n",
      " [[77  3]\n",
      " [ 1  5]]\n",
      "Best Threshold for Fold 8: 0.19999999999999996\n",
      "Confusion Matrix for Fold 8:\n",
      " [[80  0]\n",
      " [ 1  5]]\n",
      "Best Threshold for Fold 9: 0.18999999999999995\n",
      "Confusion Matrix for Fold 9:\n",
      " [[78  2]\n",
      " [ 1  4]]\n",
      "Best Threshold for Fold 10: 0.18999999999999995\n",
      "Confusion Matrix for Fold 10:\n",
      " [[77  3]\n",
      " [ 0  5]]\n",
      "--- Overall Results ---\n",
      "Mean Accuracy: 0.9568946648426813\n",
      "Accuracy Std Dev: 0.014709724945750149\n",
      "Mean Precision: 0.6546428571428572\n",
      "Precision Std Dev: 0.12496649210752403\n",
      "Mean Recall: 0.76\n",
      "Recall Std Dev: 0.1569146972791976\n",
      "Mean F1-score: 0.6901823176823176\n",
      "F1-score Std Dev: 0.10593798596185328\n",
      "Mean ROC AUC: 0.9090138888888889\n",
      "ROC AUC Std Dev: 0.0581301861870739\n",
      "Mean Entropy: 0.1982908416829238\n",
      "Entropy Std Dev: 0.010915477288591794\n",
      "Mean Confusion Matrix:\n",
      " [[77  2]\n",
      " [ 1  4]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T20:54:53.140580Z",
     "start_time": "2024-11-07T20:54:52.760232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.combine import SMOTETomek  # Import SMOTE + Tomek Links\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_smote_tomek = []\n",
    "precision_list_smote_tomek = []\n",
    "recall_list_smote_tomek = []\n",
    "f1_list_smote_tomek = []\n",
    "entropy_list_smote_tomek = []\n",
    "confusion_matrices_smote_tomek = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Decision Tree model without SMOTE + Tomek Links\n",
    "    dt_model = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before SMOTE + Tomek Links\n",
    "    y_pred_before = dt_model.predict(X_test)\n",
    "    y_prob_before = dt_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before SMOTE + Tomek Links\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before SMOTE + Tomek Links\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before, average='weighted'))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before, average='weighted'))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before, average='weighted'))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply SMOTE + Tomek Links to the training data\n",
    "    smote_tomek = SMOTETomek(random_state=42)\n",
    "    X_train_smote_tomek, y_train_smote_tomek = smote_tomek.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Decision Tree model with SMOTE + Tomek Links\n",
    "    dt_model_smote_tomek = DecisionTreeClassifier(random_state=42)\n",
    "    dt_model_smote_tomek.fit(X_train_smote_tomek, y_train_smote_tomek)\n",
    "    \n",
    "    # Predictions and probabilities after SMOTE + Tomek Links\n",
    "    y_pred_smote_tomek = dt_model_smote_tomek.predict(X_test)\n",
    "    y_prob_smote_tomek = dt_model_smote_tomek.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after SMOTE + Tomek Links\n",
    "    entropy_smote_tomek = calculate_entropy(y_prob_smote_tomek)\n",
    "    entropy_list_smote_tomek.append(entropy_smote_tomek)\n",
    "    \n",
    "    # Store metrics after SMOTE + Tomek Links\n",
    "    accuracy_list_smote_tomek.append(accuracy_score(y_test, y_pred_smote_tomek))\n",
    "    precision_list_smote_tomek.append(precision_score(y_test, y_pred_smote_tomek))\n",
    "    recall_list_smote_tomek.append(recall_score(y_test, y_pred_smote_tomek))\n",
    "    f1_list_smote_tomek.append(f1_score(y_test, y_pred_smote_tomek))\n",
    "    confusion_matrices_smote_tomek.append(confusion_matrix(y_test, y_pred_smote_tomek))\n",
    "    \n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Oversampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_smote_tomek)} After SMOTE + Tomek Links:\\n', confusion_matrices_smote_tomek[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before oversampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after SMOTE + Tomek Links\n",
    "mean_accuracy_smote_tomek = np.mean(accuracy_list_smote_tomek)\n",
    "std_accuracy_smote_tomek = np.std(accuracy_list_smote_tomek)\n",
    "mean_precision_smote_tomek = np.mean(precision_list_smote_tomek)\n",
    "std_precision_smote_tomek = np.std(precision_list_smote_tomek)\n",
    "mean_recall_smote_tomek = np.mean(recall_list_smote_tomek)\n",
    "std_recall_smote_tomek = np.std(recall_list_smote_tomek)\n",
    "mean_f1_smote_tomek = np.mean(f1_list_smote_tomek)\n",
    "std_f1_smote_tomek = np.std(f1_list_smote_tomek)\n",
    "mean_entropy_smote_tomek = np.mean(entropy_list_smote_tomek)\n",
    "std_entropy_smote_tomek = np.std(entropy_list_smote_tomek)\n",
    "\n",
    "# Calculate mean confusion matrix before and after SMOTE + Tomek Links\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_smote_tomek = np.mean(confusion_matrices_smote_tomek, axis=0)\n",
    "\n",
    "# Print results before oversampling\n",
    "print('--- Before Oversampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after SMOTE + Tomek Links\n",
    "print('--- After SMOTE + Tomek Links ---')\n",
    "print('Mean Accuracy:', mean_accuracy_smote_tomek)\n",
    "print('Accuracy Std Dev:', std_accuracy_smote_tomek)\n",
    "print('Mean Precision:', mean_precision_smote_tomek)\n",
    "print('Precision Std Dev:', std_precision_smote_tomek)\n",
    "print('Mean Recall:', mean_recall_smote_tomek)\n",
    "print('Recall Std Dev:', std_recall_smote_tomek)\n",
    "print('Mean F1-score:', mean_f1_smote_tomek)\n",
    "print('F1-score Std Dev:', std_f1_smote_tomek)\n",
    "print('Mean Entropy:', mean_entropy_smote_tomek)\n",
    "print('Entropy Std Dev:', std_entropy_smote_tomek)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_smote_tomek)"
   ],
   "id": "33cf5e67053c5dba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Oversampling:\n",
      " [[79  2]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 1 After SMOTE + Tomek Links:\n",
      " [[74  7]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 2 Before Oversampling:\n",
      " [[81  0]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 2 After SMOTE + Tomek Links:\n",
      " [[75  6]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 3 Before Oversampling:\n",
      " [[80  1]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 3 After SMOTE + Tomek Links:\n",
      " [[77  4]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 4 Before Oversampling:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 4 After SMOTE + Tomek Links:\n",
      " [[74  6]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 5 Before Oversampling:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5 After SMOTE + Tomek Links:\n",
      " [[76  4]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 6 Before Oversampling:\n",
      " [[78  2]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 6 After SMOTE + Tomek Links:\n",
      " [[76  4]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 7 Before Oversampling:\n",
      " [[78  2]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 7 After SMOTE + Tomek Links:\n",
      " [[76  4]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 Before Oversampling:\n",
      " [[78  2]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After SMOTE + Tomek Links:\n",
      " [[76  4]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 9 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 9 After SMOTE + Tomek Links:\n",
      " [[75  5]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10 After SMOTE + Tomek Links:\n",
      " [[70 10]\n",
      " [ 0  5]]\n",
      "--- Before Oversampling ---\n",
      "Mean Accuracy: 0.9522435020519836\n",
      "Accuracy Std Dev: 0.01755545744264441\n",
      "Mean Precision: 0.948954276832516\n",
      "Precision Std Dev: 0.02142842458861133\n",
      "Mean Recall: 0.9522435020519836\n",
      "Recall Std Dev: 0.01755545744264441\n",
      "Mean F1-score: 0.9496421679863628\n",
      "F1-score Std Dev: 0.019720150679522156\n",
      "Mean Entropy: -1.0000000826903714e-10\n",
      "Entropy Std Dev: 5.780100247932768e-27\n",
      "Mean Confusion Matrix:\n",
      " [[78.6  1.7]\n",
      " [ 2.4  3.1]]\n",
      "--- After SMOTE + Tomek Links ---\n",
      "Mean Accuracy: 0.916060191518468\n",
      "Accuracy Std Dev: 0.018787147100628978\n",
      "Mean Precision: 0.4011904761904762\n",
      "Precision Std Dev: 0.11572356637505976\n",
      "Mean Recall: 0.6666666666666667\n",
      "Recall Std Dev: 0.24267032964268395\n",
      "Mean F1-score: 0.4916849816849817\n",
      "F1-score Std Dev: 0.14444092950763043\n",
      "Mean Entropy: 0.0047104604811903355\n",
      "Entropy Std Dev: 0.00642404803516301\n",
      "Mean Confusion Matrix:\n",
      " [[74.9  5.4]\n",
      " [ 1.8  3.7]]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "de1144619f960eb8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
