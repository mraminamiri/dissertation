{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T21:19:36.464759Z",
     "start_time": "2024-11-07T21:19:36.462800Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:19:39.412313Z",
     "start_time": "2024-11-07T21:19:39.388512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('cleaned_data.csv')\n",
    "data.head()"
   ],
   "id": "9952fe8070f2c48e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Age  Number of sexual partners  First sexual intercourse  \\\n",
       "0   18                          6                         5   \n",
       "1   15                          0                         4   \n",
       "2   34                          0                         5   \n",
       "3   52                          7                         6   \n",
       "4   46                          5                        11   \n",
       "\n",
       "   Num of pregnancies  Smokes  Smokes (years)  Smokes (packs/year)  \\\n",
       "0                   1       0               0                    0   \n",
       "1                   1       0               0                    0   \n",
       "2                   1       0               0                    0   \n",
       "3                   6       1              23                   49   \n",
       "4                   6       0               0                    0   \n",
       "\n",
       "   Hormonal Contraceptives  Hormonal Contraceptives (years)  IUD  ...  \\\n",
       "0                        0                                0    0  ...   \n",
       "1                        0                                0    0  ...   \n",
       "2                        0                                0    0  ...   \n",
       "3                        1                               29    0  ...   \n",
       "4                        1                               20    0  ...   \n",
       "\n",
       "   STDs: Time since first diagnosis  STDs: Time since last diagnosis  \\\n",
       "0                                 0                                0   \n",
       "1                                 0                                0   \n",
       "2                                 0                                0   \n",
       "3                                 0                                0   \n",
       "4                                 0                                0   \n",
       "\n",
       "   Dx:Cancer  Dx:CIN  Dx:HPV  Dx  Hinselmann  Schiller  Citology  Biopsy  \n",
       "0          0       0       0   0           0         0         0       0  \n",
       "1          0       0       0   0           0         0         0       0  \n",
       "2          0       0       0   0           0         0         0       0  \n",
       "3          1       0       1   0           0         0         0       0  \n",
       "4          0       0       0   0           0         0         0       0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of sexual partners</th>\n",
       "      <th>First sexual intercourse</th>\n",
       "      <th>Num of pregnancies</th>\n",
       "      <th>Smokes</th>\n",
       "      <th>Smokes (years)</th>\n",
       "      <th>Smokes (packs/year)</th>\n",
       "      <th>Hormonal Contraceptives</th>\n",
       "      <th>Hormonal Contraceptives (years)</th>\n",
       "      <th>IUD</th>\n",
       "      <th>...</th>\n",
       "      <th>STDs: Time since first diagnosis</th>\n",
       "      <th>STDs: Time since last diagnosis</th>\n",
       "      <th>Dx:Cancer</th>\n",
       "      <th>Dx:CIN</th>\n",
       "      <th>Dx:HPV</th>\n",
       "      <th>Dx</th>\n",
       "      <th>Hinselmann</th>\n",
       "      <th>Schiller</th>\n",
       "      <th>Citology</th>\n",
       "      <th>Biopsy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:19:43.830391Z",
     "start_time": "2024-11-07T21:19:43.824328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X=data.drop(['Biopsy'], axis=1)\n",
    "y=data['Biopsy']"
   ],
   "id": "2ae146e493a061c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:20:10.623410Z",
     "start_time": "2024-11-07T21:20:10.621179Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "14a70043fe9d4e9f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:20:17.542218Z",
     "start_time": "2024-11-07T21:20:13.197166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_smote = []\n",
    "precision_list_smote = []\n",
    "recall_list_smote = []\n",
    "f1_list_smote = []\n",
    "entropy_list_smote = []\n",
    "confusion_matrices_smote = []\n",
    "\n",
    "accuracy_list_adasyn = []\n",
    "precision_list_adasyn = []\n",
    "recall_list_adasyn = []\n",
    "f1_list_adasyn = []\n",
    "entropy_list_adasyn = []\n",
    "confusion_matrices_adasyn = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Random Forest model without SMOTE/ADASYN\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before SMOTE/ADASYN\n",
    "    y_pred_before = rf_model.predict(X_test)\n",
    "    y_prob_before = rf_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before SMOTE/ADASYN\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before SMOTE/ADASYN\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with SMOTE\n",
    "    rf_model_smote = RandomForestClassifier(random_state=42)\n",
    "    rf_model_smote.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # Predictions and probabilities after SMOTE\n",
    "    y_pred_smote = rf_model_smote.predict(X_test)\n",
    "    y_prob_smote = rf_model_smote.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after SMOTE\n",
    "    entropy_smote = calculate_entropy(y_prob_smote)\n",
    "    entropy_list_smote.append(entropy_smote)\n",
    "    \n",
    "    # Store metrics after SMOTE\n",
    "    accuracy_list_smote.append(accuracy_score(y_test, y_pred_smote))\n",
    "    precision_list_smote.append(precision_score(y_test, y_pred_smote))\n",
    "    recall_list_smote.append(recall_score(y_test, y_pred_smote))\n",
    "    f1_list_smote.append(f1_score(y_test, y_pred_smote))\n",
    "    confusion_matrices_smote.append(confusion_matrix(y_test, y_pred_smote))\n",
    "    \n",
    "    # Apply ADASYN to the training data\n",
    "    adasyn = ADASYN(random_state=42)\n",
    "    X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with ADASYN\n",
    "    rf_model_adasyn = RandomForestClassifier(random_state=42)\n",
    "    rf_model_adasyn.fit(X_train_adasyn, y_train_adasyn)\n",
    "    \n",
    "    # Predictions and probabilities after ADASYN\n",
    "    y_pred_adasyn = rf_model_adasyn.predict(X_test)\n",
    "    y_prob_adasyn = rf_model_adasyn.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ADASYN\n",
    "    entropy_adasyn = calculate_entropy(y_prob_adasyn)\n",
    "    entropy_list_adasyn.append(entropy_adasyn)\n",
    "    \n",
    "    # Store metrics after ADASYN\n",
    "    accuracy_list_adasyn.append(accuracy_score(y_test, y_pred_adasyn))\n",
    "    precision_list_adasyn.append(precision_score(y_test, y_pred_adasyn))\n",
    "    recall_list_adasyn.append(recall_score(y_test, y_pred_adasyn))\n",
    "    f1_list_adasyn.append(f1_score(y_test, y_pred_adasyn))\n",
    "    confusion_matrices_adasyn.append(confusion_matrix(y_test, y_pred_adasyn))\n",
    "    \n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Oversampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_smote)} After SMOTE:\\n', confusion_matrices_smote[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_adasyn)} After ADASYN:\\n', confusion_matrices_adasyn[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before oversampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after SMOTE\n",
    "mean_accuracy_smote = np.mean(accuracy_list_smote)\n",
    "std_accuracy_smote = np.std(accuracy_list_smote)\n",
    "mean_precision_smote = np.mean(precision_list_smote)\n",
    "std_precision_smote = np.std(precision_list_smote)\n",
    "mean_recall_smote = np.mean(recall_list_smote)\n",
    "std_recall_smote = np.std(recall_list_smote)\n",
    "mean_f1_smote = np.mean(f1_list_smote)\n",
    "std_f1_smote = np.std(f1_list_smote)\n",
    "mean_entropy_smote = np.mean(entropy_list_smote)\n",
    "std_entropy_smote = np.std(entropy_list_smote)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ADASYN\n",
    "mean_accuracy_adasyn = np.mean(accuracy_list_adasyn)\n",
    "std_accuracy_adasyn = np.std(accuracy_list_adasyn)\n",
    "mean_precision_adasyn = np.mean(precision_list_adasyn)\n",
    "std_precision_adasyn = np.std(precision_list_adasyn)\n",
    "mean_recall_adasyn = np.mean(recall_list_adasyn)\n",
    "std_recall_adasyn = np.std(recall_list_adasyn)\n",
    "mean_f1_adasyn = np.mean(f1_list_adasyn)\n",
    "std_f1_adasyn = np.std(f1_list_adasyn)\n",
    "mean_entropy_adasyn = np.mean(entropy_list_adasyn)\n",
    "std_entropy_adasyn = np.std(entropy_list_adasyn)\n",
    "\n",
    "# Calculate mean confusion matrix before and after SMOTE/ADASYN\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_smote = np.mean(confusion_matrices_smote, axis=0)\n",
    "mean_conf_matrix_adasyn = np.mean(confusion_matrices_adasyn, axis=0)\n",
    "\n",
    "# Print results before oversampling\n",
    "print('--- Before Oversampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after SMOTE\n",
    "print('--- After SMOTE ---')\n",
    "print('Mean Accuracy:', mean_accuracy_smote)\n",
    "print('Accuracy Std Dev:', std_accuracy_smote)\n",
    "print('Mean Precision:', mean_precision_smote)\n",
    "print('Precision Std Dev:', std_precision_smote)\n",
    "print('Mean Recall:', mean_recall_smote)\n",
    "print('Recall Std Dev:', std_recall_smote)\n",
    "print('Mean F1-score:', mean_f1_smote)\n",
    "print('F1-score Std Dev:', std_f1_smote)\n",
    "print('Mean Entropy:', mean_entropy_smote)\n",
    "print('Entropy Std Dev:', std_entropy_smote)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_smote)\n",
    "\n",
    "# Print results after ADASYN\n",
    "print('--- After ADASYN ---')\n",
    "print('Mean Accuracy:', mean_accuracy_adasyn)\n",
    "print('Accuracy Std Dev:', std_accuracy_adasyn)\n",
    "print('Mean Precision:', mean_precision_adasyn)\n",
    "print('Precision Std Dev:', std_precision_adasyn)\n",
    "print('Mean Recall:', mean_recall_adasyn)\n",
    "print('Recall Std Dev:', std_recall_adasyn)\n",
    "print('Mean F1-score:', mean_f1_adasyn)\n",
    "print('F1-score Std Dev:', std_f1_adasyn)\n",
    "print('Mean Entropy:', mean_entropy_adasyn)\n",
    "print('Entropy Std Dev:', std_entropy_adasyn)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_adasyn)\n"
   ],
   "id": "42732b120cfe59cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Oversampling:\n",
      " [[79  2]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 1 After SMOTE:\n",
      " [[79  2]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 1 After ADASYN:\n",
      " [[78  3]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 2 Before Oversampling:\n",
      " [[79  2]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 2 After SMOTE:\n",
      " [[76  5]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 2 After ADASYN:\n",
      " [[79  2]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 3 Before Oversampling:\n",
      " [[78  3]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 3 After SMOTE:\n",
      " [[79  2]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 3 After ADASYN:\n",
      " [[79  2]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 4 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 4  2]]\n",
      "Confusion Matrix for Fold 4 After SMOTE:\n",
      " [[78  2]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 4 After ADASYN:\n",
      " [[77  3]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 5 Before Oversampling:\n",
      " [[78  2]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5 After SMOTE:\n",
      " [[75  5]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 5 After ADASYN:\n",
      " [[75  5]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6 After SMOTE:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 6 After ADASYN:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 7 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 5  1]]\n",
      "Confusion Matrix for Fold 7 After SMOTE:\n",
      " [[76  4]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 7 After ADASYN:\n",
      " [[77  3]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 8 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 8 After SMOTE:\n",
      " [[78  2]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After ADASYN:\n",
      " [[78  2]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 9 Before Oversampling:\n",
      " [[78  2]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 9 After SMOTE:\n",
      " [[77  3]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 9 After ADASYN:\n",
      " [[77  3]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 10 After SMOTE:\n",
      " [[76  4]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 10 After ADASYN:\n",
      " [[77  3]\n",
      " [ 0  5]]\n",
      "--- Before Oversampling ---\n",
      "Mean Accuracy: 0.9510670314637484\n",
      "Accuracy Std Dev: 0.013510033025971506\n",
      "Mean Precision: 0.6316666666666666\n",
      "Precision Std Dev: 0.12482209562235189\n",
      "Mean Recall: 0.5266666666666666\n",
      "Recall Std Dev: 0.18666666666666665\n",
      "Mean F1-score: 0.5622727272727273\n",
      "F1-score Std Dev: 0.1622855534453249\n",
      "Mean Entropy: 0.11055509171004203\n",
      "Entropy Std Dev: 0.01938897295465343\n",
      "Mean Confusion Matrix:\n",
      " [[78.7  1.6]\n",
      " [ 2.6  2.9]]\n",
      "--- After SMOTE ---\n",
      "Mean Accuracy: 0.9475512995896033\n",
      "Accuracy Std Dev: 0.01744818425636246\n",
      "Mean Precision: 0.5732936507936508\n",
      "Precision Std Dev: 0.10783784735774042\n",
      "Mean Recall: 0.76\n",
      "Recall Std Dev: 0.14892205269125788\n",
      "Mean F1-score: 0.6486738261738261\n",
      "F1-score Std Dev: 0.11142462809142166\n",
      "Mean Entropy: 0.23426532997369764\n",
      "Entropy Std Dev: 0.03786601631636077\n",
      "Mean Confusion Matrix:\n",
      " [[77.1  3.2]\n",
      " [ 1.3  4.2]]\n",
      "--- After ADASYN ---\n",
      "Mean Accuracy: 0.9499042407660738\n",
      "Accuracy Std Dev: 0.011617892202936558\n",
      "Mean Precision: 0.5872619047619047\n",
      "Precision Std Dev: 0.05508200956553579\n",
      "Mean Recall: 0.7466666666666666\n",
      "Recall Std Dev: 0.16069294390925268\n",
      "Mean F1-score: 0.6509615384615385\n",
      "F1-score Std Dev: 0.08176997551340903\n",
      "Mean Entropy: 0.23570112142439098\n",
      "Entropy Std Dev: 0.03246976320226314\n",
      "Mean Confusion Matrix:\n",
      " [[77.4  2.9]\n",
      " [ 1.4  4.1]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:21:15.897501Z",
     "start_time": "2024-11-07T21:21:14.634558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "import numpy as np\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "uncertainty_list = []  # List to store entropy for each fold\n",
    "confusion_matrices = []\n",
    "\n",
    "# Choose an oversampling method\n",
    "# oversampler = SMOTE(random_state=42)\n",
    "# oversampler = ADASYN(random_state=42)\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Function to calculate entropy\n",
    "def calculate_entropy(probabilities):\n",
    "    entropy = -np.sum(probabilities * np.log(probabilities + 1e-9), axis=1)  # Add small value to avoid log(0)\n",
    "    return np.mean(entropy)\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply oversampling\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict probabilities and classes\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    y_prob_rf = rf_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate and store entropy\n",
    "    entropy = calculate_entropy(y_prob_rf)\n",
    "    uncertainty_list.append(entropy)\n",
    "    \n",
    "    # Store metrics\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred_rf))\n",
    "    precision_list.append(precision_score(y_test, y_pred_rf))\n",
    "    recall_list.append(recall_score(y_test, y_pred_rf))\n",
    "    f1_list.append(f1_score(y_test, y_pred_rf))\n",
    "    \n",
    "    # Store confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "    confusion_matrices.append(conf_matrix)\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices)}:\\n', conf_matrix)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "std_precision = np.std(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "std_recall = np.std(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "\n",
    "# Calculate mean and standard deviation of entropy\n",
    "mean_entropy = np.mean(uncertainty_list)\n",
    "std_entropy = np.std(uncertainty_list)\n",
    "\n",
    "# Calculate mean confusion matrix\n",
    "mean_conf_matrix = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "# Print results\n",
    "print('Mean Accuracy:', mean_accuracy)\n",
    "print('Accuracy Std Dev:', std_accuracy)\n",
    "print('Mean Precision:', mean_precision)\n",
    "print('Precision Std Dev:', std_precision)\n",
    "print('Mean Recall:', mean_recall)\n",
    "print('Recall Std Dev:', std_recall)\n",
    "print('Mean F1-score:', mean_f1)\n",
    "print('F1-score Std Dev:', std_f1)\n",
    "print('Mean Entropy:', mean_entropy)\n",
    "print('Entropy Std Dev:', std_entropy)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix)\n"
   ],
   "id": "f8123f3d7bba4951",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1:\n",
      " [[79  2]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 2:\n",
      " [[80  1]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 3:\n",
      " [[78  3]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 4:\n",
      " [[78  2]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5:\n",
      " [[78  2]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6:\n",
      " [[78  2]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 7:\n",
      " [[78  2]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 8:\n",
      " [[79  1]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 9:\n",
      " [[78  2]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10:\n",
      " [[79  1]\n",
      " [ 2  3]]\n",
      "Mean Accuracy: 0.9568946648426813\n",
      "Accuracy Std Dev: 0.010402376240637098\n",
      "Mean Precision: 0.6664285714285714\n",
      "Precision Std Dev: 0.08582301305105175\n",
      "Mean Recall: 0.6499999999999999\n",
      "Recall Std Dev: 0.13519533193782166\n",
      "Mean F1-score: 0.6520745920745922\n",
      "F1-score Std Dev: 0.10072137805125708\n",
      "Mean Entropy: 0.11737405109532713\n",
      "Entropy Std Dev: 0.022804237262156444\n",
      "Mean Confusion Matrix:\n",
      " [[78.5  1.8]\n",
      " [ 1.9  3.6]]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:22:04.028501Z",
     "start_time": "2024-11-07T21:21:58.587919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks, RandomUnderSampler\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "accuracy_list_random = []\n",
    "precision_list_random = []\n",
    "recall_list_random = []\n",
    "f1_list_random = []\n",
    "entropy_list_random = []\n",
    "confusion_matrices_random = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Random Forest model without undersampling\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = rf_model.predict(X_test)\n",
    "    y_prob_before = rf_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with NearMiss\n",
    "    rf_model_nearmiss = RandomForestClassifier(random_state=42)\n",
    "    rf_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = rf_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = rf_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with ClusterCentroids\n",
    "    rf_model_clustercentroids = RandomForestClassifier(random_state=42)\n",
    "    rf_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = rf_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = rf_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with TomekLinks\n",
    "    rf_model_tomeklinks = RandomForestClassifier(random_state=42)\n",
    "    rf_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = rf_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = rf_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Apply RandomUnderSampler to the training data\n",
    "    randomundersampler = RandomUnderSampler(random_state=42)\n",
    "    X_train_random, y_train_random = randomundersampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with RandomUnderSampler\n",
    "    rf_model_random = RandomForestClassifier(random_state=42)\n",
    "    rf_model_random.fit(X_train_random, y_train_random)\n",
    "    \n",
    "    # Predictions and probabilities after RandomUnderSampler\n",
    "    y_pred_random = rf_model_random.predict(X_test)\n",
    "    y_prob_random = rf_model_random.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after RandomUnderSampler\n",
    "    entropy_random = calculate_entropy(y_prob_random)\n",
    "    entropy_list_random.append(entropy_random)\n",
    "    \n",
    "    # Store metrics after RandomUnderSampler\n",
    "    accuracy_list_random.append(accuracy_score(y_test, y_pred_random))\n",
    "    precision_list_random.append(precision_score(y_test, y_pred_random))\n",
    "    recall_list_random.append(recall_score(y_test, y_pred_random))\n",
    "    f1_list_random.append(f1_score(y_test, y_pred_random))\n",
    "    confusion_matrices_random.append(confusion_matrix(y_test, y_pred_random))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_random)} After RandomUnderSampler:\\n', confusion_matrices_random[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after RandomUnderSampler\n",
    "mean_accuracy_random = np.mean(accuracy_list_random)\n",
    "std_accuracy_random = np.std(accuracy_list_random)\n",
    "mean_precision_random = np.mean(precision_list_random)\n",
    "std_precision_random = np.std(precision_list_random)\n",
    "mean_recall_random = np.mean(recall_list_random)\n",
    "std_recall_random = np.std(recall_list_random)\n",
    "mean_f1_random = np.mean(f1_list_random)\n",
    "std_f1_random = np.std(f1_list_random)\n",
    "mean_entropy_random = np.mean(entropy_list_random)\n",
    "std_entropy_random = np.std(entropy_list_random)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "mean_conf_matrix_random = np.mean(confusion_matrices_random, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n",
    "\n",
    "# Print results after RandomUnderSampler\n",
    "print('--- After RandomUnderSampler ---')\n",
    "print('Mean Accuracy:', mean_accuracy_random)\n",
    "print('Accuracy Std Dev:', std_accuracy_random)\n",
    "print('Mean Precision:', mean_precision_random)\n",
    "print('Precision Std Dev:', std_precision_random)\n",
    "print('Mean Recall:', mean_recall_random)\n",
    "print('Recall Std Dev:', std_recall_random)\n",
    "print('Mean F1-score:', mean_f1_random)\n",
    "print('F1-score Std Dev:', std_f1_random)\n",
    "print('Mean Entropy:', mean_entropy_random)\n",
    "print('Entropy Std Dev:', std_entropy_random)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_random)\n"
   ],
   "id": "4ead439d3a967a45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[79  2]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[28 53]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[70 11]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[79  2]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 1 After RandomUnderSampler:\n",
      " [[72  9]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[79  2]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[38 43]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[75  6]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[80  1]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 2 After RandomUnderSampler:\n",
      " [[78  3]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[78  3]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[35 46]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[68 13]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[78  3]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 3 After RandomUnderSampler:\n",
      " [[77  4]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[79  1]\n",
      " [ 4  2]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[38 42]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[68 12]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[79  1]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 4 After RandomUnderSampler:\n",
      " [[71  9]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[78  2]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[36 44]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[66 14]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[78  2]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5 After RandomUnderSampler:\n",
      " [[74  6]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[79  1]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[38 42]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[70 10]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[79  1]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 6 After RandomUnderSampler:\n",
      " [[74  6]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[79  1]\n",
      " [ 5  1]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[33 47]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[65 15]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[78  2]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 7 After RandomUnderSampler:\n",
      " [[69 11]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[79  1]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[37 43]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[68 12]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[79  1]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 8 After RandomUnderSampler:\n",
      " [[77  3]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[78  2]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[39 41]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[67 13]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[78  2]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 9 After RandomUnderSampler:\n",
      " [[77  3]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[79  1]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[30 50]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[72  8]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[79  1]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 10 After RandomUnderSampler:\n",
      " [[73  7]\n",
      " [ 0  5]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9510670314637484\n",
      "Accuracy Std Dev: 0.013510033025971506\n",
      "Mean Precision: 0.6316666666666666\n",
      "Precision Std Dev: 0.12482209562235189\n",
      "Mean Recall: 0.5266666666666666\n",
      "Recall Std Dev: 0.18666666666666665\n",
      "Mean F1-score: 0.5622727272727273\n",
      "F1-score Std Dev: 0.1622855534453249\n",
      "Mean Entropy: 0.11055509171004203\n",
      "Entropy Std Dev: 0.01938897295465343\n",
      "Mean Confusion Matrix:\n",
      " [[78.7  1.6]\n",
      " [ 2.6  2.9]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.47084815321477425\n",
      "Accuracy Std Dev: 0.04225126494240287\n",
      "Mean Precision: 0.10375913548021734\n",
      "Precision Std Dev: 0.015805338102007765\n",
      "Mean Recall: 0.9466666666666667\n",
      "Recall Std Dev: 0.11075498483890765\n",
      "Mean F1-score: 0.1867534786551322\n",
      "F1-score Std Dev: 0.02710813199538727\n",
      "Mean Entropy: 0.47349945439817365\n",
      "Entropy Std Dev: 0.026706244743680545\n",
      "Mean Confusion Matrix:\n",
      " [[35.2 45.1]\n",
      " [ 0.3  5.2]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.8625034199726402\n",
      "Accuracy Std Dev: 0.028784157416069746\n",
      "Mean Precision: 0.31566858794799973\n",
      "Precision Std Dev: 0.04690687703667107\n",
      "Mean Recall: 0.9266666666666667\n",
      "Recall Std Dev: 0.09043106644167022\n",
      "Mean F1-score: 0.46804543282804156\n",
      "F1-score Std Dev: 0.05175687524775405\n",
      "Mean Entropy: 0.5343099138842111\n",
      "Entropy Std Dev: 0.022293462870860085\n",
      "Mean Confusion Matrix:\n",
      " [[68.9 11.4]\n",
      " [ 0.4  5.1]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9487551299589603\n",
      "Accuracy Std Dev: 0.02086694113419637\n",
      "Mean Precision: 0.5466666666666666\n",
      "Precision Std Dev: 0.293238621073161\n",
      "Mean Recall: 0.48666666666666664\n",
      "Recall Std Dev: 0.294089933334837\n",
      "Mean F1-score: 0.5052380952380953\n",
      "F1-score Std Dev: 0.2876947268239059\n",
      "Mean Entropy: 0.1117161285881266\n",
      "Entropy Std Dev: 0.01996370765258504\n",
      "Mean Confusion Matrix:\n",
      " [[78.7  1.6]\n",
      " [ 2.8  2.7]]\n",
      "--- After RandomUnderSampler ---\n",
      "Mean Accuracy: 0.9196169630642956\n",
      "Accuracy Std Dev: 0.027676092193648152\n",
      "Mean Precision: 0.458941303794245\n",
      "Precision Std Dev: 0.09359073515347809\n",
      "Mean Recall: 0.8533333333333333\n",
      "Recall Std Dev: 0.116619037896906\n",
      "Mean F1-score: 0.5860379849880456\n",
      "F1-score Std Dev: 0.07209028106910778\n",
      "Mean Entropy: 0.3842902638823703\n",
      "Entropy Std Dev: 0.036175200163440405\n",
      "Mean Confusion Matrix:\n",
      " [[74.2  6.1]\n",
      " [ 0.8  4.7]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:23:43.595342Z",
     "start_time": "2024-11-07T21:23:36.561669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Function to find the best threshold for F1-score\n",
    "def find_best_threshold(y_true, y_prob, thresholds):\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0.5\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob[:, 1] >= threshold).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "best_thresholds = []\n",
    "f1_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "roc_auc_list = []\n",
    "entropy_list = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Random Forest model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calibrate the model\n",
    "    calibrated_model = CalibratedClassifierCV(rf_model, method='isotonic', cv=5)\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predicted probabilities on training set\n",
    "    y_prob_train = calibrated_model.predict_proba(X_train)\n",
    "    \n",
    "    # Define a range of thresholds to test\n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "    \n",
    "    # Find the best threshold based on training set\n",
    "    best_threshold, _ = find_best_threshold(y_train, y_prob_train, thresholds)\n",
    "    best_thresholds.append(best_threshold)\n",
    "    \n",
    "    # Get predicted probabilities on test set\n",
    "    y_prob_test = calibrated_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy\n",
    "    entropy = calculate_entropy(y_prob_test)\n",
    "    entropy_list.append(entropy)\n",
    "    \n",
    "    # Make predictions using the best threshold\n",
    "    y_pred = (y_prob_test[:, 1] >= best_threshold).astype(int)\n",
    "    \n",
    "    # Calculate and store ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_prob_test[:, 1])\n",
    "    roc_auc_list.append(roc_auc)\n",
    "    \n",
    "    # Store the metrics\n",
    "    f1_list.append(f1_score(y_test, y_pred))\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    precision_list.append(precision_score(y_test, y_pred))\n",
    "    recall_list.append(recall_score(y_test, y_pred))\n",
    "    confusion_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(f'Best Threshold for Fold {len(best_thresholds)}: {best_threshold}')\n",
    "    print(f'Confusion Matrix for Fold {len(best_thresholds)}:\\n', confusion_matrices[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "std_precision = np.std(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "std_recall = np.std(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "mean_roc_auc = np.mean(roc_auc_list)\n",
    "std_roc_auc = np.std(roc_auc_list)\n",
    "mean_entropy = np.mean(entropy_list)\n",
    "std_entropy = np.std(entropy_list)\n",
    "\n",
    "# Calculate mean confusion matrix\n",
    "mean_conf_matrix = np.mean(confusion_matrices, axis=0).astype(int)\n",
    "\n",
    "# Print the results\n",
    "print('--- Overall Results ---')\n",
    "print('Mean Accuracy:', mean_accuracy)\n",
    "print('Accuracy Std Dev:', std_accuracy)\n",
    "print('Mean Precision:', mean_precision)\n",
    "print('Precision Std Dev:', std_precision)\n",
    "print('Mean Recall:', mean_recall)\n",
    "print('Recall Std Dev:', std_recall)\n",
    "print('Mean F1-score:', mean_f1)\n",
    "print('F1-score Std Dev:', std_f1)\n",
    "print('Mean ROC AUC:', mean_roc_auc)\n",
    "print('ROC AUC Std Dev:', std_roc_auc)\n",
    "print('Mean Entropy:', mean_entropy)\n",
    "print('Entropy Std Dev:', std_entropy)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix)"
   ],
   "id": "a2cb75951acf20cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold for Fold 1: 0.45999999999999985\n",
      "Confusion Matrix for Fold 1:\n",
      " [[78  3]\n",
      " [ 1  4]]\n",
      "Best Threshold for Fold 2: 0.43999999999999984\n",
      "Confusion Matrix for Fold 2:\n",
      " [[79  2]\n",
      " [ 2  3]]\n",
      "Best Threshold for Fold 3: 0.3999999999999998\n",
      "Confusion Matrix for Fold 3:\n",
      " [[78  3]\n",
      " [ 2  3]]\n",
      "Best Threshold for Fold 4: 0.4099999999999998\n",
      "Confusion Matrix for Fold 4:\n",
      " [[79  1]\n",
      " [ 2  4]]\n",
      "Best Threshold for Fold 5: 0.30999999999999994\n",
      "Confusion Matrix for Fold 5:\n",
      " [[78  2]\n",
      " [ 1  5]]\n",
      "Best Threshold for Fold 6: 0.29999999999999993\n",
      "Confusion Matrix for Fold 6:\n",
      " [[77  3]\n",
      " [ 1  5]]\n",
      "Best Threshold for Fold 7: 0.4299999999999998\n",
      "Confusion Matrix for Fold 7:\n",
      " [[78  2]\n",
      " [ 1  5]]\n",
      "Best Threshold for Fold 8: 0.4199999999999998\n",
      "Confusion Matrix for Fold 8:\n",
      " [[79  1]\n",
      " [ 1  5]]\n",
      "Best Threshold for Fold 9: 0.46999999999999986\n",
      "Confusion Matrix for Fold 9:\n",
      " [[78  2]\n",
      " [ 1  4]]\n",
      "Best Threshold for Fold 10: 0.5399999999999998\n",
      "Confusion Matrix for Fold 10:\n",
      " [[79  1]\n",
      " [ 2  3]]\n",
      "--- Overall Results ---\n",
      "Mean Accuracy: 0.9603830369357045\n",
      "Accuracy Std Dev: 0.009262649757019887\n",
      "Mean Precision: 0.6775\n",
      "Precision Std Dev: 0.09944353392709504\n",
      "Mean Recall: 0.74\n",
      "Recall Std Dev: 0.10306416555826875\n",
      "Mean F1-score: 0.7019413919413919\n",
      "F1-score Std Dev: 0.08069949891354122\n",
      "Mean ROC AUC: 0.945162037037037\n",
      "ROC AUC Std Dev: 0.04435657143888067\n",
      "Mean Entropy: 0.1054271314142278\n",
      "Entropy Std Dev: 0.019884111193559022\n",
      "Mean Confusion Matrix:\n",
      " [[78  2]\n",
      " [ 1  4]]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:25:13.685742Z",
     "start_time": "2024-11-07T21:25:10.975881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.combine import SMOTETomek  # Import SMOTE + Tomek Links\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_smote_tomek = []\n",
    "precision_list_smote_tomek = []\n",
    "recall_list_smote_tomek = []\n",
    "f1_list_smote_tomek = []\n",
    "entropy_list_smote_tomek = []\n",
    "confusion_matrices_smote_tomek = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Random Forest model without SMOTE + Tomek Links\n",
    "    rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before SMOTE + Tomek Links\n",
    "    y_pred_before = rf_model.predict(X_test)\n",
    "    y_prob_before = rf_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before SMOTE + Tomek Links\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before SMOTE + Tomek Links\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before, average='weighted'))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before, average='weighted'))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before, average='weighted'))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply SMOTE + Tomek Links to the training data\n",
    "    smote_tomek = SMOTETomek(random_state=42)\n",
    "    X_train_smote_tomek, y_train_smote_tomek = smote_tomek.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with SMOTE + Tomek Links\n",
    "    rf_model_smote_tomek = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "    rf_model_smote_tomek.fit(X_train_smote_tomek, y_train_smote_tomek)\n",
    "    \n",
    "    # Predictions and probabilities after SMOTE + Tomek Links\n",
    "    y_pred_smote_tomek = rf_model_smote_tomek.predict(X_test)\n",
    "    y_prob_smote_tomek = rf_model_smote_tomek.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after SMOTE + Tomek Links\n",
    "    entropy_smote_tomek = calculate_entropy(y_prob_smote_tomek)\n",
    "    entropy_list_smote_tomek.append(entropy_smote_tomek)\n",
    "    \n",
    "    # Store metrics after SMOTE + Tomek Links\n",
    "    accuracy_list_smote_tomek.append(accuracy_score(y_test, y_pred_smote_tomek))\n",
    "    precision_list_smote_tomek.append(precision_score(y_test, y_pred_smote_tomek))\n",
    "    recall_list_smote_tomek.append(recall_score(y_test, y_pred_smote_tomek))\n",
    "    f1_list_smote_tomek.append(f1_score(y_test, y_pred_smote_tomek))\n",
    "    confusion_matrices_smote_tomek.append(confusion_matrix(y_test, y_pred_smote_tomek))\n",
    "    \n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Oversampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_smote_tomek)} After SMOTE + Tomek Links:\\n', confusion_matrices_smote_tomek[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before oversampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after SMOTE + Tomek Links\n",
    "mean_accuracy_smote_tomek = np.mean(accuracy_list_smote_tomek)\n",
    "std_accuracy_smote_tomek = np.std(accuracy_list_smote_tomek)\n",
    "mean_precision_smote_tomek = np.mean(precision_list_smote_tomek)\n",
    "std_precision_smote_tomek = np.std(precision_list_smote_tomek)\n",
    "mean_recall_smote_tomek = np.mean(recall_list_smote_tomek)\n",
    "std_recall_smote_tomek = np.std(recall_list_smote_tomek)\n",
    "mean_f1_smote_tomek = np.mean(f1_list_smote_tomek)\n",
    "std_f1_smote_tomek = np.std(f1_list_smote_tomek)\n",
    "mean_entropy_smote_tomek = np.mean(entropy_list_smote_tomek)\n",
    "std_entropy_smote_tomek = np.std(entropy_list_smote_tomek)\n",
    "\n",
    "# Calculate mean confusion matrix before and after SMOTE + Tomek Links\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_smote_tomek = np.mean(confusion_matrices_smote_tomek, axis=0)\n",
    "\n",
    "# Print results before oversampling\n",
    "print('--- Before Oversampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after SMOTE + Tomek Links\n",
    "print('--- After SMOTE + Tomek Links ---')\n",
    "print('Mean Accuracy:', mean_accuracy_smote_tomek)\n",
    "print('Accuracy Std Dev:', std_accuracy_smote_tomek)\n",
    "print('Mean Precision:', mean_precision_smote_tomek)\n",
    "print('Precision Std Dev:', std_precision_smote_tomek)\n",
    "print('Mean Recall:', mean_recall_smote_tomek)\n",
    "print('Recall Std Dev:', std_recall_smote_tomek)\n",
    "print('Mean F1-score:', mean_f1_smote_tomek)\n",
    "print('F1-score Std Dev:', std_f1_smote_tomek)\n",
    "print('Mean Entropy:', mean_entropy_smote_tomek)\n",
    "print('Entropy Std Dev:', std_entropy_smote_tomek)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_smote_tomek)"
   ],
   "id": "5ff9c5fa054776e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Oversampling:\n",
      " [[79  2]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 1 After SMOTE + Tomek Links:\n",
      " [[78  3]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 2 Before Oversampling:\n",
      " [[79  2]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 2 After SMOTE + Tomek Links:\n",
      " [[77  4]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 3 Before Oversampling:\n",
      " [[78  3]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 3 After SMOTE + Tomek Links:\n",
      " [[78  3]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 4 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 4  2]]\n",
      "Confusion Matrix for Fold 4 After SMOTE + Tomek Links:\n",
      " [[77  3]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 5 Before Oversampling:\n",
      " [[78  2]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5 After SMOTE + Tomek Links:\n",
      " [[75  5]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6 After SMOTE + Tomek Links:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 7 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 5  1]]\n",
      "Confusion Matrix for Fold 7 After SMOTE + Tomek Links:\n",
      " [[76  4]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 8 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 8 After SMOTE + Tomek Links:\n",
      " [[78  2]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 9 Before Oversampling:\n",
      " [[78  2]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 9 After SMOTE + Tomek Links:\n",
      " [[76  4]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 10 Before Oversampling:\n",
      " [[79  1]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 10 After SMOTE + Tomek Links:\n",
      " [[76  4]\n",
      " [ 0  5]]\n",
      "--- Before Oversampling ---\n",
      "Mean Accuracy: 0.9510670314637484\n",
      "Accuracy Std Dev: 0.013510033025971506\n",
      "Mean Precision: 0.947029329497701\n",
      "Precision Std Dev: 0.0181234567838766\n",
      "Mean Recall: 0.9510670314637484\n",
      "Recall Std Dev: 0.013510033025971506\n",
      "Mean F1-score: 0.9477954800665793\n",
      "F1-score Std Dev: 0.017153689851946277\n",
      "Mean Entropy: 0.11055509171004203\n",
      "Entropy Std Dev: 0.01938897295465343\n",
      "Mean Confusion Matrix:\n",
      " [[78.7  1.6]\n",
      " [ 2.6  2.9]]\n",
      "--- After SMOTE + Tomek Links ---\n",
      "Mean Accuracy: 0.9428864569083448\n",
      "Accuracy Std Dev: 0.01515040931575353\n",
      "Mean Precision: 0.5341269841269841\n",
      "Precision Std Dev: 0.10402882035692133\n",
      "Mean Recall: 0.74\n",
      "Recall Std Dev: 0.1793816539609828\n",
      "Mean F1-score: 0.6171087246087247\n",
      "F1-score Std Dev: 0.12399138104685455\n",
      "Mean Entropy: 0.23482729242460954\n",
      "Entropy Std Dev: 0.03197830016741906\n",
      "Mean Confusion Matrix:\n",
      " [[76.8  3.5]\n",
      " [ 1.4  4.1]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d47c5d3646e71419"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
