{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T21:07:27.730165Z",
     "start_time": "2024-11-07T21:07:27.727931Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:07:34.371556Z",
     "start_time": "2024-11-07T21:07:34.349021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('cleaned_data.csv')\n",
    "data.head()"
   ],
   "id": "66e17cc22cb7807b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Age  Number of sexual partners  First sexual intercourse  \\\n",
       "0   18                          6                         5   \n",
       "1   15                          0                         4   \n",
       "2   34                          0                         5   \n",
       "3   52                          7                         6   \n",
       "4   46                          5                        11   \n",
       "\n",
       "   Num of pregnancies  Smokes  Smokes (years)  Smokes (packs/year)  \\\n",
       "0                   1       0               0                    0   \n",
       "1                   1       0               0                    0   \n",
       "2                   1       0               0                    0   \n",
       "3                   6       1              23                   49   \n",
       "4                   6       0               0                    0   \n",
       "\n",
       "   Hormonal Contraceptives  Hormonal Contraceptives (years)  IUD  ...  \\\n",
       "0                        0                                0    0  ...   \n",
       "1                        0                                0    0  ...   \n",
       "2                        0                                0    0  ...   \n",
       "3                        1                               29    0  ...   \n",
       "4                        1                               20    0  ...   \n",
       "\n",
       "   STDs: Time since first diagnosis  STDs: Time since last diagnosis  \\\n",
       "0                                 0                                0   \n",
       "1                                 0                                0   \n",
       "2                                 0                                0   \n",
       "3                                 0                                0   \n",
       "4                                 0                                0   \n",
       "\n",
       "   Dx:Cancer  Dx:CIN  Dx:HPV  Dx  Hinselmann  Schiller  Citology  Biopsy  \n",
       "0          0       0       0   0           0         0         0       0  \n",
       "1          0       0       0   0           0         0         0       0  \n",
       "2          0       0       0   0           0         0         0       0  \n",
       "3          1       0       1   0           0         0         0       0  \n",
       "4          0       0       0   0           0         0         0       0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of sexual partners</th>\n",
       "      <th>First sexual intercourse</th>\n",
       "      <th>Num of pregnancies</th>\n",
       "      <th>Smokes</th>\n",
       "      <th>Smokes (years)</th>\n",
       "      <th>Smokes (packs/year)</th>\n",
       "      <th>Hormonal Contraceptives</th>\n",
       "      <th>Hormonal Contraceptives (years)</th>\n",
       "      <th>IUD</th>\n",
       "      <th>...</th>\n",
       "      <th>STDs: Time since first diagnosis</th>\n",
       "      <th>STDs: Time since last diagnosis</th>\n",
       "      <th>Dx:Cancer</th>\n",
       "      <th>Dx:CIN</th>\n",
       "      <th>Dx:HPV</th>\n",
       "      <th>Dx</th>\n",
       "      <th>Hinselmann</th>\n",
       "      <th>Schiller</th>\n",
       "      <th>Citology</th>\n",
       "      <th>Biopsy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:07:39.844234Z",
     "start_time": "2024-11-07T21:07:39.837135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X=data.drop(['Biopsy'], axis=1)\n",
    "y=data['Biopsy']"
   ],
   "id": "af42e6bd9787da41",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Over Sampling\n",
    "\n"
   ],
   "id": "86ec4bba947e983"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:08:08.787322Z",
     "start_time": "2024-11-07T21:08:03.504907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "import numpy as np\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "uncertainty_list = []  # List to store entropy for each fold\n",
    "confusion_matrices = []\n",
    "\n",
    "# Choose an oversampling method\n",
    "oversampler = SMOTE(random_state=42)\n",
    "# oversampler = ADASYN(random_state=42)\n",
    "#oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Function to calculate entropy\n",
    "def calculate_entropy(probabilities):\n",
    "    entropy = -np.sum(probabilities * np.log(probabilities + 1e-9), axis=1)  # Add small value to avoid log(0)\n",
    "    return np.mean(entropy)\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply oversampling\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with probability enabled\n",
    "    svm_model = SVC(probability=True, random_state=42)\n",
    "    svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict probabilities and classes\n",
    "    y_pred_svm = svm_model.predict(X_test)\n",
    "    y_prob_svm = svm_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate and store entropy\n",
    "    entropy = calculate_entropy(y_prob_svm)\n",
    "    uncertainty_list.append(entropy)\n",
    "    \n",
    "    # Store metrics\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred_svm))\n",
    "    precision_list.append(precision_score(y_test, y_pred_svm))\n",
    "    recall_list.append(recall_score(y_test, y_pred_svm))\n",
    "    f1_list.append(f1_score(y_test, y_pred_svm))\n",
    "    \n",
    "    # Store confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_svm)\n",
    "    confusion_matrices.append(conf_matrix)\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices)}:\\n', conf_matrix)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "std_precision = np.std(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "std_recall = np.std(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "\n",
    "# Calculate mean and standard deviation of entropy\n",
    "mean_entropy = np.mean(uncertainty_list)\n",
    "std_entropy = np.std(uncertainty_list)\n",
    "\n",
    "# Calculate mean confusion matrix\n",
    "mean_conf_matrix = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "# Print results\n",
    "print('Mean Accuracy:', mean_accuracy)\n",
    "print('Accuracy Std Dev:', std_accuracy)\n",
    "print('Mean Precision:', mean_precision)\n",
    "print('Precision Std Dev:', std_precision)\n",
    "print('Mean Recall:', mean_recall)\n",
    "print('Recall Std Dev:', std_recall)\n",
    "print('Mean F1-score:', mean_f1)\n",
    "print('F1-score Std Dev:', std_f1)\n",
    "print('Mean Entropy:', mean_entropy)\n",
    "print('Entropy Std Dev:', std_entropy)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix)\n"
   ],
   "id": "64e081fee88cc199",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1:\n",
      " [[66 15]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 2:\n",
      " [[67 14]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 3:\n",
      " [[60 21]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 4:\n",
      " [[70 10]\n",
      " [ 4  2]]\n",
      "Confusion Matrix for Fold 5:\n",
      " [[64 16]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6:\n",
      " [[65 15]\n",
      " [ 5  1]]\n",
      "Confusion Matrix for Fold 7:\n",
      " [[56 24]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 8:\n",
      " [[62 18]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 9:\n",
      " [[65 15]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 10:\n",
      " [[65 15]\n",
      " [ 1  4]]\n",
      "Mean Accuracy: 0.773953488372093\n",
      "Accuracy Std Dev: 0.04202025954880806\n",
      "Mean Precision: 0.1265526721748959\n",
      "Precision Std Dev: 0.05919942172024951\n",
      "Mean Recall: 0.4333333333333333\n",
      "Recall Std Dev: 0.22261077142752\n",
      "Mean F1-score: 0.19407888407888407\n",
      "F1-score Std Dev: 0.0917841191842333\n",
      "Mean Entropy: 0.510744657641474\n",
      "Entropy Std Dev: 0.02766867542750917\n",
      "Mean Confusion Matrix:\n",
      " [[64.  16.3]\n",
      " [ 3.1  2.4]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:09:24.172492Z",
     "start_time": "2024-11-07T21:09:20.288184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks, RandomUnderSampler\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "accuracy_list_random = []\n",
    "precision_list_random = []\n",
    "recall_list_random = []\n",
    "f1_list_random = []\n",
    "entropy_list_random = []\n",
    "confusion_matrices_random = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the SVM model without undersampling\n",
    "    svm_model = SVC(probability=True, random_state=42)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = svm_model.predict(X_test)\n",
    "    y_prob_before = svm_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with NearMiss\n",
    "    svm_model_nearmiss = SVC(probability=True, random_state=42)\n",
    "    svm_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = svm_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = svm_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with ClusterCentroids\n",
    "    svm_model_clustercentroids = SVC(probability=True, random_state=42)\n",
    "    svm_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = svm_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = svm_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with TomekLinks\n",
    "    svm_model_tomeklinks = SVC(probability=True, random_state=42)\n",
    "    svm_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = svm_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = svm_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Apply RandomUnderSampler to the training data\n",
    "    random_undersampler = RandomUnderSampler(random_state=42)\n",
    "    X_train_random, y_train_random = random_undersampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with RandomUnderSampler\n",
    "    svm_model_random = SVC(probability=True, random_state=42)\n",
    "    svm_model_random.fit(X_train_random, y_train_random)\n",
    "    \n",
    "    # Predictions and probabilities after RandomUnderSampler\n",
    "    y_pred_random = svm_model_random.predict(X_test)\n",
    "    y_prob_random = svm_model_random.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after RandomUnderSampler\n",
    "    entropy_random = calculate_entropy(y_prob_random)\n",
    "    entropy_list_random.append(entropy_random)\n",
    "    \n",
    "    # Store metrics after RandomUnderSampler\n",
    "    accuracy_list_random.append(accuracy_score(y_test, y_pred_random))\n",
    "    precision_list_random.append(precision_score(y_test, y_pred_random))\n",
    "    recall_list_random.append(recall_score(y_test, y_pred_random))\n",
    "    f1_list_random.append(f1_score(y_test, y_pred_random))\n",
    "    confusion_matrices_random.append(confusion_matrix(y_test, y_pred_random))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_random)} After RandomUnderSampler:\\n', confusion_matrices_random[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after RandomUnderSampler\n",
    "mean_accuracy_random = np.mean(accuracy_list_random)\n",
    "std_accuracy_random = np.std(accuracy_list_random)\n",
    "mean_precision_random = np.mean(precision_list_random)\n",
    "std_precision_random = np.std(precision_list_random)\n",
    "mean_recall_random = np.mean(recall_list_random)\n",
    "std_recall_random = np.std(recall_list_random)\n",
    "mean_f1_random = np.mean(f1_list_random)\n",
    "std_f1_random = np.std(f1_list_random)\n",
    "mean_entropy_random = np.mean(entropy_list_random)\n",
    "std_entropy_random = np.std(entropy_list_random)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "mean_conf_matrix_random = np.mean(confusion_matrices_random, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n",
    "\n",
    "# Print results after RandomUnderSampler\n",
    "print('--- After RandomUnderSampler ---')\n",
    "print('Mean Accuracy:', mean_accuracy_random)\n",
    "print('Accuracy Std Dev:', std_accuracy_random)\n",
    "print('Mean Precision:', mean_precision_random)\n",
    "print('Precision Std Dev:', std_precision_random)\n",
    "print('Mean Recall:', mean_recall_random)\n",
    "print('Recall Std Dev:', std_recall_random)\n",
    "print('Mean F1-score:', mean_f1_random)\n",
    "print('F1-score Std Dev:', std_f1_random)\n",
    "print('Mean Entropy:', mean_entropy_random)\n",
    "print('Entropy Std Dev:', std_entropy_random)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_random)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks, RandomUnderSampler\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "accuracy_list_random = []\n",
    "precision_list_random = []\n",
    "recall_list_random = []\n",
    "f1_list_random = []\n",
    "entropy_list_random = []\n",
    "confusion_matrices_random = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the SVM model without undersampling\n",
    "    svm_model = SVC(probability=True, random_state=42)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = svm_model.predict(X_test)\n",
    "    y_prob_before = svm_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with NearMiss\n",
    "    svm_model_nearmiss = SVC(probability=True, random_state=42)\n",
    "    svm_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = svm_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = svm_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with ClusterCentroids\n",
    "    svm_model_clustercentroids = SVC(probability=True, random_state=42)\n",
    "    svm_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = svm_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = svm_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with TomekLinks\n",
    "    svm_model_tomeklinks = SVC(probability=True, random_state=42)\n",
    "    svm_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = svm_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = svm_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Apply RandomUnderSampler to the training data\n",
    "    random_undersampler = RandomUnderSampler(random_state=42)\n",
    "    X_train_random, y_train_random = random_undersampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with RandomUnderSampler\n",
    "    svm_model_random = SVC(probability=True, random_state=42)\n",
    "    svm_model_random.fit(X_train_random, y_train_random)\n",
    "    \n",
    "    # Predictions and probabilities after RandomUnderSampler\n",
    "    y_pred_random = svm_model_random.predict(X_test)\n",
    "    y_prob_random = svm_model_random.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after RandomUnderSampler\n",
    "    entropy_random = calculate_entropy(y_prob_random)\n",
    "    entropy_list_random.append(entropy_random)\n",
    "    \n",
    "    # Store metrics after RandomUnderSampler\n",
    "    accuracy_list_random.append(accuracy_score(y_test, y_pred_random))\n",
    "    precision_list_random.append(precision_score(y_test, y_pred_random))\n",
    "    recall_list_random.append(recall_score(y_test, y_pred_random))\n",
    "    f1_list_random.append(f1_score(y_test, y_pred_random))\n",
    "    confusion_matrices_random.append(confusion_matrix(y_test, y_pred_random))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_random)} After RandomUnderSampler:\\n', confusion_matrices_random[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after RandomUnderSampler\n",
    "mean_accuracy_random = np.mean(accuracy_list_random)\n",
    "std_accuracy_random = np.std(accuracy_list_random)\n",
    "mean_precision_random = np.mean(precision_list_random)\n",
    "std_precision_random = np.std(precision_list_random)\n",
    "mean_recall_random = np.mean(recall_list_random)\n",
    "std_recall_random = np.std(recall_list_random)\n",
    "mean_f1_random = np.mean(f1_list_random)\n",
    "std_f1_random = np.std(f1_list_random)\n",
    "mean_entropy_random = np.mean(entropy_list_random)\n",
    "std_entropy_random = np.std(entropy_list_random)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "mean_conf_matrix_random = np.mean(confusion_matrices_random, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n",
    "\n",
    "# Print results after RandomUnderSampler\n",
    "print('--- After RandomUnderSampler ---')\n",
    "print('Mean Accuracy:', mean_accuracy_random)\n",
    "print('Accuracy Std Dev:', std_accuracy_random)\n",
    "print('Mean Precision:', mean_precision_random)\n",
    "print('Precision Std Dev:', std_precision_random)\n",
    "print('Mean Recall:', mean_recall_random)\n",
    "print('Recall Std Dev:', std_recall_random)\n",
    "print('Mean F1-score:', mean_f1_random)\n",
    "print('F1-score Std Dev:', std_f1_random)\n",
    "print('Mean Entropy:', mean_entropy_random)\n",
    "print('Entropy Std Dev:', std_entropy_random)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_random)\n"
   ],
   "id": "337cfe012ac5dd6f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[23 58]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[18 63]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 1 After RandomUnderSampler:\n",
      " [[36 45]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[35 46]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[24 57]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 2 After RandomUnderSampler:\n",
      " [[70 11]\n",
      " [ 4  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[37 44]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[23 58]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 3 After RandomUnderSampler:\n",
      " [[24 57]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[39 41]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[ 6 74]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 4 After RandomUnderSampler:\n",
      " [[59 21]\n",
      " [ 5  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[31 49]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[10 70]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 5 After RandomUnderSampler:\n",
      " [[26 54]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[26 54]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[ 8 72]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 6 After RandomUnderSampler:\n",
      " [[66 14]\n",
      " [ 3  3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[30 50]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[11 69]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 7 After RandomUnderSampler:\n",
      " [[30 50]\n",
      " [ 4  2]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[35 45]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[18 62]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 8 After RandomUnderSampler:\n",
      " [[11 69]\n",
      " [ 2  4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[31 49]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[18 62]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 9 After RandomUnderSampler:\n",
      " [[66 14]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[26 54]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[14 66]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 10 After RandomUnderSampler:\n",
      " [[37 43]\n",
      " [ 2  3]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9359097127222983\n",
      "Accuracy Std Dev: 0.005682096970161464\n",
      "Mean Precision: 0.0\n",
      "Precision Std Dev: 0.0\n",
      "Mean Recall: 0.0\n",
      "Recall Std Dev: 0.0\n",
      "Mean F1-score: 0.0\n",
      "F1-score Std Dev: 0.0\n",
      "Mean Entropy: 0.22670256740313155\n",
      "Entropy Std Dev: 0.00942586759892498\n",
      "Mean Confusion Matrix:\n",
      " [[80.3  0. ]\n",
      " [ 5.5  0. ]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.41017783857729134\n",
      "Accuracy Std Dev: 0.05663128388732953\n",
      "Mean Precision: 0.07408722636572565\n",
      "Precision Std Dev: 0.010797108883815673\n",
      "Mean Recall: 0.7166666666666666\n",
      "Recall Std Dev: 0.131021626713557\n",
      "Mean F1-score: 0.1340546193878196\n",
      "F1-score Std Dev: 0.01942408790126447\n",
      "Mean Entropy: 0.25472538831006575\n",
      "Entropy Std Dev: 0.02848036408394596\n",
      "Mean Confusion Matrix:\n",
      " [[31.3 49. ]\n",
      " [ 1.6  3.9]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.22147742818057456\n",
      "Accuracy Std Dev: 0.05965684051428055\n",
      "Mean Precision: 0.057020939765080825\n",
      "Precision Std Dev: 0.012272566049379808\n",
      "Mean Recall: 0.7233333333333333\n",
      "Recall Std Dev: 0.1706523431489361\n",
      "Mean F1-score: 0.10568092904342834\n",
      "F1-score Std Dev: 0.022880308928304203\n",
      "Mean Entropy: 0.675151826233965\n",
      "Entropy Std Dev: 0.013955662408061661\n",
      "Mean Confusion Matrix:\n",
      " [[15.  65.3]\n",
      " [ 1.5  4. ]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9359097127222983\n",
      "Accuracy Std Dev: 0.005682096970161464\n",
      "Mean Precision: 0.0\n",
      "Precision Std Dev: 0.0\n",
      "Mean Recall: 0.0\n",
      "Recall Std Dev: 0.0\n",
      "Mean F1-score: 0.0\n",
      "F1-score Std Dev: 0.0\n",
      "Mean Entropy: 0.2319343152722292\n",
      "Entropy Std Dev: 0.0081981905893673\n",
      "Mean Confusion Matrix:\n",
      " [[80.3  0. ]\n",
      " [ 5.5  0. ]]\n",
      "--- After RandomUnderSampler ---\n",
      "Mean Accuracy: 0.5282216142270861\n",
      "Accuracy Std Dev: 0.22221571487913963\n",
      "Mean Precision: 0.0801551450540672\n",
      "Precision Std Dev: 0.03956261758052454\n",
      "Mean Recall: 0.51\n",
      "Recall Std Dev: 0.22063040991163885\n",
      "Mean F1-score: 0.1316565607023488\n",
      "F1-score Std Dev: 0.054746037940802426\n",
      "Mean Entropy: 0.6835280144545612\n",
      "Entropy Std Dev: 0.009347604984722499\n",
      "Mean Confusion Matrix:\n",
      " [[42.5 37.8]\n",
      " [ 2.7  2.8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[23 58]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[18 63]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 1 After RandomUnderSampler:\n",
      " [[36 45]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[35 46]\n",
      " [ 0  5]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[24 57]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 2 After RandomUnderSampler:\n",
      " [[70 11]\n",
      " [ 4  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[37 44]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[23 58]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 3 After RandomUnderSampler:\n",
      " [[24 57]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[39 41]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[ 6 74]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 4 After RandomUnderSampler:\n",
      " [[59 21]\n",
      " [ 5  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[31 49]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[10 70]\n",
      " [ 0  6]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 5 After RandomUnderSampler:\n",
      " [[26 54]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[26 54]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[ 8 72]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 6 After RandomUnderSampler:\n",
      " [[66 14]\n",
      " [ 3  3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[30 50]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[11 69]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 7 After RandomUnderSampler:\n",
      " [[30 50]\n",
      " [ 4  2]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[35 45]\n",
      " [ 2  4]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[18 62]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 8 After RandomUnderSampler:\n",
      " [[11 69]\n",
      " [ 2  4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[31 49]\n",
      " [ 2  3]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[18 62]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 9 After RandomUnderSampler:\n",
      " [[66 14]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[80  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[26 54]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[14 66]\n",
      " [ 1  4]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[80  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 10 After RandomUnderSampler:\n",
      " [[37 43]\n",
      " [ 2  3]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9359097127222983\n",
      "Accuracy Std Dev: 0.005682096970161464\n",
      "Mean Precision: 0.0\n",
      "Precision Std Dev: 0.0\n",
      "Mean Recall: 0.0\n",
      "Recall Std Dev: 0.0\n",
      "Mean F1-score: 0.0\n",
      "F1-score Std Dev: 0.0\n",
      "Mean Entropy: 0.22670256740313155\n",
      "Entropy Std Dev: 0.00942586759892498\n",
      "Mean Confusion Matrix:\n",
      " [[80.3  0. ]\n",
      " [ 5.5  0. ]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.41017783857729134\n",
      "Accuracy Std Dev: 0.05663128388732953\n",
      "Mean Precision: 0.07408722636572565\n",
      "Precision Std Dev: 0.010797108883815673\n",
      "Mean Recall: 0.7166666666666666\n",
      "Recall Std Dev: 0.131021626713557\n",
      "Mean F1-score: 0.1340546193878196\n",
      "F1-score Std Dev: 0.01942408790126447\n",
      "Mean Entropy: 0.25472538831006575\n",
      "Entropy Std Dev: 0.02848036408394596\n",
      "Mean Confusion Matrix:\n",
      " [[31.3 49. ]\n",
      " [ 1.6  3.9]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.22147742818057456\n",
      "Accuracy Std Dev: 0.05965684051428055\n",
      "Mean Precision: 0.057020939765080825\n",
      "Precision Std Dev: 0.012272566049379808\n",
      "Mean Recall: 0.7233333333333333\n",
      "Recall Std Dev: 0.1706523431489361\n",
      "Mean F1-score: 0.10568092904342834\n",
      "F1-score Std Dev: 0.022880308928304203\n",
      "Mean Entropy: 0.6751121990968979\n",
      "Entropy Std Dev: 0.013991486497852472\n",
      "Mean Confusion Matrix:\n",
      " [[15.  65.3]\n",
      " [ 1.5  4. ]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9359097127222983\n",
      "Accuracy Std Dev: 0.005682096970161464\n",
      "Mean Precision: 0.0\n",
      "Precision Std Dev: 0.0\n",
      "Mean Recall: 0.0\n",
      "Recall Std Dev: 0.0\n",
      "Mean F1-score: 0.0\n",
      "F1-score Std Dev: 0.0\n",
      "Mean Entropy: 0.2319343152722292\n",
      "Entropy Std Dev: 0.0081981905893673\n",
      "Mean Confusion Matrix:\n",
      " [[80.3  0. ]\n",
      " [ 5.5  0. ]]\n",
      "--- After RandomUnderSampler ---\n",
      "Mean Accuracy: 0.5282216142270861\n",
      "Accuracy Std Dev: 0.22221571487913963\n",
      "Mean Precision: 0.0801551450540672\n",
      "Precision Std Dev: 0.03956261758052454\n",
      "Mean Recall: 0.51\n",
      "Recall Std Dev: 0.22063040991163885\n",
      "Mean F1-score: 0.1316565607023488\n",
      "F1-score Std Dev: 0.054746037940802426\n",
      "Mean Entropy: 0.6835280144545612\n",
      "Entropy Std Dev: 0.009347604984722499\n",
      "Mean Confusion Matrix:\n",
      " [[42.5 37.8]\n",
      " [ 2.7  2.8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:10:49.904816Z",
     "start_time": "2024-11-07T21:10:44.802126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "import numpy as np\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "uncertainty_list = []  # List to store entropy for each fold\n",
    "confusion_matrices = []\n",
    "\n",
    "# Choose an oversampling method\n",
    "oversampler = SMOTE(random_state=42)\n",
    "# oversampler = ADASYN(random_state=42)\n",
    "#oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Function to calculate entropy\n",
    "def calculate_entropy(probabilities):\n",
    "    entropy = -np.sum(probabilities * np.log(probabilities + 1e-9), axis=1)  # Add small value to avoid log(0)\n",
    "    return np.mean(entropy)\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply oversampling\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with probability enabled\n",
    "    svm_model = SVC(probability=True, random_state=42)\n",
    "    svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict probabilities and classes\n",
    "    y_pred_svm = svm_model.predict(X_test)\n",
    "    y_prob_svm = svm_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate and store entropy\n",
    "    entropy = calculate_entropy(y_prob_svm)\n",
    "    uncertainty_list.append(entropy)\n",
    "    \n",
    "    # Store metrics\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred_svm))\n",
    "    precision_list.append(precision_score(y_test, y_pred_svm))\n",
    "    recall_list.append(recall_score(y_test, y_pred_svm))\n",
    "    f1_list.append(f1_score(y_test, y_pred_svm))\n",
    "    \n",
    "    # Store confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_svm)\n",
    "    confusion_matrices.append(conf_matrix)\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices)}:\\n', conf_matrix)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "std_precision = np.std(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "std_recall = np.std(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "\n",
    "# Calculate mean and standard deviation of entropy\n",
    "mean_entropy = np.mean(uncertainty_list)\n",
    "std_entropy = np.std(uncertainty_list)\n",
    "\n",
    "# Calculate mean confusion matrix\n",
    "mean_conf_matrix = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "# Print results\n",
    "print('Mean Accuracy:', mean_accuracy)\n",
    "print('Accuracy Std Dev:', std_accuracy)\n",
    "print('Mean Precision:', mean_precision)\n",
    "print('Precision Std Dev:', std_precision)\n",
    "print('Mean Recall:', mean_recall)\n",
    "print('Recall Std Dev:', std_recall)\n",
    "print('Mean F1-score:', mean_f1)\n",
    "print('F1-score Std Dev:', std_f1)\n",
    "print('Mean Entropy:', mean_entropy)\n",
    "print('Entropy Std Dev:', std_entropy)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix)\n"
   ],
   "id": "7179a02c9afeb859",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1:\n",
      " [[66 15]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 2:\n",
      " [[67 14]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 3:\n",
      " [[60 21]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 4:\n",
      " [[70 10]\n",
      " [ 4  2]]\n",
      "Confusion Matrix for Fold 5:\n",
      " [[64 16]\n",
      " [ 1  5]]\n",
      "Confusion Matrix for Fold 6:\n",
      " [[65 15]\n",
      " [ 5  1]]\n",
      "Confusion Matrix for Fold 7:\n",
      " [[56 24]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 8:\n",
      " [[62 18]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 9:\n",
      " [[65 15]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 10:\n",
      " [[65 15]\n",
      " [ 1  4]]\n",
      "Mean Accuracy: 0.773953488372093\n",
      "Accuracy Std Dev: 0.04202025954880806\n",
      "Mean Precision: 0.1265526721748959\n",
      "Precision Std Dev: 0.05919942172024951\n",
      "Mean Recall: 0.4333333333333333\n",
      "Recall Std Dev: 0.22261077142752\n",
      "Mean F1-score: 0.19407888407888407\n",
      "F1-score Std Dev: 0.0917841191842333\n",
      "Mean Entropy: 0.510744657641474\n",
      "Entropy Std Dev: 0.02766867542750917\n",
      "Mean Confusion Matrix:\n",
      " [[64.  16.3]\n",
      " [ 3.1  2.4]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:11:31.398079Z",
     "start_time": "2024-11-07T21:11:26.312676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "import numpy as np\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "uncertainty_list = []  # List to store entropy for each fold\n",
    "confusion_matrices = []\n",
    "\n",
    "# Choose an oversampling method\n",
    "#oversampler = SMOTE(random_state=42)\n",
    "oversampler = ADASYN(random_state=42)\n",
    "#oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Function to calculate entropy\n",
    "def calculate_entropy(probabilities):\n",
    "    entropy = -np.sum(probabilities * np.log(probabilities + 1e-9), axis=1)  # Add small value to avoid log(0)\n",
    "    return np.mean(entropy)\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply oversampling\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with probability enabled\n",
    "    svm_model = SVC(probability=True, random_state=42)\n",
    "    svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict probabilities and classes\n",
    "    y_pred_svm = svm_model.predict(X_test)\n",
    "    y_prob_svm = svm_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate and store entropy\n",
    "    entropy = calculate_entropy(y_prob_svm)\n",
    "    uncertainty_list.append(entropy)\n",
    "    \n",
    "    # Store metrics\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred_svm))\n",
    "    precision_list.append(precision_score(y_test, y_pred_svm))\n",
    "    recall_list.append(recall_score(y_test, y_pred_svm))\n",
    "    f1_list.append(f1_score(y_test, y_pred_svm))\n",
    "    \n",
    "    # Store confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_svm)\n",
    "    confusion_matrices.append(conf_matrix)\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices)}:\\n', conf_matrix)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "std_precision = np.std(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "std_recall = np.std(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "\n",
    "# Calculate mean and standard deviation of entropy\n",
    "mean_entropy = np.mean(uncertainty_list)\n",
    "std_entropy = np.std(uncertainty_list)\n",
    "\n",
    "# Calculate mean confusion matrix\n",
    "mean_conf_matrix = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "# Print results\n",
    "print('Mean Accuracy:', mean_accuracy)\n",
    "print('Accuracy Std Dev:', std_accuracy)\n",
    "print('Mean Precision:', mean_precision)\n",
    "print('Precision Std Dev:', std_precision)\n",
    "print('Mean Recall:', mean_recall)\n",
    "print('Recall Std Dev:', std_recall)\n",
    "print('Mean F1-score:', mean_f1)\n",
    "print('F1-score Std Dev:', std_f1)\n",
    "print('Mean Entropy:', mean_entropy)\n",
    "print('Entropy Std Dev:', std_entropy)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix)\n"
   ],
   "id": "6baba5562c91b4ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1:\n",
      " [[65 16]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 2:\n",
      " [[65 16]\n",
      " [ 4  1]]\n",
      "Confusion Matrix for Fold 3:\n",
      " [[65 16]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 4:\n",
      " [[69 11]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 5:\n",
      " [[67 13]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 6:\n",
      " [[65 15]\n",
      " [ 5  1]]\n",
      "Confusion Matrix for Fold 7:\n",
      " [[57 23]\n",
      " [ 5  1]]\n",
      "Confusion Matrix for Fold 8:\n",
      " [[63 17]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 9:\n",
      " [[64 16]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 10:\n",
      " [[70 10]\n",
      " [ 1  4]]\n",
      "Mean Accuracy: 0.7821477428180575\n",
      "Accuracy Std Dev: 0.04937349959738104\n",
      "Mean Precision: 0.12815359477124183\n",
      "Precision Std Dev: 0.07630725145159051\n",
      "Mean Recall: 0.3833333333333333\n",
      "Recall Std Dev: 0.1939358427705181\n",
      "Mean F1-score: 0.1911769161425912\n",
      "F1-score Std Dev: 0.10916185932763393\n",
      "Mean Entropy: 0.49089675261523363\n",
      "Entropy Std Dev: 0.03879538766884343\n",
      "Mean Confusion Matrix:\n",
      " [[65.  15.3]\n",
      " [ 3.4  2.1]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:12:11.332303Z",
     "start_time": "2024-11-07T21:12:06.338077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
    "import numpy as np\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "uncertainty_list = []  # List to store entropy for each fold\n",
    "confusion_matrices = []\n",
    "\n",
    "# Choose an oversampling method\n",
    "#oversampler = SMOTE(random_state=42)\n",
    "#oversampler = ADASYN(random_state=42)\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Function to calculate entropy\n",
    "def calculate_entropy(probabilities):\n",
    "    entropy = -np.sum(probabilities * np.log(probabilities + 1e-9), axis=1)  # Add small value to avoid log(0)\n",
    "    return np.mean(entropy)\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Apply oversampling\n",
    "    X_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with probability enabled\n",
    "    svm_model = SVC(probability=True, random_state=42)\n",
    "    svm_model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict probabilities and classes\n",
    "    y_pred_svm = svm_model.predict(X_test)\n",
    "    y_prob_svm = svm_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate and store entropy\n",
    "    entropy = calculate_entropy(y_prob_svm)\n",
    "    uncertainty_list.append(entropy)\n",
    "    \n",
    "    # Store metrics\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred_svm))\n",
    "    precision_list.append(precision_score(y_test, y_pred_svm))\n",
    "    recall_list.append(recall_score(y_test, y_pred_svm))\n",
    "    f1_list.append(f1_score(y_test, y_pred_svm))\n",
    "    \n",
    "    # Store confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred_svm)\n",
    "    confusion_matrices.append(conf_matrix)\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices)}:\\n', conf_matrix)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "std_precision = np.std(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "std_recall = np.std(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "\n",
    "# Calculate mean and standard deviation of entropy\n",
    "mean_entropy = np.mean(uncertainty_list)\n",
    "std_entropy = np.std(uncertainty_list)\n",
    "\n",
    "# Calculate mean confusion matrix\n",
    "mean_conf_matrix = np.mean(confusion_matrices, axis=0)\n",
    "\n",
    "# Print results\n",
    "print('Mean Accuracy:', mean_accuracy)\n",
    "print('Accuracy Std Dev:', std_accuracy)\n",
    "print('Mean Precision:', mean_precision)\n",
    "print('Precision Std Dev:', std_precision)\n",
    "print('Mean Recall:', mean_recall)\n",
    "print('Recall Std Dev:', std_recall)\n",
    "print('Mean F1-score:', mean_f1)\n",
    "print('F1-score Std Dev:', std_f1)\n",
    "print('Mean Entropy:', mean_entropy)\n",
    "print('Entropy Std Dev:', std_entropy)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix)\n"
   ],
   "id": "8601d5451c801d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1:\n",
      " [[71 10]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 2:\n",
      " [[72  9]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 3:\n",
      " [[73  8]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 4:\n",
      " [[68 12]\n",
      " [ 5  1]]\n",
      "Confusion Matrix for Fold 5:\n",
      " [[66 14]\n",
      " [ 4  2]]\n",
      "Confusion Matrix for Fold 6:\n",
      " [[70 10]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 7:\n",
      " [[61 19]\n",
      " [ 3  3]]\n",
      "Confusion Matrix for Fold 8:\n",
      " [[68 12]\n",
      " [ 4  2]]\n",
      "Confusion Matrix for Fold 9:\n",
      " [[72  8]\n",
      " [ 3  2]]\n",
      "Confusion Matrix for Fold 10:\n",
      " [[73  7]\n",
      " [ 1  4]]\n",
      "Mean Accuracy: 0.8357865937072504\n",
      "Accuracy Std Dev: 0.04518007069505705\n",
      "Mean Precision: 0.1824034299034299\n",
      "Precision Std Dev: 0.07359125205588399\n",
      "Mean Recall: 0.42333333333333334\n",
      "Recall Std Dev: 0.154236470683457\n",
      "Mean F1-score: 0.2535783978663236\n",
      "F1-score Std Dev: 0.09840988164983558\n",
      "Mean Entropy: 0.4861311151265143\n",
      "Entropy Std Dev: 0.030872595523496103\n",
      "Mean Confusion Matrix:\n",
      " [[69.4 10.9]\n",
      " [ 3.2  2.3]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:14:02.945781Z",
     "start_time": "2024-11-07T21:13:58.678381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Function to find the best threshold for F1-score\n",
    "def find_best_threshold(y_true, y_prob, thresholds):\n",
    "    best_f1 = 0\n",
    "    best_threshold = 0.5\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob[:, 1] >= threshold).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_f1\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "best_thresholds = []\n",
    "f1_list = []\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "roc_auc_list = []\n",
    "entropy_list = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the SVM model with probability estimation\n",
    "    svm_model = SVC(probability=True, random_state=42)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calibrate the model\n",
    "    calibrated_model = CalibratedClassifierCV(svm_model, method='isotonic', cv=5)\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predicted probabilities on training set\n",
    "    y_prob_train = calibrated_model.predict_proba(X_train)\n",
    "    \n",
    "    # Define a range of thresholds to test\n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "    \n",
    "    # Find the best threshold based on training set\n",
    "    best_threshold, _ = find_best_threshold(y_train, y_prob_train, thresholds)\n",
    "    best_thresholds.append(best_threshold)\n",
    "    \n",
    "    # Get predicted probabilities on test set\n",
    "    y_prob_test = calibrated_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy\n",
    "    entropy = calculate_entropy(y_prob_test)\n",
    "    entropy_list.append(entropy)\n",
    "    \n",
    "    # Make predictions using the best threshold\n",
    "    y_pred = (y_prob_test[:, 1] >= best_threshold).astype(int)\n",
    "    \n",
    "    # Calculate and store ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test, y_prob_test[:, 1])\n",
    "    roc_auc_list.append(roc_auc)\n",
    "    \n",
    "    # Store the metrics\n",
    "    f1_list.append(f1_score(y_test, y_pred))\n",
    "    accuracy_list.append(accuracy_score(y_test, y_pred))\n",
    "    precision_list.append(precision_score(y_test, y_pred))\n",
    "    recall_list.append(recall_score(y_test, y_pred))\n",
    "    confusion_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(f'Best Threshold for Fold {len(best_thresholds)}: {best_threshold}')\n",
    "    print(f'Confusion Matrix for Fold {len(best_thresholds)}:\\n', confusion_matrices[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "std_precision = np.std(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "std_recall = np.std(recall_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "mean_roc_auc = np.mean(roc_auc_list)\n",
    "std_roc_auc = np.std(roc_auc_list)\n",
    "mean_entropy = np.mean(entropy_list)\n",
    "std_entropy = np.std(entropy_list)\n",
    "\n",
    "# Calculate mean confusion matrix\n",
    "mean_conf_matrix = np.mean(confusion_matrices, axis=0).astype(int)\n",
    "\n",
    "# Print the results\n",
    "print('--- Overall Results ---')\n",
    "print('Mean Accuracy:', mean_accuracy)\n",
    "print('Accuracy Std Dev:', std_accuracy)\n",
    "print('Mean Precision:', mean_precision)\n",
    "print('Precision Std Dev:', std_precision)\n",
    "print('Mean Recall:', mean_recall)\n",
    "print('Recall Std Dev:', std_recall)\n",
    "print('Mean F1-score:', mean_f1)\n",
    "print('F1-score Std Dev:', std_f1)\n",
    "print('Mean ROC AUC:', mean_roc_auc)\n",
    "print('ROC AUC Std Dev:', std_roc_auc)\n",
    "print('Mean Entropy:', mean_entropy)\n",
    "print('Entropy Std Dev:', std_entropy)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix)"
   ],
   "id": "bb1ed8f61933c837",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold for Fold 1: 0.21999999999999995\n",
      "Confusion Matrix for Fold 1:\n",
      " [[74  7]\n",
      " [ 3  2]]\n",
      "Best Threshold for Fold 2: 0.2599999999999999\n",
      "Confusion Matrix for Fold 2:\n",
      " [[78  3]\n",
      " [ 3  2]]\n",
      "Best Threshold for Fold 3: 0.33999999999999986\n",
      "Confusion Matrix for Fold 3:\n",
      " [[78  3]\n",
      " [ 3  2]]\n",
      "Best Threshold for Fold 4: 0.29999999999999993\n",
      "Confusion Matrix for Fold 4:\n",
      " [[79  1]\n",
      " [ 2  4]]\n",
      "Best Threshold for Fold 5: 0.18999999999999995\n",
      "Confusion Matrix for Fold 5:\n",
      " [[74  6]\n",
      " [ 1  5]]\n",
      "Best Threshold for Fold 6: 0.2899999999999999\n",
      "Confusion Matrix for Fold 6:\n",
      " [[77  3]\n",
      " [ 3  3]]\n",
      "Best Threshold for Fold 7: 0.2899999999999999\n",
      "Confusion Matrix for Fold 7:\n",
      " [[77  3]\n",
      " [ 2  4]]\n",
      "Best Threshold for Fold 8: 0.2799999999999999\n",
      "Confusion Matrix for Fold 8:\n",
      " [[77  3]\n",
      " [ 4  2]]\n",
      "Best Threshold for Fold 9: 0.19999999999999996\n",
      "Confusion Matrix for Fold 9:\n",
      " [[77  3]\n",
      " [ 2  3]]\n",
      "Best Threshold for Fold 10: 0.2599999999999999\n",
      "Confusion Matrix for Fold 10:\n",
      " [[75  5]\n",
      " [ 1  4]]\n",
      "--- Overall Results ---\n",
      "Mean Accuracy: 0.928919288645691\n",
      "Accuracy Std Dev: 0.019720614423454932\n",
      "Mean Precision: 0.46926406926406933\n",
      "Precision Std Dev: 0.14070113564467543\n",
      "Mean Recall: 0.5599999999999999\n",
      "Recall Std Dev: 0.16983652270475993\n",
      "Mean F1-score: 0.4997126403008757\n",
      "F1-score Std Dev: 0.12823131777750654\n",
      "Mean ROC AUC: 0.7797222222222222\n",
      "ROC AUC Std Dev: 0.10407766196375055\n",
      "Mean Entropy: 0.17354754499881878\n",
      "Entropy Std Dev: 0.015072823396340017\n",
      "Mean Confusion Matrix:\n",
      " [[76  3]\n",
      " [ 2  3]]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T21:15:43.165880Z",
     "start_time": "2024-11-07T21:15:37.263772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.combine import SMOTETomek  # Import SMOTE + Tomek Links\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_smote_tomek = []\n",
    "precision_list_smote_tomek = []\n",
    "recall_list_smote_tomek = []\n",
    "f1_list_smote_tomek = []\n",
    "entropy_list_smote_tomek = []\n",
    "confusion_matrices_smote_tomek = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the SVM model without SMOTE + Tomek Links\n",
    "    svm_model = SVC(probability=True, kernel='rbf', random_state=42)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before SMOTE + Tomek Links\n",
    "    y_pred_before = svm_model.predict(X_test)\n",
    "    y_prob_before = svm_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before SMOTE + Tomek Links\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before SMOTE + Tomek Links\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before, average='weighted'))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before, average='weighted'))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before, average='weighted'))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply SMOTE + Tomek Links to the training data\n",
    "    smote_tomek = SMOTETomek(random_state=42)\n",
    "    X_train_smote_tomek, y_train_smote_tomek = smote_tomek.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with SMOTE + Tomek Links\n",
    "    svm_model_smote_tomek = SVC(probability=True, kernel='rbf', random_state=42)\n",
    "    svm_model_smote_tomek.fit(X_train_smote_tomek, y_train_smote_tomek)\n",
    "    \n",
    "    # Predictions and probabilities after SMOTE + Tomek Links\n",
    "    y_pred_smote_tomek = svm_model_smote_tomek.predict(X_test)\n",
    "    y_prob_smote_tomek = svm_model_smote_tomek.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after SMOTE + Tomek Links\n",
    "    entropy_smote_tomek = calculate_entropy(y_prob_smote_tomek)\n",
    "    entropy_list_smote_tomek.append(entropy_smote_tomek)\n",
    "    \n",
    "    # Store metrics after SMOTE + Tomek Links\n",
    "    accuracy_list_smote_tomek.append(accuracy_score(y_test, y_pred_smote_tomek))\n",
    "    precision_list_smote_tomek.append(precision_score(y_test, y_pred_smote_tomek))\n",
    "    recall_list_smote_tomek.append(recall_score(y_test, y_pred_smote_tomek))\n",
    "    f1_list_smote_tomek.append(f1_score(y_test, y_pred_smote_tomek))\n",
    "    confusion_matrices_smote_tomek.append(confusion_matrix(y_test, y_pred_smote_tomek))\n",
    "    \n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Oversampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_smote_tomek)} After SMOTE + Tomek Links:\\n', confusion_matrices_smote_tomek[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before oversampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after SMOTE + Tomek Links\n",
    "mean_accuracy_smote_tomek = np.mean(accuracy_list_smote_tomek)\n",
    "std_accuracy_smote_tomek = np.std(accuracy_list_smote_tomek)\n",
    "mean_precision_smote_tomek = np.mean(precision_list_smote_tomek)\n",
    "std_precision_smote_tomek = np.std(precision_list_smote_tomek)\n",
    "mean_recall_smote_tomek = np.mean(recall_list_smote_tomek)\n",
    "std_recall_smote_tomek = np.std(recall_list_smote_tomek)\n",
    "mean_f1_smote_tomek = np.mean(f1_list_smote_tomek)\n",
    "std_f1_smote_tomek = np.std(f1_list_smote_tomek)\n",
    "mean_entropy_smote_tomek = np.mean(entropy_list_smote_tomek)\n",
    "std_entropy_smote_tomek = np.std(entropy_list_smote_tomek)\n",
    "\n",
    "# Calculate mean confusion matrix before and after SMOTE + Tomek Links\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_smote_tomek = np.mean(confusion_matrices_smote_tomek, axis=0)\n",
    "\n",
    "# Print results before oversampling\n",
    "print('--- Before Oversampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after SMOTE + Tomek Links\n",
    "print('--- After SMOTE + Tomek Links ---')\n",
    "print('Mean Accuracy:', mean_accuracy_smote_tomek)\n",
    "print('Accuracy Std Dev:', std_accuracy_smote_tomek)\n",
    "print('Mean Precision:', mean_precision_smote_tomek)\n",
    "print('Precision Std Dev:', std_precision_smote_tomek)\n",
    "print('Mean Recall:', mean_recall_smote_tomek)\n",
    "print('Recall Std Dev:', std_recall_smote_tomek)\n",
    "print('Mean F1-score:', mean_f1_smote_tomek)\n",
    "print('F1-score Std Dev:', std_f1_smote_tomek)\n",
    "print('Mean Entropy:', mean_entropy_smote_tomek)\n",
    "print('Entropy Std Dev:', std_entropy_smote_tomek)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_smote_tomek)"
   ],
   "id": "f69ff2003c41d246",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Oversampling:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 1 After SMOTE + Tomek Links:\n",
      " [[66 15]\n",
      " [ 4  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 2 Before Oversampling:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 2 After SMOTE + Tomek Links:\n",
      " [[67 14]\n",
      " [ 4  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 3 Before Oversampling:\n",
      " [[81  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 3 After SMOTE + Tomek Links:\n",
      " [[60 21]\n",
      " [ 3  2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 4 Before Oversampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 4 After SMOTE + Tomek Links:\n",
      " [[69 11]\n",
      " [ 4  2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 5 Before Oversampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 5 After SMOTE + Tomek Links:\n",
      " [[63 17]\n",
      " [ 1  5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 6 Before Oversampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 6 After SMOTE + Tomek Links:\n",
      " [[65 15]\n",
      " [ 5  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 7 Before Oversampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 7 After SMOTE + Tomek Links:\n",
      " [[57 23]\n",
      " [ 3  3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 8 Before Oversampling:\n",
      " [[80  0]\n",
      " [ 6  0]]\n",
      "Confusion Matrix for Fold 8 After SMOTE + Tomek Links:\n",
      " [[62 18]\n",
      " [ 3  3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 9 Before Oversampling:\n",
      " [[80  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 9 After SMOTE + Tomek Links:\n",
      " [[64 16]\n",
      " [ 3  2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 10 Before Oversampling:\n",
      " [[80  0]\n",
      " [ 5  0]]\n",
      "Confusion Matrix for Fold 10 After SMOTE + Tomek Links:\n",
      " [[65 15]\n",
      " [ 1  4]]\n",
      "--- Before Oversampling ---\n",
      "Mean Accuracy: 0.9359097127222983\n",
      "Accuracy Std Dev: 0.005682096970161464\n",
      "Mean Precision: 0.8759592765939133\n",
      "Precision Std Dev: 0.01063602674427472\n",
      "Mean Recall: 0.9359097127222983\n",
      "Recall Std Dev: 0.005682096970161464\n",
      "Mean F1-score: 0.9049343565899726\n",
      "F1-score Std Dev: 0.008331939708934689\n",
      "Mean Entropy: 0.22670256740313155\n",
      "Entropy Std Dev: 0.00942586759892498\n",
      "Mean Confusion Matrix:\n",
      " [[80.3  0. ]\n",
      " [ 5.5  0. ]]\n",
      "--- After SMOTE + Tomek Links ---\n",
      "Mean Accuracy: 0.7716142270861833\n",
      "Accuracy Std Dev: 0.03692568390189449\n",
      "Mean Precision: 0.12396212546670213\n",
      "Precision Std Dev: 0.056446973891806494\n",
      "Mean Recall: 0.4333333333333333\n",
      "Recall Std Dev: 0.22261077142752\n",
      "Mean F1-score: 0.1913642100970476\n",
      "F1-score Std Dev: 0.08905531185704302\n",
      "Mean Entropy: 0.508063556429099\n",
      "Entropy Std Dev: 0.029485129750824526\n",
      "Mean Confusion Matrix:\n",
      " [[63.8 16.5]\n",
      " [ 3.1  2.4]]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "20cf943460c27ed4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
