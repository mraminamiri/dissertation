{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-06T21:17:28.452446Z",
     "start_time": "2024-09-06T21:17:28.261119Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:17:30.851076Z",
     "start_time": "2024-09-06T21:17:30.703463Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = pd.read_csv('final_with_covid_AS.csv')\n",
    "data.head()"
   ],
   "id": "5e66e8e6fe57b66a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   CountCases  BedDys  BeddystoCC  Severity  DiedCases  DiedBdDys  Hsptlsns  \\\n",
       "0          17     133    7.823529        75          4          9        13   \n",
       "1          13     372   28.615385        63          4         34         9   \n",
       "2           8     106   13.250000        48          4         13         4   \n",
       "3          45     218    4.844444       153          3         24        42   \n",
       "4          24     238    9.916667        90          3          8        21   \n",
       "\n",
       "   April  August  December  ...  Y2013  Y2014  Y2015  Y2016  Y2017  Y2018  \\\n",
       "0      0       0         0  ...      1      0      0      0      0      0   \n",
       "1      0       0         0  ...      0      0      0      0      0      0   \n",
       "2      0       0         0  ...      0      0      0      0      0      1   \n",
       "3      0       0         0  ...      0      0      0      1      0      0   \n",
       "4      0       1         0  ...      1      0      0      0      0      0   \n",
       "\n",
       "   Y2019  Y2020  Y2021  CovidPrd  \n",
       "0      0      0      0         0  \n",
       "1      0      0      0         0  \n",
       "2      0      0      0         0  \n",
       "3      0      0      0         0  \n",
       "4      0      0      0         0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountCases</th>\n",
       "      <th>BedDys</th>\n",
       "      <th>BeddystoCC</th>\n",
       "      <th>Severity</th>\n",
       "      <th>DiedCases</th>\n",
       "      <th>DiedBdDys</th>\n",
       "      <th>Hsptlsns</th>\n",
       "      <th>April</th>\n",
       "      <th>August</th>\n",
       "      <th>December</th>\n",
       "      <th>...</th>\n",
       "      <th>Y2013</th>\n",
       "      <th>Y2014</th>\n",
       "      <th>Y2015</th>\n",
       "      <th>Y2016</th>\n",
       "      <th>Y2017</th>\n",
       "      <th>Y2018</th>\n",
       "      <th>Y2019</th>\n",
       "      <th>Y2020</th>\n",
       "      <th>Y2021</th>\n",
       "      <th>CovidPrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>133</td>\n",
       "      <td>7.823529</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>372</td>\n",
       "      <td>28.615385</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>218</td>\n",
       "      <td>4.844444</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>238</td>\n",
       "      <td>9.916667</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:17:35.729119Z",
     "start_time": "2024-09-06T21:17:35.716546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filtered_data2 = data[data['CarPngr'] == 1]\n",
    "filtered_data2.info()\n"
   ],
   "id": "bcdf4616fe1c91fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11789 entries, 33 to 54030\n",
      "Data columns (total 58 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CountCases       11789 non-null  int64  \n",
      " 1   BedDys           11789 non-null  int64  \n",
      " 2   BeddystoCC       11789 non-null  float64\n",
      " 3   Severity         11789 non-null  int64  \n",
      " 4   DiedCases        11789 non-null  int64  \n",
      " 5   DiedBdDys        11789 non-null  int64  \n",
      " 6   Hsptlsns         11789 non-null  int64  \n",
      " 7   April            11789 non-null  int64  \n",
      " 8   August           11789 non-null  int64  \n",
      " 9   December         11789 non-null  int64  \n",
      " 10  February         11789 non-null  int64  \n",
      " 11  January          11789 non-null  int64  \n",
      " 12  July             11789 non-null  int64  \n",
      " 13  June             11789 non-null  int64  \n",
      " 14  March            11789 non-null  int64  \n",
      " 15  May              11789 non-null  int64  \n",
      " 16  November         11789 non-null  int64  \n",
      " 17  October          11789 non-null  int64  \n",
      " 18  September        11789 non-null  int64  \n",
      " 19  MajorCities      11789 non-null  int64  \n",
      " 20  Regional         11789 non-null  int64  \n",
      " 21  Female           11789 non-null  int64  \n",
      " 22  Male             11789 non-null  int64  \n",
      " 23  Age07            11789 non-null  int64  \n",
      " 24  Age816           11789 non-null  int64  \n",
      " 25  Age1725          11789 non-null  int64  \n",
      " 26  Age2639          11789 non-null  int64  \n",
      " 27  Age4064          11789 non-null  int64  \n",
      " 28  Age6574          11789 non-null  int64  \n",
      " 29  Age75plus        11789 non-null  int64  \n",
      " 30  CarDriver        11789 non-null  int64  \n",
      " 31  CarPngr          11789 non-null  int64  \n",
      " 32  Mtrcyclist       11789 non-null  int64  \n",
      " 33  PdlCyclist       11789 non-null  int64  \n",
      " 34  Pedestrian       11789 non-null  int64  \n",
      " 35  Cntrprt23WldMV   11789 non-null  int64  \n",
      " 36  CntrprtCrTrkVn   11789 non-null  int64  \n",
      " 37  CntrprtFxdStnry  11789 non-null  int64  \n",
      " 38  CntrprtHvyVhcl   11789 non-null  int64  \n",
      " 39  CntrprtNClsn     11789 non-null  int64  \n",
      " 40  CntrprtNA        11789 non-null  int64  \n",
      " 41  CntrprtOther     11789 non-null  int64  \n",
      " 42  CntrprtNMV       11789 non-null  int64  \n",
      " 43  CntrprtPdlC      11789 non-null  int64  \n",
      " 44  CntrprtPdstAnml  11789 non-null  int64  \n",
      " 45  CntrprtTrn       11789 non-null  int64  \n",
      " 46  Y2011            11789 non-null  int64  \n",
      " 47  Y2012            11789 non-null  int64  \n",
      " 48  Y2013            11789 non-null  int64  \n",
      " 49  Y2014            11789 non-null  int64  \n",
      " 50  Y2015            11789 non-null  int64  \n",
      " 51  Y2016            11789 non-null  int64  \n",
      " 52  Y2017            11789 non-null  int64  \n",
      " 53  Y2018            11789 non-null  int64  \n",
      " 54  Y2019            11789 non-null  int64  \n",
      " 55  Y2020            11789 non-null  int64  \n",
      " 56  Y2021            11789 non-null  int64  \n",
      " 57  CovidPrd         11789 non-null  int64  \n",
      "dtypes: float64(1), int64(57)\n",
      "memory usage: 5.3 MB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:17:43.207225Z",
     "start_time": "2024-09-06T21:17:43.195962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_bins = 2\n",
    "\n",
    "bed_days_min = filtered_data2['Severity'].min()\n",
    "bed_days_max = filtered_data2['Severity'].max()\n",
    "\n",
    "bin_width = (bed_days_max - bed_days_min) / num_bins\n",
    "bins = [bed_days_min + i * bin_width for i in range(num_bins + 1)]\n",
    "\n",
    "def bin_function(x):\n",
    "    for i in range(1, len(bins)):\n",
    "        if x <= bins[i]:\n",
    "            return i - 1\n",
    "    return i\n",
    "\n",
    "filtered_data2['Bed_days_category'] = filtered_data2['Severity'].apply(bin_function)"
   ],
   "id": "9f6b77fa31b26a10",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3l/xh28kn0j7_7d5hh7fgz188940000gn/T/ipykernel_1462/530833198.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data2['Bed_days_category'] = filtered_data2['Severity'].apply(bin_function)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:17:48.765011Z",
     "start_time": "2024-09-06T21:17:48.760606Z"
    }
   },
   "cell_type": "code",
   "source": "filtered_data2['Bed_days_category'].value_counts()\n",
   "id": "937b8fd94ef58c5e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bed_days_category\n",
       "0    11589\n",
       "1      200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:17:54.588911Z",
     "start_time": "2024-09-06T21:17:54.520853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X = filtered_data2[['Age1725','Age2639','Age4064','Age6574','Age75plus',\n",
    "                   \n",
    "                   'Male','Female',\n",
    "                   \n",
    "                   'Regional','MajorCities',\n",
    "\n",
    "                   'April','December','February','January','July',\n",
    "                   'June','March','May','November','October','September',\n",
    "\n",
    "                   'Cntrprt23WldMV','CntrprtFxdStnry','CntrprtHvyVhcl',\n",
    "                   'CntrprtNClsn','CntrprtOther','CntrprtNMV','CntrprtCrTrkVn',\n",
    "                   'CntrprtPdlC','CntrprtPdstAnml','CntrprtTrn',\n",
    "\n",
    "                   'Y2014','Y2015','Y2016','Y2017','Y2018','Y2019','Y2020','Y2021',\n",
    "                   'Y2013','Y2012',\n",
    "                   'CovidPrd']]\n",
    "\n",
    "\n",
    "\n",
    "y = filtered_data2['Bed_days_category']\n"
   ],
   "id": "86346c0787b54082",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LOGESTIC REGRESSION\n",
   "id": "996ec7c13bfb79e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:18:56.113264Z",
     "start_time": "2024-09-06T21:18:24.694303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Logistic Regression model without undersampling\n",
    "    logreg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    logreg_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = logreg_model.predict(X_test)\n",
    "    y_prob_before = logreg_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Logistic Regression model with NearMiss\n",
    "    logreg_model_nearmiss = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    logreg_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = logreg_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = logreg_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Logistic Regression model with ClusterCentroids\n",
    "    logreg_model_clustercentroids = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    logreg_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = logreg_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = logreg_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Logistic Regression model with TomekLinks\n",
    "    logreg_model_tomeklinks = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    logreg_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = logreg_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = logreg_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n"
   ],
   "id": "583b4870092ccb52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[1156    3]\n",
      " [  10   10]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[566 593]\n",
      " [  3  17]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[964 195]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[1156    3]\n",
      " [  10   10]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[1156    3]\n",
      " [   6   14]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[570 589]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[834 325]\n",
      " [  1  19]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[1154    5]\n",
      " [   6   14]]\n",
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[1154    5]\n",
      " [  11    9]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[586 573]\n",
      " [  6  14]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[852 307]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[1153    6]\n",
      " [  11    9]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[1155    4]\n",
      " [   5   15]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[583 576]\n",
      " [  3  17]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[763 396]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[1155    4]\n",
      " [   5   15]]\n",
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[1155    4]\n",
      " [   8   12]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[603 556]\n",
      " [  5  15]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[903 256]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[1155    4]\n",
      " [   8   12]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[1156    3]\n",
      " [   8   12]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[584 575]\n",
      " [  2  18]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[935 224]\n",
      " [  1  19]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[1155    4]\n",
      " [   7   13]]\n",
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[1155    4]\n",
      " [  11    9]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[575 584]\n",
      " [  4  16]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[950 209]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[1154    5]\n",
      " [  11    9]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[1156    3]\n",
      " [  10   10]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[613 546]\n",
      " [  1  19]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[912 247]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[1156    3]\n",
      " [  10   10]]\n",
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[1159    0]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[560 599]\n",
      " [  4  16]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[923 236]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[1157    2]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[1156    2]\n",
      " [  14    6]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[587 571]\n",
      " [  4  16]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[975 183]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[1155    3]\n",
      " [  12    8]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9895662780031422\n",
      "Accuracy Std Dev: 0.0022472782060769785\n",
      "Mean Precision: 0.7786629469601606\n",
      "Precision Std Dev: 0.08904871702007784\n",
      "Mean Recall: 0.5399999999999999\n",
      "Recall Std Dev: 0.12409673645990857\n",
      "Mean F1-score: 0.6303604848576385\n",
      "F1-score Std Dev: 0.10258351999171707\n",
      "Mean Entropy: 0.03229952351742282\n",
      "Entropy Std Dev: 0.0021293695552566253\n",
      "Mean Confusion Matrix:\n",
      " [[1155.8    3.1]\n",
      " [   9.2   10.8]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.5085251810475051\n",
      "Accuracy Std Dev: 0.013162646025374291\n",
      "Mean Precision: 0.028341977045659338\n",
      "Precision Std Dev: 0.002939839755391904\n",
      "Mean Recall: 0.8400000000000001\n",
      "Recall Std Dev: 0.08602325267042628\n",
      "Mean F1-score: 0.05483258324291028\n",
      "F1-score Std Dev: 0.005678447693352322\n",
      "Mean Entropy: 0.4903779688331721\n",
      "Entropy Std Dev: 0.005078339338487872\n",
      "Mean Confusion Matrix:\n",
      " [[582.7 576.2]\n",
      " [  3.2  16.8]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.7811573072054675\n",
      "Accuracy Std Dev: 0.05346790027258819\n",
      "Mean Precision: 0.07470376641389474\n",
      "Precision Std Dev: 0.0153717463974083\n",
      "Mean Recall: 0.99\n",
      "Recall Std Dev: 0.020000000000000018\n",
      "Mean F1-score: 0.1385562218107666\n",
      "F1-score Std Dev: 0.02672921416381121\n",
      "Mean Entropy: 0.35227582153797504\n",
      "Entropy Std Dev: 0.021393052548783147\n",
      "Mean Confusion Matrix:\n",
      " [[9.011e+02 2.578e+02]\n",
      " [2.000e-01 1.980e+01]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9891422617941883\n",
      "Accuracy Std Dev: 0.0020366157655246405\n",
      "Mean Precision: 0.7395766926571881\n",
      "Precision Std Dev: 0.067336794858499\n",
      "Mean Recall: 0.5549999999999999\n",
      "Recall Std Dev: 0.11056672193747989\n",
      "Mean F1-score: 0.6295163246586396\n",
      "F1-score Std Dev: 0.08527191331090848\n",
      "Mean Entropy: 0.032521673568704626\n",
      "Entropy Std Dev: 0.002168035208917359\n",
      "Mean Confusion Matrix:\n",
      " [[1155.     3.9]\n",
      " [   8.9   11.1]]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "XGBOOST",
   "id": "792ca2c05693c062"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:20:02.253892Z",
     "start_time": "2024-09-06T21:19:28.956333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the XGBoost model without undersampling\n",
    "    xgb_model = XGBClassifier(random_state=42)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = xgb_model.predict(X_test)\n",
    "    y_prob_before = xgb_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the XGBoost model with NearMiss\n",
    "    xgb_model_nearmiss = XGBClassifier(random_state=42)\n",
    "    xgb_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = xgb_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = xgb_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the XGBoost model with ClusterCentroids\n",
    "    xgb_model_clustercentroids = XGBClassifier(random_state=42)\n",
    "    xgb_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = xgb_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = xgb_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the XGBoost model with TomekLinks\n",
    "    xgb_model_tomeklinks = XGBClassifier(random_state=42)\n",
    "    xgb_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = xgb_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = xgb_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n"
   ],
   "id": "88c46321a75fc2e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[1154    5]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[664 495]\n",
      " [  3  17]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[1046  113]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[1154    5]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[1150    9]\n",
      " [   5   15]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[670 489]\n",
      " [  1  19]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[935 224]\n",
      " [  1  19]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[1150    9]\n",
      " [   5   15]]\n",
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[1151    8]\n",
      " [  11    9]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[714 445]\n",
      " [  6  14]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[990 169]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[1151    8]\n",
      " [  12    8]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[1154    5]\n",
      " [   6   14]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[695 464]\n",
      " [  3  17]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[977 182]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[1153    6]\n",
      " [   8   12]]\n",
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[1154    5]\n",
      " [   8   12]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[726 433]\n",
      " [  3  17]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[961 198]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[1154    5]\n",
      " [  10   10]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[1155    4]\n",
      " [   5   15]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[701 458]\n",
      " [  1  19]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[1055  104]\n",
      " [   1   19]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[1156    3]\n",
      " [   5   15]]\n",
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[1154    5]\n",
      " [   6   14]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[702 457]\n",
      " [  2  18]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[1056  103]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[1152    7]\n",
      " [   6   14]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[1152    7]\n",
      " [   7   13]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[732 427]\n",
      " [  4  16]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[1063   96]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[1154    5]\n",
      " [  10   10]]\n",
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[1155    4]\n",
      " [   7   13]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[654 505]\n",
      " [  4  16]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[1069   90]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[1154    5]\n",
      " [   7   13]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[1154    4]\n",
      " [   8   12]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[675 483]\n",
      " [  4  16]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[1081   77]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[1155    3]\n",
      " [   8   12]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9891424777983703\n",
      "Accuracy Std Dev: 0.0022049943500056534\n",
      "Mean Precision: 0.6975657894736842\n",
      "Precision Std Dev: 0.07400271421086013\n",
      "Mean Recall: 0.64\n",
      "Recall Std Dev: 0.08888194417315588\n",
      "Mean F1-score: 0.6652562002562001\n",
      "F1-score Std Dev: 0.07310342446542445\n",
      "Mean Entropy: 0.019062487\n",
      "Entropy Std Dev: 0.0018941757\n",
      "Mean Confusion Matrix:\n",
      " [[1153.3    5.6]\n",
      " [   7.2   12.8]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.6024246469411647\n",
      "Accuracy Std Dev: 0.021257583405217346\n",
      "Mean Precision: 0.035084530669706744\n",
      "Precision Std Dev: 0.0031144786055243615\n",
      "Mean Recall: 0.845\n",
      "Recall Std Dev: 0.0722841614740048\n",
      "Mean F1-score: 0.0673646534793004\n",
      "F1-score Std Dev: 0.005933924706281829\n",
      "Mean Entropy: 0.31660074\n",
      "Entropy Std Dev: 0.007832353\n",
      "Mean Confusion Matrix:\n",
      " [[693.3 465.6]\n",
      " [  3.1  16.9]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.8848120979622166\n",
      "Accuracy Std Dev: 0.04218594267920538\n",
      "Mean Precision: 0.14026290790010534\n",
      "Precision Std Dev: 0.04123701507909969\n",
      "Mean Recall: 0.99\n",
      "Recall Std Dev: 0.020000000000000018\n",
      "Mean F1-score: 0.24347044094775092\n",
      "F1-score Std Dev: 0.06380310784789739\n",
      "Mean Entropy: 0.14595766\n",
      "Entropy Std Dev: 0.024330074\n",
      "Mean Confusion Matrix:\n",
      " [[1.0233e+03 1.3560e+02]\n",
      " [2.0000e-01 1.9800e+01]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9884640086632077\n",
      "Accuracy Std Dev: 0.002492419797543205\n",
      "Mean Precision: 0.6834722222222223\n",
      "Precision Std Dev: 0.08704345179276844\n",
      "Mean Recall: 0.6\n",
      "Recall Std Dev: 0.10954451150103321\n",
      "Mean F1-score: 0.6354135153108195\n",
      "F1-score Std Dev: 0.08849824991516768\n",
      "Mean Entropy: 0.01925568\n",
      "Entropy Std Dev: 0.0018359653\n",
      "Mean Confusion Matrix:\n",
      " [[1153.3    5.6]\n",
      " [   8.    12. ]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "svm\n",
   "id": "9b3c6d14b62c4687"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:22:08.886047Z",
     "start_time": "2024-09-06T21:20:35.266924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the SVM model without undersampling\n",
    "    svm_model = SVC(probability=True, random_state=42)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = svm_model.predict(X_test)\n",
    "    y_prob_before = svm_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with NearMiss\n",
    "    svm_model_nearmiss = SVC(probability=True, random_state=42)\n",
    "    svm_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = svm_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = svm_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with ClusterCentroids\n",
    "    svm_model_clustercentroids = SVC(probability=True, random_state=42)\n",
    "    svm_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = svm_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = svm_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the SVM model with TomekLinks\n",
    "    svm_model_tomeklinks = SVC(probability=True, random_state=42)\n",
    "    svm_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = svm_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = svm_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n"
   ],
   "id": "8ef50a7607755cf8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[1156    3]\n",
      " [  10   10]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[173 986]\n",
      " [  4  16]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[850 309]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[1156    3]\n",
      " [  10   10]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[1155    4]\n",
      " [   7   13]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[ 125 1034]\n",
      " [   1   19]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[754 405]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[1155    4]\n",
      " [   7   13]]\n",
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[1155    4]\n",
      " [  12    8]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[210 949]\n",
      " [  5  15]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[877 282]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[1155    4]\n",
      " [  12    8]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[1156    3]\n",
      " [   6   14]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[192 967]\n",
      " [  2  18]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[700 459]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[1156    3]\n",
      " [   6   14]]\n",
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[1155    4]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[213 946]\n",
      " [  5  15]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[901 258]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[1155    4]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[1157    2]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[ 146 1013]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[896 263]\n",
      " [  1  19]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[1157    2]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[1157    2]\n",
      " [  11    9]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[ 110 1049]\n",
      " [   2   18]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[863 296]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[1157    2]\n",
      " [  11    9]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[1158    1]\n",
      " [  11    9]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[203 956]\n",
      " [  4  16]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[659 500]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[1158    1]\n",
      " [  11    9]]\n",
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[1158    1]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[ 115 1044]\n",
      " [   1   19]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[396 763]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[1158    1]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[1155    3]\n",
      " [  13    7]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[ 148 1010]\n",
      " [   3   17]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[886 272]\n",
      " [  0  20]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[1155    3]\n",
      " [  13    7]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9894814603610727\n",
      "Accuracy Std Dev: 0.0018678754989892\n",
      "Mean Precision: 0.7938468394350748\n",
      "Precision Std Dev: 0.07788551151000622\n",
      "Mean Recall: 0.5149999999999999\n",
      "Recall Std Dev: 0.10259142264341595\n",
      "Mean F1-score: 0.6195569988715149\n",
      "F1-score Std Dev: 0.08508930800216104\n",
      "Mean Entropy: 0.036958032609530934\n",
      "Entropy Std Dev: 0.001506418885996129\n",
      "Mean Confusion Matrix:\n",
      " [[1156.2    2.7]\n",
      " [   9.7   10.3]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.15336217709174849\n",
      "Accuracy Std Dev: 0.03099872071348124\n",
      "Mean Precision: 0.017057349376866836\n",
      "Precision Std Dev: 0.0012082715085083473\n",
      "Mean Recall: 0.865\n",
      "Recall Std Dev: 0.08381527307120104\n",
      "Mean F1-score: 0.03345405180247128\n",
      "F1-score Std Dev: 0.002383457839933048\n",
      "Mean Entropy: 0.48528609370846254\n",
      "Entropy Std Dev: 0.05055452733526462\n",
      "Mean Confusion Matrix:\n",
      " [[163.5 995.4]\n",
      " [  2.7  17.3]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.6769948346199982\n",
      "Accuracy Std Dev: 0.12852137294065236\n",
      "Mean Precision: 0.055093486121167136\n",
      "Precision Std Dev: 0.014933980110588463\n",
      "Mean Recall: 0.9949999999999999\n",
      "Recall Std Dev: 0.015000000000000015\n",
      "Mean F1-score: 0.10400807684049052\n",
      "F1-score Std Dev: 0.027061796386700487\n",
      "Mean Entropy: 0.4790880245506015\n",
      "Entropy Std Dev: 0.019984818572438574\n",
      "Mean Confusion Matrix:\n",
      " [[7.782e+02 3.807e+02]\n",
      " [1.000e-01 1.990e+01]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.9894814603610727\n",
      "Accuracy Std Dev: 0.0018678754989892\n",
      "Mean Precision: 0.7938468394350748\n",
      "Precision Std Dev: 0.07788551151000622\n",
      "Mean Recall: 0.5149999999999999\n",
      "Recall Std Dev: 0.10259142264341595\n",
      "Mean F1-score: 0.6195569988715149\n",
      "F1-score Std Dev: 0.08508930800216104\n",
      "Mean Entropy: 0.03656596951428613\n",
      "Entropy Std Dev: 0.001536228754271661\n",
      "Mean Confusion Matrix:\n",
      " [[1156.2    2.7]\n",
      " [   9.7   10.3]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Random Forest",
   "id": "583c59238686b145"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T21:23:00.885982Z",
     "start_time": "2024-09-06T21:22:23.170226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import NearMiss, ClusterCentroids, TomekLinks\n",
    "import numpy as np\n",
    "\n",
    "# Define entropy function\n",
    "def calculate_entropy(probabilities):\n",
    "    epsilon = 1e-10  # Small constant to avoid log(0)\n",
    "    return -np.mean(np.sum(probabilities * np.log(probabilities + epsilon), axis=1))\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 10\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "accuracy_list_before = []\n",
    "precision_list_before = []\n",
    "recall_list_before = []\n",
    "f1_list_before = []\n",
    "entropy_list_before = []\n",
    "confusion_matrices_before = []\n",
    "\n",
    "accuracy_list_nearmiss = []\n",
    "precision_list_nearmiss = []\n",
    "recall_list_nearmiss = []\n",
    "f1_list_nearmiss = []\n",
    "entropy_list_nearmiss = []\n",
    "confusion_matrices_nearmiss = []\n",
    "\n",
    "accuracy_list_clustercentroids = []\n",
    "precision_list_clustercentroids = []\n",
    "recall_list_clustercentroids = []\n",
    "f1_list_clustercentroids = []\n",
    "entropy_list_clustercentroids = []\n",
    "confusion_matrices_clustercentroids = []\n",
    "\n",
    "accuracy_list_tomeklinks = []\n",
    "precision_list_tomeklinks = []\n",
    "recall_list_tomeklinks = []\n",
    "f1_list_tomeklinks = []\n",
    "entropy_list_tomeklinks = []\n",
    "confusion_matrices_tomeklinks = []\n",
    "\n",
    "# Loop through the StratifiedKFold splits\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize and train the Random Forest model without undersampling\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions and probabilities before undersampling\n",
    "    y_pred_before = rf_model.predict(X_test)\n",
    "    y_prob_before = rf_model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy before undersampling\n",
    "    entropy_before = calculate_entropy(y_prob_before)\n",
    "    entropy_list_before.append(entropy_before)\n",
    "    \n",
    "    # Store metrics before undersampling\n",
    "    accuracy_list_before.append(accuracy_score(y_test, y_pred_before))\n",
    "    precision_list_before.append(precision_score(y_test, y_pred_before))\n",
    "    recall_list_before.append(recall_score(y_test, y_pred_before))\n",
    "    f1_list_before.append(f1_score(y_test, y_pred_before))\n",
    "    confusion_matrices_before.append(confusion_matrix(y_test, y_pred_before))\n",
    "    \n",
    "    # Apply NearMiss to the training data\n",
    "    nearmiss = NearMiss(version=1)\n",
    "    X_train_nearmiss, y_train_nearmiss = nearmiss.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with NearMiss\n",
    "    rf_model_nearmiss = RandomForestClassifier(random_state=42)\n",
    "    rf_model_nearmiss.fit(X_train_nearmiss, y_train_nearmiss)\n",
    "    \n",
    "    # Predictions and probabilities after NearMiss\n",
    "    y_pred_nearmiss = rf_model_nearmiss.predict(X_test)\n",
    "    y_prob_nearmiss = rf_model_nearmiss.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after NearMiss\n",
    "    entropy_nearmiss = calculate_entropy(y_prob_nearmiss)\n",
    "    entropy_list_nearmiss.append(entropy_nearmiss)\n",
    "    \n",
    "    # Store metrics after NearMiss\n",
    "    accuracy_list_nearmiss.append(accuracy_score(y_test, y_pred_nearmiss))\n",
    "    precision_list_nearmiss.append(precision_score(y_test, y_pred_nearmiss))\n",
    "    recall_list_nearmiss.append(recall_score(y_test, y_pred_nearmiss))\n",
    "    f1_list_nearmiss.append(f1_score(y_test, y_pred_nearmiss))\n",
    "    confusion_matrices_nearmiss.append(confusion_matrix(y_test, y_pred_nearmiss))\n",
    "    \n",
    "    # Apply ClusterCentroids to the training data\n",
    "    clustercentroids = ClusterCentroids(random_state=42)\n",
    "    X_train_clustercentroids, y_train_clustercentroids = clustercentroids.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with ClusterCentroids\n",
    "    rf_model_clustercentroids = RandomForestClassifier(random_state=42)\n",
    "    rf_model_clustercentroids.fit(X_train_clustercentroids, y_train_clustercentroids)\n",
    "    \n",
    "    # Predictions and probabilities after ClusterCentroids\n",
    "    y_pred_clustercentroids = rf_model_clustercentroids.predict(X_test)\n",
    "    y_prob_clustercentroids = rf_model_clustercentroids.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after ClusterCentroids\n",
    "    entropy_clustercentroids = calculate_entropy(y_prob_clustercentroids)\n",
    "    entropy_list_clustercentroids.append(entropy_clustercentroids)\n",
    "    \n",
    "    # Store metrics after ClusterCentroids\n",
    "    accuracy_list_clustercentroids.append(accuracy_score(y_test, y_pred_clustercentroids))\n",
    "    precision_list_clustercentroids.append(precision_score(y_test, y_pred_clustercentroids))\n",
    "    recall_list_clustercentroids.append(recall_score(y_test, y_pred_clustercentroids))\n",
    "    f1_list_clustercentroids.append(f1_score(y_test, y_pred_clustercentroids))\n",
    "    confusion_matrices_clustercentroids.append(confusion_matrix(y_test, y_pred_clustercentroids))\n",
    "    \n",
    "    # Apply TomekLinks to the training data\n",
    "    tomeklinks = TomekLinks()\n",
    "    X_train_tomeklinks, y_train_tomeklinks = tomeklinks.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Initialize and train the Random Forest model with TomekLinks\n",
    "    rf_model_tomeklinks = RandomForestClassifier(random_state=42)\n",
    "    rf_model_tomeklinks.fit(X_train_tomeklinks, y_train_tomeklinks)\n",
    "    \n",
    "    # Predictions and probabilities after TomekLinks\n",
    "    y_pred_tomeklinks = rf_model_tomeklinks.predict(X_test)\n",
    "    y_prob_tomeklinks = rf_model_tomeklinks.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate entropy after TomekLinks\n",
    "    entropy_tomeklinks = calculate_entropy(y_prob_tomeklinks)\n",
    "    entropy_list_tomeklinks.append(entropy_tomeklinks)\n",
    "    \n",
    "    # Store metrics after TomekLinks\n",
    "    accuracy_list_tomeklinks.append(accuracy_score(y_test, y_pred_tomeklinks))\n",
    "    precision_list_tomeklinks.append(precision_score(y_test, y_pred_tomeklinks))\n",
    "    recall_list_tomeklinks.append(recall_score(y_test, y_pred_tomeklinks))\n",
    "    f1_list_tomeklinks.append(f1_score(y_test, y_pred_tomeklinks))\n",
    "    confusion_matrices_tomeklinks.append(confusion_matrix(y_test, y_pred_tomeklinks))\n",
    "    \n",
    "    # Print confusion matrices for each method\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_before)} Before Undersampling:\\n', confusion_matrices_before[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_nearmiss)} After NearMiss:\\n', confusion_matrices_nearmiss[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_clustercentroids)} After ClusterCentroids:\\n', confusion_matrices_clustercentroids[-1])\n",
    "    print(f'Confusion Matrix for Fold {len(confusion_matrices_tomeklinks)} After TomekLinks:\\n', confusion_matrices_tomeklinks[-1])\n",
    "\n",
    "# Calculate mean and standard deviation of each metric before undersampling\n",
    "mean_accuracy_before = np.mean(accuracy_list_before)\n",
    "std_accuracy_before = np.std(accuracy_list_before)\n",
    "mean_precision_before = np.mean(precision_list_before)\n",
    "std_precision_before = np.std(precision_list_before)\n",
    "mean_recall_before = np.mean(recall_list_before)\n",
    "std_recall_before = np.std(recall_list_before)\n",
    "mean_f1_before = np.mean(f1_list_before)\n",
    "std_f1_before = np.std(f1_list_before)\n",
    "mean_entropy_before = np.mean(entropy_list_before)\n",
    "std_entropy_before = np.std(entropy_list_before)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after NearMiss\n",
    "mean_accuracy_nearmiss = np.mean(accuracy_list_nearmiss)\n",
    "std_accuracy_nearmiss = np.std(accuracy_list_nearmiss)\n",
    "mean_precision_nearmiss = np.mean(precision_list_nearmiss)\n",
    "std_precision_nearmiss = np.std(precision_list_nearmiss)\n",
    "mean_recall_nearmiss = np.mean(recall_list_nearmiss)\n",
    "std_recall_nearmiss = np.std(recall_list_nearmiss)\n",
    "mean_f1_nearmiss = np.mean(f1_list_nearmiss)\n",
    "std_f1_nearmiss = np.std(f1_list_nearmiss)\n",
    "mean_entropy_nearmiss = np.mean(entropy_list_nearmiss)\n",
    "std_entropy_nearmiss = np.std(entropy_list_nearmiss)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after ClusterCentroids\n",
    "mean_accuracy_clustercentroids = np.mean(accuracy_list_clustercentroids)\n",
    "std_accuracy_clustercentroids = np.std(accuracy_list_clustercentroids)\n",
    "mean_precision_clustercentroids = np.mean(precision_list_clustercentroids)\n",
    "std_precision_clustercentroids = np.std(precision_list_clustercentroids)\n",
    "mean_recall_clustercentroids = np.mean(recall_list_clustercentroids)\n",
    "std_recall_clustercentroids = np.std(recall_list_clustercentroids)\n",
    "mean_f1_clustercentroids = np.mean(f1_list_clustercentroids)\n",
    "std_f1_clustercentroids = np.std(f1_list_clustercentroids)\n",
    "mean_entropy_clustercentroids = np.mean(entropy_list_clustercentroids)\n",
    "std_entropy_clustercentroids = np.std(entropy_list_clustercentroids)\n",
    "\n",
    "# Calculate mean and standard deviation of each metric after TomekLinks\n",
    "mean_accuracy_tomeklinks = np.mean(accuracy_list_tomeklinks)\n",
    "std_accuracy_tomeklinks = np.std(accuracy_list_tomeklinks)\n",
    "mean_precision_tomeklinks = np.mean(precision_list_tomeklinks)\n",
    "std_precision_tomeklinks = np.std(precision_list_tomeklinks)\n",
    "mean_recall_tomeklinks = np.mean(recall_list_tomeklinks)\n",
    "std_recall_tomeklinks = np.std(recall_list_tomeklinks)\n",
    "mean_f1_tomeklinks = np.mean(f1_list_tomeklinks)\n",
    "std_f1_tomeklinks = np.std(f1_list_tomeklinks)\n",
    "mean_entropy_tomeklinks = np.mean(entropy_list_tomeklinks)\n",
    "std_entropy_tomeklinks = np.std(entropy_list_tomeklinks)\n",
    "\n",
    "# Calculate mean confusion matrix before and after each method\n",
    "mean_conf_matrix_before = np.mean(confusion_matrices_before, axis=0)\n",
    "mean_conf_matrix_nearmiss = np.mean(confusion_matrices_nearmiss, axis=0)\n",
    "mean_conf_matrix_clustercentroids = np.mean(confusion_matrices_clustercentroids, axis=0)\n",
    "mean_conf_matrix_tomeklinks = np.mean(confusion_matrices_tomeklinks, axis=0)\n",
    "\n",
    "# Print results before undersampling\n",
    "print('--- Before Undersampling ---')\n",
    "print('Mean Accuracy:', mean_accuracy_before)\n",
    "print('Accuracy Std Dev:', std_accuracy_before)\n",
    "print('Mean Precision:', mean_precision_before)\n",
    "print('Precision Std Dev:', std_precision_before)\n",
    "print('Mean Recall:', mean_recall_before)\n",
    "print('Recall Std Dev:', std_recall_before)\n",
    "print('Mean F1-score:', mean_f1_before)\n",
    "print('F1-score Std Dev:', std_f1_before)\n",
    "print('Mean Entropy:', mean_entropy_before)\n",
    "print('Entropy Std Dev:', std_entropy_before)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_before)\n",
    "\n",
    "# Print results after NearMiss\n",
    "print('--- After NearMiss ---')\n",
    "print('Mean Accuracy:', mean_accuracy_nearmiss)\n",
    "print('Accuracy Std Dev:', std_accuracy_nearmiss)\n",
    "print('Mean Precision:', mean_precision_nearmiss)\n",
    "print('Precision Std Dev:', std_precision_nearmiss)\n",
    "print('Mean Recall:', mean_recall_nearmiss)\n",
    "print('Recall Std Dev:', std_recall_nearmiss)\n",
    "print('Mean F1-score:', mean_f1_nearmiss)\n",
    "print('F1-score Std Dev:', std_f1_nearmiss)\n",
    "print('Mean Entropy:', mean_entropy_nearmiss)\n",
    "print('Entropy Std Dev:', std_entropy_nearmiss)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_nearmiss)\n",
    "\n",
    "# Print results after ClusterCentroids\n",
    "print('--- After ClusterCentroids ---')\n",
    "print('Mean Accuracy:', mean_accuracy_clustercentroids)\n",
    "print('Accuracy Std Dev:', std_accuracy_clustercentroids)\n",
    "print('Mean Precision:', mean_precision_clustercentroids)\n",
    "print('Precision Std Dev:', std_precision_clustercentroids)\n",
    "print('Mean Recall:', mean_recall_clustercentroids)\n",
    "print('Recall Std Dev:', std_recall_clustercentroids)\n",
    "print('Mean F1-score:', mean_f1_clustercentroids)\n",
    "print('F1-score Std Dev:', std_f1_clustercentroids)\n",
    "print('Mean Entropy:', mean_entropy_clustercentroids)\n",
    "print('Entropy Std Dev:', std_entropy_clustercentroids)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_clustercentroids)\n",
    "\n",
    "# Print results after TomekLinks\n",
    "print('--- After TomekLinks ---')\n",
    "print('Mean Accuracy:', mean_accuracy_tomeklinks)\n",
    "print('Accuracy Std Dev:', std_accuracy_tomeklinks)\n",
    "print('Mean Precision:', mean_precision_tomeklinks)\n",
    "print('Precision Std Dev:', std_precision_tomeklinks)\n",
    "print('Mean Recall:', mean_recall_tomeklinks)\n",
    "print('Recall Std Dev:', std_recall_tomeklinks)\n",
    "print('Mean F1-score:', mean_f1_tomeklinks)\n",
    "print('F1-score Std Dev:', std_f1_tomeklinks)\n",
    "print('Mean Entropy:', mean_entropy_tomeklinks)\n",
    "print('Entropy Std Dev:', std_entropy_tomeklinks)\n",
    "print('Mean Confusion Matrix:\\n', mean_conf_matrix_tomeklinks)\n"
   ],
   "id": "955fb5117b023b20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Fold 1 Before Undersampling:\n",
      " [[1155    4]\n",
      " [   8   12]]\n",
      "Confusion Matrix for Fold 1 After NearMiss:\n",
      " [[484 675]\n",
      " [  6  14]]\n",
      "Confusion Matrix for Fold 1 After ClusterCentroids:\n",
      " [[1076   83]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 1 After TomekLinks:\n",
      " [[1155    4]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 2 Before Undersampling:\n",
      " [[1153    6]\n",
      " [   6   14]]\n",
      "Confusion Matrix for Fold 2 After NearMiss:\n",
      " [[712 447]\n",
      " [  5  15]]\n",
      "Confusion Matrix for Fold 2 After ClusterCentroids:\n",
      " [[1080   79]\n",
      " [   1   19]]\n",
      "Confusion Matrix for Fold 2 After TomekLinks:\n",
      " [[1153    6]\n",
      " [   8   12]]\n",
      "Confusion Matrix for Fold 3 Before Undersampling:\n",
      " [[1153    6]\n",
      " [  11    9]]\n",
      "Confusion Matrix for Fold 3 After NearMiss:\n",
      " [[600 559]\n",
      " [  9  11]]\n",
      "Confusion Matrix for Fold 3 After ClusterCentroids:\n",
      " [[1062   97]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 3 After TomekLinks:\n",
      " [[1153    6]\n",
      " [  11    9]]\n",
      "Confusion Matrix for Fold 4 Before Undersampling:\n",
      " [[1156    3]\n",
      " [   7   13]]\n",
      "Confusion Matrix for Fold 4 After NearMiss:\n",
      " [[674 485]\n",
      " [  7  13]]\n",
      "Confusion Matrix for Fold 4 After ClusterCentroids:\n",
      " [[1087   72]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 4 After TomekLinks:\n",
      " [[1157    2]\n",
      " [   7   13]]\n",
      "Confusion Matrix for Fold 5 Before Undersampling:\n",
      " [[1154    5]\n",
      " [  10   10]]\n",
      "Confusion Matrix for Fold 5 After NearMiss:\n",
      " [[654 505]\n",
      " [  9  11]]\n",
      "Confusion Matrix for Fold 5 After ClusterCentroids:\n",
      " [[1054  105]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 5 After TomekLinks:\n",
      " [[1155    4]\n",
      " [  11    9]]\n",
      "Confusion Matrix for Fold 6 Before Undersampling:\n",
      " [[1155    4]\n",
      " [   7   13]]\n",
      "Confusion Matrix for Fold 6 After NearMiss:\n",
      " [[694 465]\n",
      " [  2  18]]\n",
      "Confusion Matrix for Fold 6 After ClusterCentroids:\n",
      " [[1094   65]\n",
      " [   1   19]]\n",
      "Confusion Matrix for Fold 6 After TomekLinks:\n",
      " [[1156    3]\n",
      " [   7   13]]\n",
      "Confusion Matrix for Fold 7 Before Undersampling:\n",
      " [[1157    2]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 7 After NearMiss:\n",
      " [[499 660]\n",
      " [  4  16]]\n",
      "Confusion Matrix for Fold 7 After ClusterCentroids:\n",
      " [[1074   85]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 7 After TomekLinks:\n",
      " [[1157    2]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 8 Before Undersampling:\n",
      " [[1153    6]\n",
      " [  14    6]]\n",
      "Confusion Matrix for Fold 8 After NearMiss:\n",
      " [[701 458]\n",
      " [ 11   9]]\n",
      "Confusion Matrix for Fold 8 After ClusterCentroids:\n",
      " [[1070   89]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 8 After TomekLinks:\n",
      " [[1153    6]\n",
      " [  15    5]]\n",
      "Confusion Matrix for Fold 9 Before Undersampling:\n",
      " [[1156    3]\n",
      " [  10   10]]\n",
      "Confusion Matrix for Fold 9 After NearMiss:\n",
      " [[700 459]\n",
      " [  6  14]]\n",
      "Confusion Matrix for Fold 9 After ClusterCentroids:\n",
      " [[1101   58]\n",
      " [   1   19]]\n",
      "Confusion Matrix for Fold 9 After TomekLinks:\n",
      " [[1156    3]\n",
      " [   9   11]]\n",
      "Confusion Matrix for Fold 10 Before Undersampling:\n",
      " [[1156    2]\n",
      " [  16    4]]\n",
      "Confusion Matrix for Fold 10 After NearMiss:\n",
      " [[652 506]\n",
      " [ 11   9]]\n",
      "Confusion Matrix for Fold 10 After ClusterCentroids:\n",
      " [[1093   65]\n",
      " [   0   20]]\n",
      "Confusion Matrix for Fold 10 After TomekLinks:\n",
      " [[1154    4]\n",
      " [  12    8]]\n",
      "--- Before Undersampling ---\n",
      "Mean Accuracy: 0.9882090517272415\n",
      "Accuracy Std Dev: 0.0027487395340848202\n",
      "Mean Precision: 0.7075923831070889\n",
      "Precision Std Dev: 0.09856100992516917\n",
      "Mean Recall: 0.51\n",
      "Recall Std Dev: 0.15132745950421556\n",
      "Mean F1-score: 0.5832725457725457\n",
      "F1-score Std Dev: 0.13632524037064597\n",
      "Mean Entropy: 0.02491357285457515\n",
      "Entropy Std Dev: 0.00230947194940163\n",
      "Mean Confusion Matrix:\n",
      " [[1154.8    4.1]\n",
      " [   9.8   10.2]]\n",
      "--- After NearMiss ---\n",
      "Mean Accuracy: 0.5513622663734771\n",
      "Accuracy Std Dev: 0.0668105869374257\n",
      "Mean Precision: 0.024678903377793493\n",
      "Precision Std Dev: 0.006218951097173424\n",
      "Mean Recall: 0.6500000000000001\n",
      "Recall Std Dev: 0.1414213562373095\n",
      "Mean F1-score: 0.04752074337215106\n",
      "F1-score Std Dev: 0.01185647087438175\n",
      "Mean Entropy: 0.5217547005029239\n",
      "Entropy Std Dev: 0.006822659618651089\n",
      "Mean Confusion Matrix:\n",
      " [[637.  521.9]\n",
      " [  7.   13. ]]\n",
      "--- After ClusterCentroids ---\n",
      "Mean Accuracy: 0.9320563886116835\n",
      "Accuracy Std Dev: 0.0118539637444743\n",
      "Mean Precision: 0.2018584053189041\n",
      "Precision Std Dev: 0.02695311001359748\n",
      "Mean Recall: 0.985\n",
      "Recall Std Dev: 0.02291287847477922\n",
      "Mean F1-score: 0.33403799724021166\n",
      "F1-score Std Dev: 0.036326003938786246\n",
      "Mean Entropy: 0.35517575827278736\n",
      "Entropy Std Dev: 0.02096894731117663\n",
      "Mean Confusion Matrix:\n",
      " [[1.0791e+03 7.9800e+01]\n",
      " [3.0000e-01 1.9700e+01]]\n",
      "--- After TomekLinks ---\n",
      "Mean Accuracy: 0.988294013372099\n",
      "Accuracy Std Dev: 0.0029093802388156197\n",
      "Mean Precision: 0.7124554612054612\n",
      "Precision Std Dev: 0.1188406357167895\n",
      "Mean Recall: 0.51\n",
      "Recall Std Dev: 0.11789826122551596\n",
      "Mean F1-score: 0.5921276136116843\n",
      "F1-score Std Dev: 0.11852546890264047\n",
      "Mean Entropy: 0.026133846624954587\n",
      "Entropy Std Dev: 0.002395750772951356\n",
      "Mean Confusion Matrix:\n",
      " [[1154.9    4. ]\n",
      " [   9.8   10.2]]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4015c12eb4f0424a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
